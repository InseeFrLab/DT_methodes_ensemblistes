---
title: "Le boosting"
author: |
  [Olivier Meslin](https://github.com/oliviermeslin)
  [Mélina Hillion](https://github.com/melinahillion)
format:
  typst:
    toc: true
    section-numbering: 1.1.1
    bibliography: references.bib
---

```{=typst} 
#import "@preview/mitex:0.2.4": *
```

$
\DeclareMathOperator*{\argmin}{arg\,min}
\makeatletter
\let\ams@underbrace=\underbrace
\def\underbrace#1_#2{%
  \setbox0=\hbox{$\displaystyle#1$}%
  \ams@underbrace{#1}_{\parbox[t]{\the\wd0}{#2}}%
}
\makeatother
$

Le _boosting_ est une approche ensembliste qui ne traite pas les modèles de base séparément les uns des autres.


Imaginons qu'on veuille entraîner le modèle suivant:

$F\left(\mathbf{x}\right) = \sum_{m=1}^M \beta_m f\left(\mathbf{x}, \mathbf{\theta}_m\right)$


$\hat{F}$ est caractérisée par les paramètres $\{\beta_m, \mathbf{\theta}_m\}_{m=1}^{M}$ tels que
$\argmin_{\{\beta_m, \mathbf{\theta}_m\}_{m=1}^{M}} \sum_{i=1}^N L\left(y_i, \sum_{m=1}^M \beta_m f\left(\mathbf{x}_i, \mathbf{\theta}_m\right)\right)$


C'est un problème très compliqué dès que $M$ est élevé!

## Le *boosting*

Le *boosting* combine une approche ensembliste avec une **modélisation additive par étapes** (*forward stagewise additive modeling*). La modélisation additive par étapes consite à décomposer l'entraînement d'un modèle très complexe en une __séquence d'entraînements de petits modèles__, procédure beaucoup plus simple. 

D'autre part, chacun de ces modèles simples est entraîné de façon à améliorer la prédiction par rapport à 

. . .

- Chaque _base learner_ essaie de [corriger les erreurs du modèle issu des étapes précédentes]{.blue2}.


## Modélisation additive par étapes {.small90}

Un point important est que __la modélisation additive par étapes simplifie considérablement l'entraînement du modèle__: - On commence par entraîner un seul _base learner_;
- On ajoute au modèle un deuxième _base learner_ sans modifier les paramètres du premier _base learner_ déjà entraîné;
- On entraîne ce deuxième _base learner_ de façon à améliorer le plus possible le modèle global (la somme des deux _base learners_).
- On ajoute un troisième _base learner_ et on l'entraîne...

<!--
```{=typst} 
#import "@preview/algo:0.3.3": algo, i, d, comment, code

#algo(
  line-numbers: false,
  title: Modélisation additive par étape
)[
  if $n < 0$:#i\        // use #i to indent the following lines
    return null#d\      // use #d to dedent the following lines
  if $n = 0$ or $n = 1$:#i #comment[you can also]\
    return $n$#d #comment[add comments!]\
  return #smallcaps("Fib")$(n-1) +$ #smallcaps("Fib")$(n-2)$
]    
```
-->


1.  Commencer par $f_0\left(\mathbf{x}\right) = 0$.
2.  Pour $m = 1, \dots, M:$
    (a) Entraîner le $m$-ième modèle:
    $$\left(\hat{\beta}_m, \hat{\theta}_m\right) = \argmin_{\beta, \mathbf{\theta}} \sum_{i=1}^N L\left(y_i, f_{m-1}\left(\mathbf{x}_i\right) + \beta b\left(\mathbf{x}_i, \mathbf{\theta}\right)\right)$$
    (b) Définir $f_m\left(\mathbf{x}\right) = f_{m-1}\left(\mathbf{x}\right) + \hat{\beta}_m b\left(\mathbf{x}_i, \mathbf{\hat{\theta}_m}\right)$

## La mécanique du _gradient boosting_

Depuis la publication de @friedman2001greedy, la méthode de _gradient boosting_ a connu de multiples implémentations, parmi lesquelles celle proposée par Friedman lui-même, XGBoost (@chen2016xgboost), LightGBM (@ke2017lightgbm) et CatBoost (@prokhorenkova2018catboost). S'il existe quelques différences entre ces implémentations, elles partagent néanmoins la même mécanique d'ensemble, que la section qui suit va présenter en détail en s'appuyant sur l'implémentation proposée par XBGoost.[^Cette partie reprend la structure et les notations de la partie 2 de @chen2016xgboost.]

Quatre étapes:

- Présentation du modèle qu'on veut entraîner;
- Reformulation du modèle pour faire apparaître les gradients;
- Calcul des poids optimaux et de la qualité d'un arbre dont la structure est donnée;
- Définition d'une méthode et de critères permettant de construire un arbre.


### Le modèle à entraîner

On veut entraîner un modèle comprenant $K$ arbres de régression ou de classification: 

$$\hat{y}_{i} = \phi\left(\mathbf{x}_i\right) = \sum_{k=1}^{K} f_k\left(\mathbf{x}_i\right), f_k \epsilon \mathcal{F}$$

Chaque arbre $F$ est défini par trois paramètres: sa structure (une fonction $q: \mathbb{R}^m \rightarrow \{1, \dots, T\}$ qui à un vecteur d'inputs $x$ de dimension $m$ associe une feuille terminale de l'arbre), son nombre de feuilles terminales $T$ et les valeurs figurant sur ses feuilles terminales $\mathbf{w}\in \mathbb{R}^T$ (appelées poids ou _weights_).

Le modèle est entraîné avec une __fonction-objectif__ constituée d'une __fonction de perte__ dérivable et convexe $l$ et d'une __fonction de régularisation__ $\Omega$. La fonction de perte mesure la distance entre la prédiction $hat(y)$ et la vraie valeur $y$; la fonction de perte pénalise la complexité du modèle.

```{=typst} 
#mitex(`
$$\mathcal{L}(\phi) = \underbrace{\sum_i l(\hat{y}_{i}, y_{i})}_{\substack{\text{Perte sur les} \\ \text{observations}}} + \underbrace{\sum_k \Omega(f_{k})}_{\substack{\text{Fonction de} \\ \text{régularisation}}}\hspace{5mm}\text{avec}\hspace{5mm}\Omega(f) = \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_i^2$$

`)
```

<!-- ```{=typst} 
#mitex(`
$$\mathcal{L}(\phi) = \underbrace{\sum_i l(\hat{y}_{i}, y_{i})}_{\substack{\text{Perte sur les} \\ \text{observations}}} + \underbrace{\sum_k \Omega(f_{k})}_{\substack{\text{Fonction de} \\ \text{régularisation}}}\hspace{5mm}\text{avec}\hspace{5mm}\Omega(f) = \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_i^2$$ + \alpha \sum_{j=1}^T |w_i|$$
`)
``` -->

<!-- $\mathcal{F} = \{f(\mathbf{x}) = w_{q(\mathbf{x})}\}(q:\mathbb{R}^m \rightarrow T,w \in \mathbb{R}^T)$ -->

<!-- $\hat{y}_i^{(0)} = 0\\ \hat{y}_i^{(1)} = f_1(x_i) = \hat{y}_i^{(0)} + f_1(x_i)\\ \hat{y}_i^{(2)} = f_1(x_i) + f_2(x_i)= \hat{y}_i^{(1)} + f_2(x_i)\\ ....\\ \hat{y}_i^{(t)} = \sum_{k=1}^t f_k(x_i)= \hat{y}_i^{(t-1)} + f_t(x_i)$ -->



### Faire apparaître le gradient

La fonction-objectif introduite précédemment est très complexe et ne peut être utilisée directement pour entraîner le modèle, car il faudrait entraîner tous les arbres en même temps. On va donc reformuler donc cette fonction objectif de façon à isoler le $t$-ième arbre, qui pourra ensuite être entraîné seul, une fois que les $t-1$ arbres précédents auront été entraînés. Pour cela, on note $\hat{y}_i^{(t)}$ la prédiction à l'issue de l'étape $t$: $\hat{y}_i^{(t)} = \sum_{k=1}^t f_k(\mathbf{x}_i)$, et on écrit la fonction-objectif `#mi("\mathcal{L}^{(t)}")`{=typst} au moment de l'entraînement du $t$-ième arbre: 

```{=typst} 
#mitex(`
$$\begin{align*}
\mathcal{L}^{(t)} 
&= \sum_{i=1}^{n} l(y_i, \hat{y}_{i}^{(t)})                                                                               & + \sum_{k=1}^t\Omega(f_k) \\
&= \sum_{i=1}^{n} l(y_i, \underbrace{\hat{y}_{i}^{(t-1)}}_{\text{(A)}} + \underbrace{f_{t}(\mathbf{x}_i)}_{\text{(B)}}) & + \underbrace{\sum_{k=1}^{t-1}\Omega(f_k)}_{\text{(C)}} + \underbrace{\Omega(f_t)}_{\text{(D)}} \\
&= \sum_{i=1}^{n} l(y_i, \text{constante} + f_{t}(\mathbf{x}_i)) & + \text{constante} + \Omega(f_t)
\end{align*}$$


`)
```

Il est important de noter qu'à l'issue de l'entraînement des $t-1$ arbres précédents, les termes (A) et (C) sont constants. Par conséquent, la seule façon d'améliorer le modèle est de trouver un $t$-ième arbre qui minimise la fonction-objectif ainsi réécrite.

Une fois isolé le $t$-ième arbre, on fait un développement limité d'ordre 2 de $l(y_i, \hat{y}_{i}^{(t-1)} + f_{t}(\mathbf{x}_i))$ au voisinage de $\hat{y}_{i}^{(t-1)}$: 

```{=typst} 
#mitex(`
$$\mathcal{L}^{(t)} \approx \sum_{i=1}^{n} [l(y_i, \hat{y}_{i}^{(t-1)}) + g_i f_t(\mathbf{x}_i)+ \frac{1}{2} h_i f^2_t(\mathbf{x}_i)] + \Omega(f_t)$$
`)
```

```{=typst} 
#mitex(`
$$\text{avec}\hspace{4mm} 
g_i = \frac{\partial l(y_i, \hat{y}_i^{(t-1)})}{\partial\hat{y}_i^{(t-1)}} \hspace{4mm}\text{et}\hspace{4mm}
h_i = \frac{\partial^2 l(y_i, \hat{y}_i^{(t-1)})}{{\partial \hat{y}_i^{(t-1)}^2}}$$
`)
```


## Faire apparaître les poids $w_j$ {.small90}

::: {.small80}
:::: {.incremental}

- On peut simplifier $\mathcal{\tilde{L}}^{(t)}$ en enlevant les termes $l(y_i, \hat{y}_{i}^{(t-1)})$ car ils sont constants et en remplaçant $\Omega(f)$ par sa définition: 
$$\mathcal{\tilde{L}}^{(t)} = \sum_{i=1}^{n} [g_i f_t(\mathbf{x}_i)+ \frac{1}{2} h_i f^2_t(\mathbf{x}_i)] + \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_i^2$$

- On définit $I_j = \{ i | q(\mathbf{x}_i) = j \}$ l'ensemble des observations situées sur la feuille $j$ et on réorganise $\mathcal{\tilde{L}}^{(t)}$ pour faire apparaître les poids $w_i$ du $t$-ième arbre:
$$\begin{alignat*}{4}
\mathcal{\tilde{L}}^{(t)}
  &= \sum_{j=1}^{T} \sum_{i\in I_j} \Bigl[g_i f_t(\mathbf{x}_i) &&+ \frac{1}{2} h_i f^2_t(\mathbf{x}_i)\Bigr] &&+ \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_i^2 \\
  &= \sum_{j=1}^{T} \sum_{i\in I_j} \Bigl[g_i w_j &&+ \frac{1}{2} h_i w_j^2\Bigl] &&+ \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_i^2 \\
  &= \sum^T_{j=1} \Bigl[w_j\Bigl(\sum_{i\in I_j} g_i\Bigr) &&+ \frac{1}{2} w_j^2 \Bigl(\sum_{i\in I_j} h_i + \lambda\Bigr) \Bigr] &&+ \gamma T
\end{alignat*}$$

:::
::::

## Calculer les poids optimaux $w_j$ {.small90}

::: {.small90}
:::: {.incremental}

- Pour une structure d'arbre donnée ($q: \mathbb{R}^m \rightarrow \{1, \dots, T\}$), on peut facilement calculer les poids optimaux et la valeur optimale de la fonction-objectif:
$$w_j^{\ast} = -\frac{\sum_{i\in I_j} g_i}{\sum_{i\in I_j} h_i+\lambda}$$
$$\mathcal{\tilde{L}}^{(t)}(q) = -\frac{1}{2} \sum_{j=1}^T \frac{\left(\sum_{i\in I_j} g_i\right)^2}{\sum_{i\in I_j} h_i+\lambda} + \gamma T$$

- [__Ces deux formules sont très utiles!__]{.blue2}

:::
::::

## Évaluer la qualité d'un arbre et d'un _split_ {.small90}

::: {.small80}
:::: {.incremental}

- On peut utiliser la formule donnant la valeur optimale de la fonction-objectif pour comparer la qualité de deux arbres.

- On également peut utiliser cette formule pour évaluer le gain (réduction de la fonction-objectif) induit par un _split_ marginal.

- Imaginons qu'on décompose la feuille $I$ en deux nouvelles feuilles $I_L$ et $I_R$ (avec $I = I_L \cup I_R$). Le gain potentiel par ce _split_ est:
$$\mathcal{L}_{\text{split}} = \frac{1}{2} \left[\frac{\left(\sum_{i\in I_L} g_i\right)^2}{\sum_{i\in I_L} h_i+\lambda}+\frac{\left(\sum_{i\in I_R} g_i\right)^2}{\sum_{i\in I_R} h_i+\lambda}-\frac{\left(\sum_{i\in I} g_i\right)^2}{\sum_{i\in I} h_i+\lambda}\right] - \gamma$$

- Cette dernière formule est essentielle: elle permet de comparer les _splits_ possibles lorsqu'on construit un arbre.

:::
::::

## Comment construire un arbre

- Bien dire qu'on est en approche _greedy_ (glouton/morfal/bourrin).
- Décrire les différentes façons de rechercher les _splits_.
- Parler à la fin du _pruning_.



## Encore des équations


$obj^{(t)} = \sum_{i=1}^n (y_{i} - (\hat{y}_{i}^{(t-1)} + f_t(x_i)))^2 + \sum_{i=1}^t\Omega(f_i) \\ = \sum_{i=1}^n [2(\hat{y}_i^{(t-1)} - y_i)f_t(x_i) + f_t(x_i)^2] + \Omega(f_t) + constant$

$obj^{(t)} = \sum_{i=1}^{n} [l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_{i} f_{t}^2(x_i)] + \Omega(f_t) + constant$

## Toujours des équations



$\sum_{i=1}^n [g_{i} f_{t}(x_i) + \frac{1}{2} h_{i} f_{t}^2(x_i)] + \Omega(f_t)$

$f_t(x) = w_{q(x)}, w \in R^{T}, q:R^d\rightarrow \{1,2,...,T\}$

## Ya encore des équations

$\Omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2 obj^{(t)} \approx \sum_{i=1}^n [g_i w_{q(x_i)} + \frac{1}{2} h_i w_{q(x_i)}^2] + \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2\\ = \sum^T_{j=1} [(\sum_{i\in I_j} g_i) w_j + \frac{1}{2} (\sum_{i\in I_j} h_i + \lambda) w_j^2 ] + \gamma T$

$obj^{(t)} = \sum^T_{j=1} [G_jw_j + \frac{1}{2} (H_j+\lambda) w_j^2] +\gamma T$

$G_j = \sum_{i\in I_j} g_i\\ H_j = \sum_{i\in I_j} h_i$

$w_j^{\ast} = -\frac{G_j}{H_j+\lambda}\\ \text{obj}^{\ast} = -\frac{1}{2} \sum_{j=1}^T \frac{G_j^2}{H_j+\lambda} + \gamma T$

$Gain = \frac{1}{2} \left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}\right] - \gamma$





