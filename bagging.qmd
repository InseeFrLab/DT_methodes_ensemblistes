---
title: "Le bagging"
author: |
  [Mélina Hillion](https://github.com/melinahillion)
  [Olivier Meslin](https://github.com/oliviermeslin)
format:
  ams-typst: default
  typst:
    toc: true
    section-numbering: 1.1.1
bibliography: references.bib
---

```{=typst}
#import "@preview/mitex:0.2.4": *
#set math.equation(
numbering: "(1)",
supplement: none
)
```
# Le bagging

Le bagging, ou "bootstrap aggregating", est une méthode ensembliste conçue pour améliorer la stabilité et la précision des algorithmes d'apprentissage automatique (Breiman, 1996). Elle repose sur la construction de plusieurs modèles élémentaires (il s'agit souvent de plusieurs versions d'un même modèle) entraînés sur des échantillons distincts grâce à la technique du bootstrap. Ces modèles sont ensuite combinés pour produire une prédiction agrégée, souvent plus robuste et généralisable que celle obtenue par un modèle unique.

<!-- , qui consiste à créer des échantillons par tirage aléatoires avec remise à partir du jeu de données initial -->

## Principe du bagging

Le bagging comporte trois étapes clés:

-   **L'échantillonnage bootstrap** : L'échantillonnage bootstrap consiste à créer des échantillons distincts en tirant des observations aléatoirement avec remise à partir du jeu de données initial. Chaque échantillon *bootstrap* contient le même nombre d'observations que le jeu de données initial, mais certaines observations peuvent être répétées (car sélectionnées plusieurs fois), tandis que d'autres peuvent être omises.

-   **L'entraînement de plusieurs modèles** : Un modèle (aussi appelé *apprenant de base* ou *weak learner*) est entraîné/construit pour chaque échantillon bootstrap. Les modèles peuvent être des arbres de décision, des régressions ou tout autre algorithme d'apprentissage. Le bagging est particulièrement efficace et souvent utilisé en pratique avec les arbres de décision.

-   **L'agrégation des prédictions** : Les prédictions de tous les modèles sont ensuite agrégées, en procédant généralement à la moyenne (ou à la médiane) des prédictions dans le cas de la régression, et au vote majoritaire (ou à la moyenne des probabilités prédites pour chaque classe) dans le cas de la classification, afin d'obtenir des prédictions plus précises et généralisables.

## Pourquoi ça marche: propriétés du bagging

Un modèle avec une variance élevée va produire des prédictions très variables, instables, d'un jeu de données à l'autre. Cela signifie qu'il est très sensible aux variations dans les données d'apprentissage. L'objectif du bagging est d'améliorer la précision globale en agrégeant les prédictions de plusieurs modèles entraînés sur des échantillons (légèrement) différents les uns des autres. Dans un article fondateur, Breiman (1996) montre que, sous certaines conditions, la variance du modèle agrégé est inférieure à la variance moyenne de chaque modèle pris individuellement. Cette méthode est particulièrement efficace lorsqu'elle est appliquée à des familles de modèles très instables, dont les performances sont particulièrement sensibles aux fluctuations aléatoires du jeu de données d'apprentissage/d'entraînement.

Afin de mieux comprendre comment, et dans quelles conditions, l'agrégation de modèles par bagging peut améliorer la performance d'un modèle individuel, nous présentons dans cette section les principaux éléments de la démonstration de Breiman (1996). Ces considérations seront utiles pour décider s'il convient ou non d'agréger les prédictions de plusieurs modèles dans une situation donnée. 

Dans la suite, nous notons $φ(x, L)$ un prédicteur (d'une valeur numérique dans le cas de la *régression* ou d'un label dans le cas de la *classification*), entraîné sur un ensemble d'apprentissage $L$, et prenant en entrée un vecteur de caractéristiques x. Nous notons $Y = f(x)$ la variable que l'on cherche à prédire.



### La régression: réduction de l'erreur quadratique moyenne par agrégation

Dans le contexte de la **régression**, l'objectif est de prédire une valeur numérique $Y$ à partir d'un vecteur de caractéristiques $x$. Un modèle de régression $\phi(x, L)$ est construit à partir d'un ensemble d'apprentissage $L$, et produit une estimation de $Y$ pour chaque observation $x$. Le **bagging** vise à améliorer la précision de ces prédictions en réduisant la variance des estimations.


- **Définition du prédicteur agrégé**

Formellement, le **prédicteur agrégé** obtenu par bagging est défini comme suit :

$$\phi_A(x) = E_L[\phi(x, L)]$$

où $\phi_A(x)$ représente la prédiction agrégée, $E_L[.]$ correspond à l'espérance prise sur tous les échantillons d'apprentissage $L$ possibles, chacun étant tiré selon la même distribution que le jeu de données initial, et $\phi(x, L)$ correspond à la prédiction du modèle construit sur l'échantillon d'apprentissage $L$.


- **La décomposition biais-variance** 

Pour mieux comprendre comment le bagging améliore la performance globale d'un modèle, revenons à la **décomposition biais-variance** de l'erreur quadratique moyenne, classiquement considérée dans un problème de régression. La décomposition de l'erreur totale permet de faire appraître trois composantes : le biais, la variance et le bruit. Pour un modèle $\phi(x, L)$, l'erreur quadratique moyenne peut s'écrire comme suit :

$E_L[(Y - \phi(x, L))^2] = \underbrace{(E_L[\phi(x, L)] - f(x))^2}_{\text{Biais}^2} + \underbrace{E_L[(\phi(x, L) - E_L[\phi(x, L)])^2]}_{\text{Variance}} + \underbrace{\sigma^2}_{\text{Bruit}}$

  - Le **biais** est la différence entre la valeur observée ($Y = f(x)$) que l'on souhaite prédire et la prédiction moyenne $E_L[\phi(x, L)]$. Si le modèle est sous-ajusté, le biais sera élevé.

  - La **variance** est la variabilité des prédictions ($\phi(x, L)$) autour de leur moyenne ($E_L[\phi(x, L)]$). Un modèle avec une variance élevée est très sensible aux fluctuations au sein des données d'entraînement.
  
  - Enfin, le **bruit** est une composante intrinsèque au processus générateur des données qui ne peut être réduite, quel que soit le modèle.

Nous allons voir que le bagging agit principalement sur la  **variance**. En moyenne, le biais reste inchangé, car le bagging ne modifie pas la structure du modèle. Cependant, en agrégant plusieurs modèles, le bagging procède à la **moyenne des variations** dues aux différents échantillons d'entraînement, ce qui a pour effet de **réduire la variance globale**.



- **L'inégalité de Breiman (1996)** 

La démonstration du fait que le prédicteur obtenu par bagging réduit la variance d'un modèle de régression repose sur une **inégalité clé** introduite par Breiman (1996). Cette inégalité compare l'erreur quadratique moyenne d'un modèle individuel avec celle du modèle agrégé. Elle est formulée ainsi :


$$(Y - \phi_A(x))^2 \leq E_L[(Y - \phi(x, L))^2]$$

  - Le terme $(Y - \phi_A(x))^2$ représente l'erreur quadratique du **prédicteur agrégé** $\phi_A(x)$
  - Le terme $E_L[(Y - \phi(x, L))^2]$ est l'erreur quadratique moyenne d'un **prédicteur individuel** $\phi(x, L)$ entraîné sur un échantillon aléatoire $L$. Cette erreur varie en fonction des données d'entraînement.

Cette inégalité montre que **l'erreur quadratique moyenne du prédicteur agrégé est toujours inférieure ou égale à la moyenne des erreurs des prédicteurs individuels**. 

Breiman (1996) montre ainsi que la **variance du modèle agrégé** $\phi_A(x)$ est **toujours inférieure ou égale** à la variance moyenne d'un modèle individuel :

$$\text{Var}(\phi_A(x)) = \text{Var}(E_L[\phi(x, L)]) \leq E_L[\text{Var}(\phi(x, L))]$$

Le processus d'agrégation par bagging réduit la **variance** des prédictions, tout en maintenant un biais constant, ce qui a pour conséquence de réduire l'erreur de prédiction globale.


### La classification: vers un classificateur presque optimal par agrégation

Dans le cas de la classification, le mécanisme de réduction de la variance par le bagging est légèrement différent de celui de la régression et permet d'atteindre un **classificateur presque optimal** (*nearly optimal classifier*). Ce concept a été introduit par Breiman (1996) pour décrire un modèle qui tend à classer une observation dans la classe la plus probable, avec une performance approchant celle du classificateur Bayésien optimal (la meilleure performance théorique qu'un modèle de classification puisse atteindre).

Breiman (1996) montre que le bagging peut transformer un classificateur "mostly order-correct" (c'est-à-dire un modèle qui, en espérance, attribue correctement la classe la plus probable à la plupart des observations, mais peut se tromper pour certaines d'entre elles) en un classificateur presque optimal (c'est-à-dire un modèle qui, pour la plupart des observations $x$, classe toujours l'observation $x$ dans la classe à laquelle elle a la plus grande probabilité conditionnelle $P(j∣x)$ d'appartenir). Le classificateur agrégé ainsi obtenu est optimal dans toutes les régions de l'espace où le classificateur individuel est order-correct en espérance. De manière intuitive, lorsque la majorité des modèles prédit la bonne classe, l'agrégation réduit ou élimine les erreurs aléatoires des classificateurs individuels, améliorant ainsi la précision globale du classificateur agrégé.

Pour comprendre ce résutlat, introduisons $Q(j|x) = P(φ(x, L) = j)$, la probabilité que le modèle $φ(x, L)$, entraîné sur l'ensemble L, prédise la classe $j$ pour l'observation $x$, et $P(j|x)$, la vraie probabilité (conditionnelle) que $x$ appartienne à la classe $j$.

En théorie, $Q(j|x)$ correspond à la probabilité d'affectation de l'observation $x$ à la classe $j$ lorsque le modèle $φ$ est entraîné sur tous les ensembles d'apprentissage possibles $L$.
En pratique $Q(j|x)$, est estimée à partir des prédictions de modèles entraînés sur une collection plus restreinte d'ensembles d'apprentissage (typiquement, des ensembles générés par bootstrap à partir de l'échantillon initial). Chaque modèle prédit une classe pour l'entrée $x$, et $Q(j∣x)$ correspond à la fréquence de prédiction de la classe $j$ pour l'observation $x$ parmi l'ensemble des modèles.


-   **Définition du classificateur order correct**

Un classificateur est dit **order-correct** pour une observation $x$ si, en espérance, il identifie **correctement la classe la plus probable** pour cette observation, même s’il ne prédit pas toujours avec exactitude les probabilités associées à chaque classe $Q(j∣x)$. Cela signifie que si l'on prenait un nombre infini de jeux de données et que l'on évaluait les prédictions du modèle en $x$, la majorité des prédictions correspondraient à la classe ayant la plus grande probabilité vraie $P(j∣x)$ [à laquelle il a la plus grande probabilité vraie $P(j∣x)$ d'appartenir].

Formellement, un prédicteur est dit "order-correct" pour une entrée $x$ si :

$$argmax_j Q(j|x) = argmax_j P(j|x)$$

où $P(j|x)$ est la vraie probabilité que l’observation $x$ appartienne à la classe $j$, et $Q(j|x)$ est la probabilité estimée par le modèle que $x$ appartienne à la classe $j$.

Un classificateur est **order-correct** si, pour **chaque** observation $x$, la classe qu'il prédit correspond à celle qui a la probabilité maximale $P(j|x)$ dans la distribution vraie. 


-   **Prédicteur agrégé en classification: le rôle du vote majoritaire**

Dans le cas de la classification, le prédicteur agrégé est défini par le **vote majoritaire**. Cela signifie que si $K$ classificateurs sont entraînés sur $K$ échantillons distincts, la classe prédite pour $x$ est celle qui reçoit **le plus de votes** de la part des modèles individuels.

Formellement, le classificateur agrégé $φA(x)$ est défini par :

$φA(x) =  \text{argmax}_j \sum_{L} I(\phi(x, L) = j) = argmax_j Q(j|x)$

où $Q(j|x)$ est la proportion de votes (prédictions) reçus par la classe $j$ pour l'observation $x$ parmi les $K$ classificateurs.
 

-   **Performance globale: convergence vers un classificateur presque optimal**

Breiman (1996) montre que si chaque prédicteur individuel $φ(x, L)$ est order-correct pour une observation $x$, alors le prédicteur agrégé $φA(x)$, obtenu par vote majoritaire, atteint la performance optimale pour cette observation, c'est-à-dire qu'il converge vers la classe ayant la probabilité maximale $P(j∣x)$. Le vote majoritaire permet ainsi de **réduire les erreurs aléatoires** des classificateurs individuels.

Pour comprendre ce résultat, considérons la probabilité que le classificateur agrégé $ϕA$ prédise correctement la classe d'une observation $x$, étant donné les probabilités vraies $P(j|x)$ :

$$Σ_j I(argmax_i Q(i|x) = j)P(j|x)$$

où $Q(i∣x)$ est la probabilité que le modèle prédise la classe $i$ pour l'entrée $x$, $argmax_i Q(i∣x)$ est la classe prédite par le vote majoritair (la classe ayant reçu le plus de vote, c'est-à-dire la plus souvent prédite parmi l'ensemble des classificateurs individuels), $P(j∣x)$ est la véritable probabilité que $x$ appartienne à la classe $j$, $I(⋅)$ est la fonction indicatrice, qui vaut 1 si la condition à l'intérieur est vraie et 0 sinon.

Si le classificateur $ϕ$ est order-correct pour l'entrée $x$, c'est-à-dire qu'il identifie correctement la classe à laquelle celle-ci a la plus grande probabilité d'appartenir ($P(j∣x)$), alors la formule $Σ_j I(argmax_i Q(i|x) = j)P(j|x)$ devient simplement $\max_j P(j|x)$, ce qui correspond à la probabilité maximale que $x$ appartienne à une classe particulière $j$. Cette valeur représente le critère **optimal** pour minimiser les **erreurs de classification** : un classificateur optimal assignera systématiquement $x$ à la classe qui a cette probabilité maximale.

Cela signifie que le classificateur agrégé $ϕA$ prédit systématiquement la classe la plus probable pour l'observation $x$, et que la probabilité de classification correcte est donc **optimale** dans les régions où les classificateurs individuels sont order-correct. 

Cependant, dans les régions de l’espace où les classificateurs individuels ne sont pas order-corrects en espérance (c’est-à-dire qu'ils se trompent majoritairement sur la classe), le bagging ne pourra pas compenser ces erreurs de manière suffisante. Dans ces régions, l'agrégation par vote majoritaire n'améliorera pas les performances, et dans certains cas, elle pourrait même dégrader les résultats en consolidant les erreurs systémiques.


## Quand utiliser le bagging

### Les implications des propriétés précédentes dans le cas de la régression:

-   Si φ(x, L) varie fortement (variance élevée, instabilité des prédiction) selon l'ensemble d'entraînement L, l'inégalité $Var(φA(x)) ≤ EL[Var(φ(x, L))]$ sera d'autant plus forte et le bagging sera d'autant plus efficace.

-   Si au contraire φ(x, L) ne varie peu (variance faible, stabilité des prédiction) d'un ensemble d'entraînement L à l'autre, alors $Var(φA(x))$ est proche de $EL[Var(φ(x, L))]$, la réduction de variance apportée par le bagging sera faible.

Ce résultat justifie que le bagging soit particulièrement efficace pour améliorer les performances des modèles instables, comme les arbres de décision, mais pas celles des modèles stables comme la méthode des K plus proches voisins (K-means).

### Les implications des propriétés précédentes dans le cas de la classification:

Breiman (1996) conclut que si un prédicteur est "bon" (c'est-à-dire qu'il prédit correctement l'ordre des classes pour la plupart des entrées $x$), l'agrégation peut le transformer en un prédicteur presque optimal. Cependant, l'agrégation de mauvais prédicteurs (c'est-à-dire ne prédisant pas correctement la classe majoritaire) peut aggraver les performances du modèle initial.

### Les limites

Qu'il s'agisse de la régression ou de la classification, les performances des modèles peuvent se dégrader dans certaines circonstances, en particulier lorsque la variance du modèle est faible, et que les modèles sont biaisés (c'est le cas d'un modèle globalement non order correct dans le cas de la classification par exemple). Cela vient du fait que, en pratique, les différents ensembles d'apprentissage L utilisés pour construire le prédicteur agrégé sont construits par la méthode du bootstrap, en tirant aléatoirement avec remise des observations dans le jeu de données initial, et non sur l'ensemble des jeux de données possibles.
