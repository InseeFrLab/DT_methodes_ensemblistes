# Guide d'usage du _gradient boosting_ {#sec-guide-gb}

Ce guide propose des recommandations sur l'usage des algorithmes de _gradient boosting_ disponibles dans la littérature, notamment @bentejac2021comparative. 

Contrairement aux forêts aléatoires, la littérature méthodologique sur l'usages des algorithmes de _gradient boosting_ est assez limitée et relativement peu conclusive. 


. Ce guide comporte un certain nombre de choix méthodologiques forts, comme les implémentations recommandées ou la procédure d'entraînement proposée, et d'autres choix pertinents sont évidemment possibles. C'est pourquoi les recommandations de ce guide doivent être considérées comme un point de départ raisonnable, pas comme un ensemble de règles devant être respectées à tout prix.

## Quelle implémentation utiliser? {#sec-implementation-gb}

Il existe quatre implémentations du _gradient boosting_: `XGBoost`, `LightGBM`, `CatBoost` et `scikit-learn`. Elles sont toutes des variantes optimisées de l'algorithme de @friedman2001greedy et ne diffèrent que sur des points mineurs. De multiples publications les ont comparées, à la fois en matière de pouvoir prédictif et de rapidité d'entraînement (voir notamment @bentejac2021comparative, @alshari2021comparison et @florek2023benchmarking). Cette littérature a abouti à trois conclusions. Premièrement, les différentes implémentations présentent des performances très proches (le classement exact variant d'une publication à l'autre). Deuxièmement, bien optimiser les hyperparamètres est nettement plus important que le choix de l'implémentation. Troisièmement, le temps d'entraînement varie beaucoup d'une implémentation à l'autre, et `LightGBM` est sensiblement plus rapide que les autres. Dans la mesure où l'optimisation des hyperparamètres est une étape à la fois essentielle et intense en calcul, l'efficacité computationnelle apparaît comme un critère majeur de choix de l'implémentation. C'est pourquoi __le présent document décrit et recommande l'usage de `LightGBM`__. Ceci étant, les trois autres implémentations peuvent également être utilisées, notamment si les données sont de taille limitée.

Par ailleurs, chacune de ces implémentations propose une interface de haut niveau compatible avec `scikit-learn`. __Il est vivement recommandé d'utiliser cette interface car elle minimise les risques d'erreur, facilite la construction de modèles reproductibles et permet d'utiliser l'ensemble des outils proposés par `scikit-learn`.__

## Les hyperparamètres clés du _gradient boosting_ {#sec-hyperparam-gb}

::: {.content-visible when-format="html"}

Cette section décrit en détail les principaux hyperparamètres des algorithmes de _gradient boosting_ listés dans le tableau @tbl-hyp-lightgbm. Les noms des hyperparamètres sont ceux utilisés dans `LightGBM`. Les hyperparamètres portent généralement le même nom dans les autres implémentations; si ce n'est pas le cas, il est facile de s'y retrouver en lisant attentivement la documentation.


| Hyperparamètre                         | Description                                                                                    | Valeur par défaut |
|:---------------------------------------|:-----------------------------------------------------------------------------------------------|:-----------------:|
| `objective`                            | Fonction de perte utilisée                                                                     | Variable          |
| `n_estimators` ou `num_trees`          | Nombre d'arbres                                                                                | 100               |
| `learning_rate` ou `eta`               | Taux d'apprentissage                                                                           | 0.1               |
| `max_depth`                            | Profondeur maximale des arbres                                                                 | -1 (pas de limite)|
| `num_leaves`                           | Nombre de feuilles terminales des arbres                                                       | 31                |
| `min_child_samples`                    | Nombre minimal d'observations qu'une feuille terminale doit contenir                           | 20                |
| `min_child_weight`                     | Poids minimal qu'une feuille terminale doit contenir                                           | 0.001             |
| `lambda` ou `lambda_l2`                | Pénalisation quadratique sur la valeur des feuilles terminales                                 | 0                 |
| `reg_alpha` ou `lambda_l1`             | Pénalisation absolue (L1) sur la valeur des feuilles terminales                                | 0                 |
| `min_split_gain`                       | Gain minimal nécessaire pour diviser un noeud                                                  | 0                 |
| `bagging_fraction`                     | Taux d'échantillonnage des données d'entraînement (utilisé uniquement si `bagging_freq` )  > 0 | 1                 |
| `bagging_freq`                         | Fréquence de rééchantillonnage des données d'entraînement (utilisé uniquement si `bagging_fraction` ) < 1 | 1                 |
| `feature_fraction`                     | Taux d'échantillonnage des colonnes par arbre                                                  | 1                 |
| `feature_fraction_bynode`              | Taux d'échantillonnage des colonnes par noeud                                                  | 1                 |
| `max_bin`                              | Nombre de _bins_ utilisés pour discrétiser les variables continues                             | 255               |
| `max_cat_to_onehot`                    | Nombre de modalités en-deça duquel `LightGBM` utilise le _one-hot-encoding_                    | 4                 |
| `max_cat_threshold`                    | Nombre maximal de _splits_ considérés <br> dans le traitement des variables catégorielles      | 32                | 
| `sample_weight`                        | Pondération des observations dans les données d'entraînement                                   | 1                 |
| `scale_pos_weight`                     | Poids des observations de la classe positive (classification binaire uniquement)               | Aucun             |
| `class_weight`                         | Poids des observations de chaque classe (classification multiclasse uniquement)                | Aucun             |

: Les principaux hyperparamètres de `LightGBM` {#tbl-hyp-lightgbm tbl-colwidths="[25,60,15]"}

:::


::: {.callout-warning title="Attention aux alias!"}

Il arrive fréquemment que les hyperparamètres des algorithmes de _gradient boosting_ portent plusieurs noms. Par exemple dans `LightGBM`, le nombre d'arbres porte les noms suivants: `num_iterations`, `num_iteration`, `n_iter`, `num_tree`, `num_trees`, `num_round`, `num_rounds`, `nrounds`, `num_boost_round`, `n_estimators` et `max_iter` (ouf!). C'est une source récurrente de confusion, mais il est facile de s'y retrouver en consultant la page de la documentation sur les hyperparamètres, qui liste les _alias_:

- [hyperparamètres de `LightGBM`](https://lightgbm.readthedocs.io/en/latest/Parameters.html);
- [hyperparamètres de `XGBoost`](https://xgboost.readthedocs.io/en/stable/parameter.html);
- [hyperparamètres de `CatBoost`](https://catboost.ai/docs/en/references/training-parameters/);
- [hyperparamètres de `scikit-learn`](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html).

:::

Voici une présentation des principaux hyperparamètres et de leurs effets sur les performances sur le modèle de _gradient boosting_:

- La __mécanique du *gradient boosting*__ est contrôlée par seulement trois hyperparamètres (tous les autres hyperparamètres portant sur la construction des arbres pris isolément):

    - L'hyperparamètre `objective` définit à la fois la __nature du problème__ modélisé (régression, classification...) et la __fonction de perte__ utilisée lors de l'entraînement du modèle. Valeur par défaut différente selon les cas, regression_l2 en cas de régression, binary_log_loss pour la classification binaire, LIEN PARTIE USAGE AVANCE. A COMPLETER.

    - le __nombre d'arbres__ contrôle la complexité générale de l'algorithme. Le point essentiel est que, contrairement aux forêts aléatoires, la performance du _gradient boosting_ sur les données d'entraînement croît continûment avec le nombre d'arbres sans jamais se stabiliser. Le choix du nombre d'arbres est essentiel, et doit viser un équilibre entre amélioration du pouvoir prédictif du modèle (si les arbres supplémentaires permettent au modèle de corriger les erreurs résiduelles), et lutte contre le surajustement (si les arbres supplémentaires captent uniquement les bruits statistiques et les fluctuations spécifiques des données d'entraînement). Par ailleurs, le choix du nombre d'arbres est très lié à celui du taux d'apprentissage, et il est nécessaire de les optimiser conjointement (@probst2019tunability).

    - le __taux d'apprentissage__ (_learning rate_) contrôle l'influence de chaque arbre sur le modèle global; il s'agit de $\eta$ dans l'équation REFERENCE PARTIE OVERFITTING. Cet hyperparamètre a un effet important sur la performance du modèle global (@probst2019tunability). Un taux d'apprentissage faible réduit la contribution de chaque arbre, rendant l'apprentissage plus progressif; cela évite qu'un arbre donné ait une influence trop importante sur le modèle global et contribue donc à réduire le surajustement, mais nécessite un plus grand nombre d'arbres pour converger vers une solution optimale. Inversement, un taux d'apprentissage élevé accélère l'entraînement mais peut rendre le modèle instable (car trop sensible à un arbre donné), entraîner un surajustement et/ou aboutir à un modèle sous-optimal. La règle générale est de privilégier un taux d'apprentissage faible (entre 0.01 ou 0.3). Le choix du taux d'apprentissage est très lié à celui du nombre d'arbres: plus le taux d'apprentissage sera faible, plus le nombre d'arbres nécessaires pour converger vers une solution optimale sera élevé. Ces deux hyperparamètres doivent donc être optimisés conjointement.

- La __complexité des arbres__: la profondeur maximale des arbres, le nombre de feuilles terminales et le nombre minimal d'observations par feuille terminale contrôlent la complexité des _weak learners_: une profondeur élevée, un grand nombre de feuilles et un faible nombre d'observations par feuille terminale aboutissent à des arbres complexes au pouvoir prédictif plus élevé, mais induisent un risque de surajustement. Par ailleurs, de tels arbres sont plus longs à entraîner que des arbres peu profonds avec un nombre limité de feuilles. Les valeurs de  hyperparamètres ont un effet sur le nombre optimal d'arbres: celui-ci est plus faible quand les arbres sont complexes. Il est à noter que le nombre de feuilles terminales a un effet linéaire sur la complexité des arbres, tandis que la profondeur maximale a un effet exponentiel: un arbre pleinement développé de profondeur $k$ comprend $2^k$ feuilles terminales et $2^k - 1$ _splits_. Augmenter la profondeur d'une unité a donc pour effet de doubler le temps d'entraînement de chaque arbre.

- La __lutte contre le surajustement__: ces hyperparamètres de régularisation jouent un rôle important dans le contrôle de la complexité des _weak learners_ et contribuent à éviter le surajustement: 
    - Les pénalisations tendent à réduire le poids $w_j$ des feuilles terminales: la pénalisation quadratique réduit la valeur absolue des poids sans les annuler (il s'agit de $\lambda$ dans l'[équation donnant le poids optimal](4-boosting.qmd#eq-w-j-optimal) d'une feuille terminale), tandis que la pénalisation absolue élevée pousse certains poids à être nuls. La pénalisation quadratique est la plus utilisée, notamment parce qu'elle permet d'amoindrir l'influence des points aberrants. 
    - Le gain minimal définit la réduction minimale de la perte requise pour qu'un nœud soit divisé (il s'agit du paramètre $\gamma$ dans l'[équation donnant le gain potentiel d'un _split_](4-boosting.qmd#eq-fct-eval-split)); une valeur plus élevée contribue à réduire la complexité des arbres et à limiter le surajustement en empêchant l'algorithme de créer des _splits_ dont l'apport est très faible et potentiellement dû à des variations non significatives des données d'entraînement.

- Les __hyperparamètres d'échantillonnage__: 
    - le taux d'échantillonnage des données d'entraînement et le taux d'échantillonnage des colonnes par noeud jouent exactement le même rôle que `sample.fraction` ou `max_samples`, et `mtry` dans la forêt aléatoire: échantillonner les données d'entraînement accélère l'entraînement, et échantillonner les colonnes au niveau de chaque noeud aboutit à des arbres plus variés. Il est à noter que l'échantillonnage des données se fait systématiquement sans remise dans les algorithmes de _gradient boosting_. Comme pour la forêt aléatoire, la valeur optimale du taux d'échantillonnage des colonnes par noeud dépend du nombre de variables réellement pertinentes dans les données, et une valeur plus élevée est préférable si les données comprennent un grand nombre de variables binaires issues du _one-hot-encoding_ des variables catégorielles.
    - L'échantillonnage des colonnes par arbre sert essentiellement à accélérer l'entraînement. Si les colonnes sont échantillonnées par arbre et par noeud, alors le taux d'échantillonnage final est le produit des deux taux.
    
- Les __réglages relatifs au retraitement des colonnes__: 
    - le nombre de _bins_ utilisés pour discrétiser les variables continues (voir partie PREPROCESSING pour le détail): un faible de _bins_ contribue à accélérer l'entraînement (car le nombre de _splits_ potentiels est faible), mais peut dégrader le pouvoir prédictif si de faibles variations de la variable continue ont un impact notable sur la variable-cible. Inversement, une valeur élevée permet de conserver davantage d'information sur la distribution de la variable continue, mais peut ralentir l'entraînement.
    - le nombre de modalités en-deça duquel les variables catégorielles font l'objet d'un _one-hot-encoding_ et le nombre maximal de _splits_ considérés dans le traitement des variables catégorielles définissent la méthode utilisée pour traiter les variables catégorielles (voir partie PREPROCESSING pour le détail). 

- Les __pondérations__:
    - la pondération des observations sert à pondérer les données d'entraînement (voir PARTIE USAGE AVANCE).
    - le poids des observations de la classe positive sert à rééquilibrer les données d'entraînement lorsque la classe positive est sous-représentée. Cet hyperparamètre ne sert que pour la classification binaire. Par défaut les deux classes ont le même poids.
    - le poids des observations de chaque classe sert à rééquilibrer les données d'entraînement lorsque la part des différentes classes est hétérogène. Cet hyperparamètre ne sert que pour la classification binaire multiclasse. Par défaut toutes les classes ont le même poids.


::: {.callout-warning title="_Depth-wise versus leaf-wise_: les deux approches de la construction des arbres"}
Il existe deux méthodes de construction des arbres, illustrée par la figure ci-dessous:

- dans l' __approche par niveau__ (dite _depth-wise_) proposée à l'origine par `XGBoost`, l'arbre est construit niveau par niveau, en divisant tous les nœuds du même niveau avant de passer au niveau suivant. L'approche _depth-wise_ n'est pas optimale pour minimiser la fonction de perte, car elle ne recherche pas systématiquement le _split_ le plus performant, mais elle permet d'obtenir des arbres équilibrés et de profondeur limitée. L'hyperparamètre-clé de cette approche est la profondeur maximale des arbres (`max_depth`).

- dans l' __approche par feuille__ (dite _leaf-wise_) proposée à l'origine par `LightGBM`, l'arbre est construit feuille par feuille, et c'est le _split_ avec le gain le plus élevé qui est retenu à chaque étape, et ce quelle que soit sa position dans l'arbre. L'approche _leaf-wise_ est très efficace pour minimiser la fonction de perte, car elle privilégie les _splits_ les plus porteurs de gain. L'hyperparamètre-clé de cette approche est le nombre maximal de feuilles terminales (`num_leaves`). Il se trouve que l'approche _leaf-wise_ a été ajoutée par la suite à `XGBoost`, _via_ l'hyperparamètre `grow_policy` qui peut prendre les valeurs `depthwise` (valeur par défaut) et `lossguide` (approche _leaf-wise_).

Si elle est en général plus performante que l'approche par niveau, l'approche par feuille peut aboutir à un modèle surajusté et difficile à utiliser car composé d'arbres complexes, déséquilibrés et très profonds^[REFERENCE USAGE EN PREDICTION Voir par exemple [cette discussion](https://community.intel.com/t5/Intel-oneAPI-Data-Analytics/why-daal4py-model-is-8-02-GB-while-the-same-LightGBM-model-is/td-p/1521207)]. Par exemple, si on fixe `num_leaves` à 256, on peut aisément obtenir un arbre avec une branche de profondeur 30. Il est donc important de spécifier à la fois `num_leaves` et `max_depth` lorsqu'on utilise l'approche par feuille, de façon à obtenir des arbres peu déséquilibrés. Une approche simple consiste à fixer conjointement les deux hyperparamètres: si on fixe `num_leaves` à $2^k$, on peut fixer `max_depth` à $k+5$. Cela signifie que dans un arbre à 256 feuilles aucune branche ne pourra pas avoir une profondeur supérieure à 13.

![](/figures/leafwise-depthwise.png){#fig-leaf-wise width=60%}


:::


## Comment entraîner un algorithme de _gradient boosting_? {#sec-procedure-training-gb}


Proposer une procédure pour l'optimisation des hyperparamètres s'avère plus délicat pour les algorithmes de _gradient boosting_ que pour les forêts aléatoires, car ces algorithmes comprennent un nombre beaucoup plus élevé d'hyperparamètres, et la littérature méthodologique sur leur usage pratique reste assez limitée et peu conclusive (en-dehors des nombreux tutoriels introductifs disponibles sur internet). Trois constats sont néanmoins bien établis. Premièrement, __bien optimiser les hyperparamètres est essentiel pour la performance du modèle final__. Deuxièmement, __cette optimisation est complexe et longue__, il faut donc la mener de façon rigoureuse et organisée pour ne pas perdre de temps. Troisièmement, __contrairement aux forêts aléatoires, les valeurs par défaut des hyperparamètres dans les différentes implémentations ne constituent le plus souvent pas un point de départ raisonnable__ (@bentejac2021comparative et @probst2019tunability), en particulier pour les hyperparamètres de régularisation dont la valeur par défaut est souvent nulle.

### Préparer l'optimisation des hyperparamètres

- __Définir des valeurs de départ raisonnables__. Définir les valeurs de départ des hyperpararamètres est une étape importante car elle permet de gagner du temps lors de l'optimisation des hyperparamètres. __Ce choix prend du temps__ et doit reposer sur une bonne compréhension du fonctionnement de l'algorithme et sur une connaissance approfondie des données utilisées. Voici quelques suggestions de valeurs de départ issues de la littérature (voir notamment @bentejac2021comparative et @probst2019tunability); il est tout à fait possible de s'en écarter lorsqu'on pense que le problème modélisé le justifie:

    - `max_depth`: entre 8 et 12; 
    - `num_leaves`: entre 30 et 255;
    <!-- On ne met pas learning_rate car c'est le premier HP à optimiser -->
    <!-- - `learning_rate`: entre 0.03 et 0.2; -->
    - `min_split_gain`: valeur strictement positive, commencer entre 0.1 et 1;
    - `lambda`: valeur strictement positive; commencer avec une valeur entre 0.5 et 2; choisir une valeur plus élevée s'il y a des valeurs aberrantes sur $y$ ou de clairs signes de surajustement; 
    - `bagging_fraction`         : valeur strictement inférieure à 1, commencer entre 0.6 et 0.8; 
    - `bagging_freq`             : valeur entière strictement positive, commencer avec 1 ; 
    - `feature_fraction_bynode`  : valeur strictement inférieure à 1, commencer entre 0.5 et 0.7; choisir une valeur plus élevée si les données comprennent un grand nombre de variables binaires issues d'un _one-hot-encoding_;
    - `max_bin`                  : garder la valeur par défaut; choisir éventuellement une valeur plus élevée si la la valeur par défaut ne suffit pas à refléter la distribution des variables continues;
    - `max_cat_to_onehot`        : garder la valeur par défaut;
    - `max_cat_threshold`        : garder la valeur par défaut.

- __Définir la méthode d'évaluation des hyperparamètres__: indépendamment de la méthode d'optimisation des hyperparamètres (_grid search_, _random search_...), deux approches sont envisageables pour évaluer les valeurs possibles des hyperparamètres: soit une __validation croisée__ (par exemple avec la fonction `GridSearchCV` de `scikit-learn`), soit une __validation simple__ reposant sur un unique ensemble de validation. La validation simple peut être préférable si les données utilisées sont volumineuses (au-delà de plusieurs centaines de milliers d'observations) car elle offre un gain de temps appréciable, sans nécessairement dégrader les résultats. La validation croisée est censée être plus robuste que l'utilisation d'un ensemble de validation, mais elle est coûteuse sur le plan computationnel (car il faut entraîner plusieurs fois un modèle pour chaque jeu d'hyperparamètres).

### Optimiser les hyperparamètres

#### Une procédure itérative par validation croisée

Voici une procédure simple pour optimiser les hyperparamètres d'un algorithme de _gradient boosting_. Elle ne garantit pas l'obtention d'un modèle optimal, mais elle est lisible et permet d'obtenir rapidement un modèle raisonnablement performant. Elle est coûteuse sur le plan computationnel et donc adaptée à des données peu volumineuses.

- __Optimiser conjointement le nombre d'arbres et le taux d'apprentissage__. Par exemple, on évalue les performances du modèle en testant les valeurs `[100, 200, 500, 1000]` pour le nombre d'arbres, et `[0.05, 0.1, 0.15, 0.2]` pour le taux d'apprentissage, avec des valeurs raisonnables pour les autres hyperparamètres. On retient finalement le taux d'apprentissage et le nombre d'arbres du modèle le plus performant. Si l'un de ces hyperparamètres est la valeur minimale ou maximale testée (par exemple 1000 arbres, ou 0.05 pour le taux d'apprentissage), alors il est préférable de recommencer l'exercice en ajustant la liste des valeurs possibles.

- __Optimiser conjointement l'échantillonnage des observations et des variables__. On utilise le taux d'apprentissage et le nombre d'arbres issus de l'étape précédente, puis on évalue les performances de différents couples de valeurs (`bagging_fraction`, `bagging_fraction`), et on retient enfin les valeurs des hyperparamètres du modèle le plus performant.

- __Optimiser conjointement les hyperparamètres de régularisation__. On utilise les valeurs des hyperparamètre issues des étapes précédentes, puis on évalue les performances de différents couples de valeurs (`lambda`, `min_split_gain`), et on retient les valeurs des hyperparamètres du modèle le plus performant.

Cette procédure est présentée en détail dans la partie 1 du notebook XXXXXXXXXXXXXXXXXXXXXXXXXXXX.
    
<!-- ::: {.callout-warning title="_Early stopping_ et validation croisée"}

::: -->


#### Une procédure itérative par validation simple

- __Optimiser conjointement le nombre d'arbres et le taux d'apprentissage__. Le principe est le suivant: on évalue les performances de différents couples de valeurs (nombre d'arbres, taux d'apprentissage) avec des valeurs raisonnables pour les autres hyperparamètres. Il y a deux approches, selon qu'on retient une approche de validation croisée, 

    - Évaluer conjointement les couples de valeurs (nombre d'arbres, taux d'apprentissage). Par exemple, on évalue les performances du modèle en testant les valeurs `[100, 200, 500, 1000]` pour le nombre d'arbres, et `[0.05, 0.1, 0.15, 0.2]` pour le taux d'apprentissage. On retient finalement le taux d'apprentissage et le nombre d'arbres du modèle le plus performant. Si l'un de ces hyperparamètres est la valeur minimale ou maximale testée (par exemple 1000 arbres, ou 0.05 pour le taux d'apprentissage), alors il est préférable de recommencer l'exercice en ajustant la liste des valeurs possibles.
    - Mettre un nombre d'arbres très élevé et tester uniquement des valeurs du taux d'apprentissage. Par exemple, on fixe à 50000 le nombre d'arbres, et on teste les valeurs `[0.05, 0.1, 0.15, 0.2]` pour le taux d'apprentissage. Il est __indispensable__ d'utiliser l'_early stopping_ dans cette approche. L'intuition est la suivante: pour chaque valeur possible du taux d'apprentissage, on laisse l'entraînement se prolonger jusqu'à ce que les performances cessent de s'améliorer sur l'ensemble de validation. Chaque modèle entraîné se résume par trois informations: le taux d'apprentissage testé, le nombre d'arbres auquel l'entraînement s'est arrêté, et la performance sur l'ensemble de validation. On retient finalement le taux d'apprentissage et le nombre d'arbres du modèle le plus performant.

Gridsearch avec ou sans CV, avec _early stopping_, avec des valeurs raisonnables pour les principaux hyperparamètres. Nombre d'arbres: `[100, 200, 500, 1000]`, _learning rate_: `[0.05, 0.1, 0.15, 0.2]`. Si l'un des hyperparamètres considérés comme optimal est la valeur minimale ou maximale (1000 arbres dans l'exemple précédent, ou 0.05 pour ), alors il est préférable de recommencer l'exercice en ajustant la liste des valeurs possibles.

Attention, il est essentiel d'utiliser l'_early stopping_

Cette procédure est présentée en détail dans la partie 2 du notebook XXXXXXXXXXXXXXXXXXXXXXXXXXXX.



si le nombre d'arbres n'était pas suffisant. Une fois défini le bon nombre d'arbres, mettre 20% de plus.

Pour les étapes suivantes: reprendre les étapes présentées [ici](https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258).

Regarder cette vidéo: https://www.bilibili.com/video/BV1DE41167cu/

- __Ajuster la complexité des arbres__.
- __Ajuster les hyperparamètres de lutte contre le surajustement__.
- __Entraîner du modèle final__: entraîner une forêt aléatoire avec les hyperparamètres optimisés déduits des étapes précédentes.
- __Évaluer du modèle final__: mesurer la performance du modèle final sur un ensemble de test.



::: {.callout-tip title="Parfois, une forêt aléatoire suffit..."}

Avant de se lancer dans le _gradient boosting_, il est utile d'entraîner une forêt aléatoire selon la procédure décrite dans la section @sec-procedure-training-rf. Ce modèle servira de point de comparaison pour la suite, et permettra notamment de voir si le _gradient boosting_ offre des gains de performances qui justifient le temps passé à l'optimisation des hyperparamètres.
:::


#### Une approche avancée: utiliser `optuna`


Cette procédure est présentée en détail dans la partie 3 du notebook XXXXXXXXXXXXXXXXXXXXXXXXXXXX.
