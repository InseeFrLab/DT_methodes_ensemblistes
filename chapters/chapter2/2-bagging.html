<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>bagging – Introduction aux méthodes ensemblistes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter2/3-random_forest.html" rel="next">
<link href="../../chapters/chapter2/1-CART.html" rel="prev">
<link href="../../images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1959eab64d7f8dc8170c6f7139d73ad1.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter2/1-CART.html">Présentation formelle des algorithmes</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter2/2-bagging.html">Le <em>bagging</em></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Introduction aux méthodes ensemblistes</a> 
        <div class="sidebar-tools-main">
    <a href="../.././pdf/dt_methodes_ensemblistes.pdf" title="NMFS Open Science" class="quarto-navigation-tool px-1" aria-label="NMFS Open Science"><i class="bi bi-file-pdf-fill"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction aux méthodes ensemblistes</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter1/1-survol.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Survol des méthodes ensemblistes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter1/1-survol.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Aperçu des méthodes ensemblistes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter1/2-comparaison_GB_RF.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comparaison entre forêts aléatoires et <em>gradient boosting</em></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter2/1-CART.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Présentation formelle des algorithmes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/1-CART.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">La brique élémentaire: l’arbre de décision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/2-bagging.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Le <em>bagging</em></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/3-random_forest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">La forêt aléatoire</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/4-boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Le <em>boosting</em></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/ajouts_boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sujets avancés</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter3/1-preparation_donnees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comment bien utiliser les algorithmes?</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/1-preparation_donnees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Préparation des données</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/2-guide_usage_RF.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guide d’usage des forêts aléatoires</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/3-guide_usage_GB.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guide d’usage du <em>gradient boosting</em></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-bagging-detail" id="toc-sec-bagging-detail" class="nav-link active" data-scroll-target="#sec-bagging-detail"><span class="header-section-number">1</span> Le <em>bagging</em></a>
  <ul class="collapse">
  <li><a href="#principe-du-bagging" id="toc-principe-du-bagging" class="nav-link" data-scroll-target="#principe-du-bagging"><span class="header-section-number">1.1</span> Principe du <em>bagging</em></a></li>
  <li><a href="#pourquoi-et-dans-quelles-situations-le-bagging-fonctionne" id="toc-pourquoi-et-dans-quelles-situations-le-bagging-fonctionne" class="nav-link" data-scroll-target="#pourquoi-et-dans-quelles-situations-le-bagging-fonctionne"><span class="header-section-number">1.2</span> Pourquoi (et dans quelles situations) le <em>bagging</em> fonctionne</a>
  <ul class="collapse">
  <li><a href="#la-régression-réduction-de-lerreur-quadratique-moyenne-par-agrégation" id="toc-la-régression-réduction-de-lerreur-quadratique-moyenne-par-agrégation" class="nav-link" data-scroll-target="#la-régression-réduction-de-lerreur-quadratique-moyenne-par-agrégation"><span class="header-section-number">1.2.1</span> La régression: réduction de l’erreur quadratique moyenne par agrégation</a></li>
  <li><a href="#la-classification-vers-un-classificateur-presque-optimal-par-agrégation" id="toc-la-classification-vers-un-classificateur-presque-optimal-par-agrégation" class="nav-link" data-scroll-target="#la-classification-vers-un-classificateur-presque-optimal-par-agrégation"><span class="header-section-number">1.2.2</span> La classification: vers un classificateur presque optimal par agrégation</a></li>
  </ul></li>
  <li><a href="#léchantillage-par-bootstrap-peut-détériorer-les-performances-théoriques-du-modèle-agrégé" id="toc-léchantillage-par-bootstrap-peut-détériorer-les-performances-théoriques-du-modèle-agrégé" class="nav-link" data-scroll-target="#léchantillage-par-bootstrap-peut-détériorer-les-performances-théoriques-du-modèle-agrégé"><span class="header-section-number">1.3</span> L’échantillage par bootstrap peut détériorer les performances théoriques du modèle agrégé</a></li>
  <li><a href="#le-bagging-en-pratique" id="toc-le-bagging-en-pratique" class="nav-link" data-scroll-target="#le-bagging-en-pratique"><span class="header-section-number">1.4</span> Le <em>bagging</em> en pratique</a>
  <ul class="collapse">
  <li><a href="#quand-utiliser-le-bagging-en-pratique" id="toc-quand-utiliser-le-bagging-en-pratique" class="nav-link" data-scroll-target="#quand-utiliser-le-bagging-en-pratique"><span class="header-section-number">1.4.1</span> Quand utiliser le <em>bagging</em> en pratique</a></li>
  <li><a href="#comment-utiliser-le-bagging-en-pratique" id="toc-comment-utiliser-le-bagging-en-pratique" class="nav-link" data-scroll-target="#comment-utiliser-le-bagging-en-pratique"><span class="header-section-number">1.4.2</span> Comment utiliser le <em>bagging</em> en pratique</a></li>
  </ul></li>
  <li><a href="#mise-en-pratique-exemple-avec-code" id="toc-mise-en-pratique-exemple-avec-code" class="nav-link" data-scroll-target="#mise-en-pratique-exemple-avec-code"><span class="header-section-number">1.5</span> Mise en pratique (exemple avec code)</a></li>
  <li><a href="#interprétation" id="toc-interprétation" class="nav-link" data-scroll-target="#interprétation"><span class="header-section-number">1.6</span> Interprétation</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/edit/main/chapters/chapter2/2-bagging.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/blob/main/chapters/chapter2/2-bagging.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter2/1-CART.html">Présentation formelle des algorithmes</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter2/2-bagging.html">Le <em>bagging</em></a></li></ol></nav></header>




<section id="sec-bagging-detail" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Le <em>bagging</em></h1>
<p>Le <em>bagging</em>, ou “bootstrap aggregating”, est une méthode ensembliste qui vise à améliorer la stabilité et la précision des algorithmes d’apprentissage automatique en agrégeant plusieurs modèles (<span class="citation" data-cites="breiman1996bagging">Breiman (<a href="#ref-breiman1996bagging" role="doc-biblioref">1996</a>)</span>). Chaque modèle est entraîné sur un échantillon distinct généré par une technique de rééchantillonnage (<em>bootstrap</em>). Ces modèles sont ensuite combinés pour produire une prédiction agrégée, souvent plus robuste et généralisable que celle obtenue par un modèle unique.</p>
<!-- , qui consiste à créer des échantillons par tirage aléatoires avec remise à partir du jeu de données initial -->
<section id="principe-du-bagging" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="principe-du-bagging"><span class="header-section-number">1.1</span> Principe du <em>bagging</em></h2>
<p>Le <em>bagging</em> comporte trois étapes principales:</p>
<ul>
<li><p><strong>L’échantillonnage bootstrap</strong> : L’échantillonnage bootstrap consiste à créer des échantillons distincts en tirant aléatoirement avec remise des observations du jeu de données initial. Chaque échantillon <em>bootstrap</em> contient le même nombre d’observations que le jeu de données initial, mais certaines observations sont répétées (car sélectionnées plusieurs fois), tandis que d’autres sont omises.</p></li>
<li><p><strong>L’entraînement de plusieurs modèles</strong> : Un modèle (aussi appelé <em>apprenant de base</em> ou <em>weak learner</em>) est entraîné sur chaque échantillon bootstrap. Les modèles peuvent être des arbres de décision, des régressions ou tout autre algorithme d’apprentissage. Le <em>bagging</em> est particulièrement efficace avec des modèles instables, tels que les arbres de décision non élagués.</p></li>
<li><p><strong>L’agrégation des prédictions</strong> : Les prédictions de tous les modèles sont ensuite agrégées, en procédant généralement à la moyenne (ou à la médiane) des prédictions dans le cas de la régression, et au vote majoritaire (ou à la moyenne des probabilités prédites pour chaque classe) dans le cas de la classification, afin d’obtenir des prédictions plus précises et généralisables.</p></li>
</ul>
</section>
<section id="pourquoi-et-dans-quelles-situations-le-bagging-fonctionne" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="pourquoi-et-dans-quelles-situations-le-bagging-fonctionne"><span class="header-section-number">1.2</span> Pourquoi (et dans quelles situations) le <em>bagging</em> fonctionne</h2>
<p>Certains modèles sont très sensibles aux données d’entraînement, et leurs prédictions sont très instables d’un échantillon à l’autre. L’objectif du <em>bagging</em> est de construire un prédicteur plus précis en agrégeant les prédictions de plusieurs modèles entraînés sur des échantillons (légèrement) différents les uns des autres.</p>
<p><span class="citation" data-cites="breiman1996bagging">Breiman (<a href="#ref-breiman1996bagging" role="doc-biblioref">1996</a>)</span> montre que cette méthode est particulièrement efficace lorsqu’elle est appliquée à des modèles très instables, dont les performances sont particulièrement sensibles aux variations du jeu de données d’entraînement, et peu biaisés.</p>
<p>Cette section vise à mieux comprendre comment (et sous quelles conditions) l’agrégation par <em>bagging</em> permet de construire un prédicteur plus performant.</p>
<p>Dans la suite, nous notons <span class="math inline">\(φ(x, L)\)</span> un prédicteur (d’une valeur numérique dans le cas de la <em>régression</em> ou d’un label dans le cas de la <em>classification</em>), entraîné sur un ensemble d’apprentissage <span class="math inline">\(L\)</span>, et prenant en entrée un vecteur de caractéristiques <span class="math inline">\(x\)</span>.</p>
<section id="la-régression-réduction-de-lerreur-quadratique-moyenne-par-agrégation" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="la-régression-réduction-de-lerreur-quadratique-moyenne-par-agrégation"><span class="header-section-number">1.2.1</span> La régression: réduction de l’erreur quadratique moyenne par agrégation</h3>
<p>Dans le contexte de la <strong>régression</strong>, l’objectif est de prédire une valeur numérique <span class="math inline">\(Y\)</span> à partir d’un vecteur de caractéristiques <span class="math inline">\(x\)</span>. Un modèle de régression <span class="math inline">\(\phi(x, L)\)</span> est construit à partir d’un ensemble d’apprentissage <span class="math inline">\(L\)</span>, et produit une estimation de <span class="math inline">\(Y\)</span> pour chaque observation <span class="math inline">\(x\)</span>.</p>
<section id="définition-du-prédicteur-agrégé" class="level4" data-number="1.2.1.1">
<h4 data-number="1.2.1.1" class="anchored" data-anchor-id="définition-du-prédicteur-agrégé"><span class="header-section-number">1.2.1.1</span> Définition du prédicteur agrégé</h4>
<p>Dans le cas de la régression, le <strong>prédicteur agrégé</strong> est défini comme suit :</p>
<p>$ _A(x) = E_L[(x, L)] $</p>
<p>où <span class="math inline">\(\phi_A(x)\)</span> représente la prédiction agrégée, <span class="math inline">\(E_L[.]\)</span> correspond à l’espérance prise sur tous les échantillons d’apprentissage possibles <span class="math inline">\(L\)</span>, chacun étant tiré selon la même distribution que le jeu de données initial, et <span class="math inline">\(\phi(x, L)\)</span> correspond à la prédiction du modèle construit sur l’échantillon d’apprentissage <span class="math inline">\(L\)</span>.</p>
</section>
<section id="la-décomposition-biais-variance" class="level4" data-number="1.2.1.2">
<h4 data-number="1.2.1.2" class="anchored" data-anchor-id="la-décomposition-biais-variance"><span class="header-section-number">1.2.1.2</span> La décomposition biais-variance</h4>
<p>Pour mieux comprendre comment l’agrégation améliore la performance globale d’un modèle individuel <span class="math inline">\(\phi(x, L)\)</span>, revenons à la <strong>décomposition biais-variance</strong> de l’erreur quadratique moyenne (il s’agit de la mesure de performance classiquement considérée dans un problème de régression):</p>
<p><span id="eq-decompo-biais-variance"><span class="math display">\[E_L[\left(Y - \phi(x, L)\right)^2] = \underbrace{\left(E_L\left[\phi(x, L) - Y\right]\right)^2}_{\text{Biais}^2} + \underbrace{E_L[\left(\phi(x, L) - E_L[\phi(x, L)]\right)^2]}_{\text{Variance}} \tag{1}\]</span></span></p>
<ul>
<li><p>Le <strong>biais</strong> est la différence entre la valeur observée <span class="math inline">\(Y\)</span> que l’on souhaite prédire et la prédiction moyenne <span class="math inline">\(E_L[\phi(x, L)]\)</span>. Si le modèle est sous-ajusté, le biais sera élevé.</p></li>
<li><p>La <strong>variance</strong> est la variabilité des prédictions (<span class="math inline">\(\phi(x, L)\)</span>) autour de leur moyenne (<span class="math inline">\(E_L[\phi(x, L)]\)</span>). Un modèle avec une variance élevée est très sensible aux fluctuations au sein des données d’entraînement: ses prédictions varient beaucoup lorsque les données d’entraînement se modifient.</p></li>
</ul>
<p>L’équation <a href="#eq-decompo-biais-variance" class="quarto-xref">1</a> illustre l’<strong>arbitrage biais-variance</strong> qui est omniprésent en <em>machine learning</em>: plus la complexité d’un modèle s’accroît (exemple: la profondeur d’un arbre), plus son biais sera plus faible (car ses prédictions seront de plus en plus proches des données d’entraînement), et plus sa variance sera élevée (car ses prédictions, étant très proches des données d’entraînement, auront tendance à varier fortement d’un jeu d’entraînement à l’autre).</p>
</section>
<section id="linégalité-de-breiman-1996" class="level4" data-number="1.2.1.3">
<h4 data-number="1.2.1.3" class="anchored" data-anchor-id="linégalité-de-breiman-1996"><span class="header-section-number">1.2.1.3</span> L’inégalité de Breiman (1996)</h4>
<p><span class="citation" data-cites="breiman1996bagging">Breiman (<a href="#ref-breiman1996bagging" role="doc-biblioref">1996</a>)</span> compare l’erreur quadratique moyenne d’un modèle individuel avec celle du modèle agrégé et démontre l’inégalité suivante :</p>
<!-- La démonstration s'appuie sur l'inégalité de Jensen appliquée au modèle agrégé: $E_L[\phi(x,L)^2]≥(E_L[\phi(x,L)])^2$.-->
<p>$ (Y - _A(x))^2 E_L[(Y - (x, L))^2] $ {#eq-inegalite-breiman1996}</p>
<ul>
<li><p>Le terme <span class="math inline">\((Y - \phi_A(x))^2\)</span> représente l’erreur quadratique du <strong>prédicteur agrégé</strong> <span class="math inline">\(\phi_A(x)\)</span>;</p></li>
<li><p>Le terme <span class="math inline">\(E_L[(Y - \phi(x, L))^2]\)</span> est l’erreur quadratique moyenne d’un <strong>prédicteur individuel</strong> <span class="math inline">\(\phi(x, L)\)</span> entraîné sur un échantillon aléatoire <span class="math inline">\(L\)</span>. Cette erreur varie en fonction des données d’entraînement.</p></li>
</ul>
<p>Cette inégalité montre que <strong>l’erreur quadratique moyenne du prédicteur agrégé est toujours inférieure ou égale à la moyenne des erreurs des prédicteurs individuels</strong>. Puisque le biais du prédicteur agrégé est identique au biais du prédicteur individuel, alors l’inégalité précédente implique que la <strong>variance du modèle agrégé</strong> <span class="math inline">\(\phi_A(x)\)</span> est <strong>toujours inférieure ou égale</strong> à la variance moyenne d’un modèle individuel :</p>
<p>$ (_A(x)) = (E_L[(x, L)]) E_L[((x, L))] $</p>
<p>Autrement dit, le processus d’agrégation réduit l’erreur de prédiction globale en réduisant la <strong>variance</strong> des prédictions, tout en conservant un biais constant.</p>
<p>Ce résultat ouvre la voie à des considérations pratiques immédiates. Lorsque le modèle individuel est instable et présente une variance élevée, l’inégalité <span class="math inline">\(Var(\phi_A(x)) \leq E_L[Var(\phi(x,L))]\)</span> est forte, ce qui signifie que l’agrégation peut améliorer significativement la performance globale du modèle. En revanche, si <span class="math inline">\(ϕ(x,L)\)</span> varie peu d’un ensemble d’entraînement à un autre (modèle stable avec variance faible), alors <span class="math inline">\(Var(\phi_A(x))\)</span> est proche de <span class="math inline">\(E_L[Var(\phi(x,L))]\)</span>, et la réduction de variance apportée par l’agrégation est faible. Ainsi, <strong>le <em>bagging</em> est particulièrement efficace pour les modèles instables</strong>, tels que les arbres de décision, mais moins efficace pour les modèles stables tels que les méthodes des k plus proches voisins.</p>
</section>
</section>
<section id="la-classification-vers-un-classificateur-presque-optimal-par-agrégation" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="la-classification-vers-un-classificateur-presque-optimal-par-agrégation"><span class="header-section-number">1.2.2</span> La classification: vers un classificateur presque optimal par agrégation</h3>
<p>Dans le cas de la classification, le mécanisme de réduction de la variance par le <em>bagging</em> permet, sous une certaine condition, d’atteindre un <strong>classificateur presque optimal</strong> (<em>nearly optimal classifier</em>). Ce concept a été introduit par <span class="citation" data-cites="breiman1996bagging">Breiman (<a href="#ref-breiman1996bagging" role="doc-biblioref">1996</a>)</span> pour décrire un modèle qui tend à classer une observation dans la classe la plus probable, avec une performance approchant celle du classificateur Bayésien optimal (la meilleure performance théorique qu’un modèle de classification puisse atteindre).</p>
<p>Pour comprendre ce résutlat, introduisons <span class="math inline">\(Q(j|x) = E_L(1_{φ(x, L) = j}) = P(φ(x, L) = j)\)</span>, la probabilité qu’un modèle <span class="math inline">\(φ(x, L)\)</span> prédise la classe <span class="math inline">\(j\)</span> pour l’observation <span class="math inline">\(x\)</span>, et <span class="math inline">\(P(j|x)\)</span>, la probabilité réelle (conditionnelle) que <span class="math inline">\(x\)</span> appartienne à la classe <span class="math inline">\(j\)</span>.</p>
<section id="définition-classificateur-order-correct" class="level4" data-number="1.2.2.1">
<h4 data-number="1.2.2.1" class="anchored" data-anchor-id="définition-classificateur-order-correct"><span class="header-section-number">1.2.2.1</span> Définition : classificateur order-correct</h4>
<p>Un classificateur <span class="math inline">\(φ(x, L)\)</span> est dit <strong>order-correct</strong> pour une observation <span class="math inline">\(x\)</span> si, en espérance, il identifie <strong>correctement la classe la plus probable</strong>, même s’il ne prédit pas toujours avec exactitude les probabilités associées à chaque classe <span class="math inline">\(Q(j∣x)\)</span>.</p>
<p>Cela signifie que si l’on considérait tous les ensemble de données possibles, et que l’on évaluait les prédictions du modèle en <span class="math inline">\(x\)</span>, la majorité des prédictions correspondraient à la classe à laquelle il a la plus grande probabilité vraie d’appartenir <span class="math inline">\(P(j∣x)\)</span>.</p>
<p>Formellement, un prédicteur est dit “order-correct” pour une entrée <span class="math inline">\(x\)</span> si :</p>
<p>$ argmax_j Q(j|x) = argmax_j P(j|x) $</p>
<p>où <span class="math inline">\(P(j|x)\)</span> est la vraie probabilité que l’observation <span class="math inline">\(x\)</span> appartienne à la classe <span class="math inline">\(j\)</span>, et <span class="math inline">\(Q(j|x)\)</span> est la probabilité que <span class="math inline">\(x\)</span> appartienne à la classe <span class="math inline">\(j\)</span> prédite par le modèle <span class="math inline">\(φ(x, L)\)</span>.</p>
<p>Un classificateur est <strong>order-correct</strong> si, pour <strong>chaque</strong> observation <span class="math inline">\(x\)</span>, la classe qu’il prédit correspond à celle qui a la probabilité maximale <span class="math inline">\(P(j|x)\)</span> dans la distribution vraie.</p>
</section>
<section id="prédicteur-agrégé-en-classification-le-vote-majoritaire" class="level4" data-number="1.2.2.2">
<h4 data-number="1.2.2.2" class="anchored" data-anchor-id="prédicteur-agrégé-en-classification-le-vote-majoritaire"><span class="header-section-number">1.2.2.2</span> Prédicteur agrégé en classification: le vote majoritaire</h4>
<p>Dans le cas de la classification, le prédicteur agrégé est défini par le <strong>vote majoritaire</strong>. Cela signifie que si <span class="math inline">\(K\)</span> classificateurs sont entraînés sur <span class="math inline">\(K\)</span> échantillons distincts, la classe prédite pour <span class="math inline">\(x\)</span> est celle qui reçoit <strong>le plus de votes</strong> de la part des modèles individuels.</p>
<p>Formellement, le classificateur agrégé <span class="math inline">\(φA(x)\)</span> est défini par :</p>
<p><span class="math inline">\(φA(x) =  \text{argmax}_j \sum_{L} I(\phi(x, L) = j) = argmax_j Q(j|x)\)</span></p>
</section>
<section id="performance-globale-convergence-vers-un-classificateur-presque-optimal" class="level4" data-number="1.2.2.3">
<h4 data-number="1.2.2.3" class="anchored" data-anchor-id="performance-globale-convergence-vers-un-classificateur-presque-optimal"><span class="header-section-number">1.2.2.3</span> Performance globale: convergence vers un classificateur presque optimal</h4>
<p><span class="citation" data-cites="breiman1996bagging">Breiman (<a href="#ref-breiman1996bagging" role="doc-biblioref">1996</a>)</span> montre que si chaque prédicteur individuel <span class="math inline">\(φ(x, L)\)</span> est order-correct pour une observation <span class="math inline">\(x\)</span>, alors le prédicteur agrégé <span class="math inline">\(φA(x)\)</span>, obtenu par <strong>vote majoritaire</strong>, atteint la performance optimale pour cette observation, c’est-à-dire qu’il converge vers la classe ayant la probabilité maximale <span class="math inline">\(P(j∣x)\)</span> pour l’observation <span class="math inline">\(x\)</span> lorsque le nombre de prédicteurs individuels augmente. Le vote majoritaire permet ainsi de <strong>réduire les erreurs aléatoires</strong> des classificateurs individuels.</p>
<p>Le classificateur agrégé <span class="math inline">\(ϕA\)</span> est optimal s’il prédit systématiquement la classe la plus probable pour l’observation <span class="math inline">\(x\)</span> dans toutes les régions de l’espace.</p>
<p>Cependant, dans les régions de l’espace où les classificateurs individuels ne sont pas order-corrects (c’est-à-dire qu’ils se trompent majoritairement sur la classe d’appartenance), l’agrégation par vote majoritaire n’améliore pas les performances. Elles peuvent même se détériorer par rapport aux modèles individuels si l’agrégation conduit à amplifier des erreurs systématiques (biais).</p>
</section>
</section>
</section>
<section id="léchantillage-par-bootstrap-peut-détériorer-les-performances-théoriques-du-modèle-agrégé" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="léchantillage-par-bootstrap-peut-détériorer-les-performances-théoriques-du-modèle-agrégé"><span class="header-section-number">1.3</span> L’échantillage par bootstrap peut détériorer les performances théoriques du modèle agrégé</h2>
<p>En pratique, au lieu d’utiliser tous les ensembles d’entraînement possibles <span class="math inline">\(L\)</span>, le <em>bagging</em> repose sur un nombre limité d’échantillons bootstrap tirés avec remise à partir d’un même jeu de données initial, ce qui peut introduire des biais par rapport au prédicteur agrégé théorique.</p>
<p>Les échantillons bootstrap présentent les limites suivantes :</p>
<ul>
<li><p>Une <strong>taille effective réduite par rapport au jeu de données initial</strong>: Bien que chaque échantillon bootstrap présente le même nombre d’observations que le jeu de données initial, environ 1/3 des observations (uniques) du jeu initial sont absentes de chaque échantillon bootstrap (du fait du tirage avec remise). Cela peut limiter la capacité des modèles à capturer des relations complexes au sein des données (et aboutir à des modèles individuels sous-ajustés par rapport à ce qui serait attendu théoriquement), en particulier lorsque l’échantillon initial est de taille modeste.</p></li>
<li><p>Une <strong>dépendance entre échantillons</strong> : Les échantillons bootstrap sont tirés dans le même jeu de données, ce qui génère une dépendance entre eux, qui réduit la diversité des modèles. Cela peut limiter l’efficacité de la réduction de variance dans le cas de la régression, voire acroître le biais dans le cas de la classification.</p></li>
<li><p>Une <strong>couverture incomplète de l’ensemble des échantillons possibles</strong>: Les échantillons bootstrap ne couvrent pas l’ensemble des échantillons d’entraînement possibles, ce qui peut introduire un biais supplémentaire par rapport au prédicteur agrégé théorique.</p></li>
</ul>
</section>
<section id="le-bagging-en-pratique" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="le-bagging-en-pratique"><span class="header-section-number">1.4</span> Le <em>bagging</em> en pratique</h2>
<section id="quand-utiliser-le-bagging-en-pratique" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="quand-utiliser-le-bagging-en-pratique"><span class="header-section-number">1.4.1</span> Quand utiliser le <em>bagging</em> en pratique</h3>
<p>Le <em>bagging</em> est particulièrement utile lorsque les modèles individuels présentent une variance élevée et sont instables. Dans de tels cas, l’agrégation des prédictions peut réduire significativement la variance globale, améliorant ainsi la performance du modèle agrégé. Les situations où le <em>bagging</em> est recommandé incluent typiquement:</p>
<ul>
<li><p>Les modèles instables : Les modèles tels que les arbres de décision non élagués, qui sont sensibles aux variations des données d’entraînement, bénéficient grandement du <em>bagging</em>. L’agrégation atténue les fluctuations des prédictions dues aux différents échantillons.</p></li>
<li><p>Les modèles avec biais faibles: En classification, si les modèles individuels sont order-corrects pour la majorité des observations, le <em>bagging</em> peut améliorer la précision en renforçant les prédictions correctes et en réduisant les erreurs aléatoires.</p></li>
</ul>
<p>Inversement, le <em>bagging</em> peut être moins efficace ou même néfaste dans certaines situations :</p>
<ul>
<li><p>Les modèles stables avec variance faible : Si les modèles individuels sont déjà stables et présentent une faible variance (par exemple, la régression linéaire), le <em>bagging</em> n’apporte que peu d’amélioration, car la réduction de variance supplémentaire est minimale.</p></li>
<li><p>La présence de biais élevée : Si les modèles individuels sont biaisés, entraînant des erreurs systématiques, le <em>bagging</em> peut amplifier ces erreurs plutôt que de les corriger. Dans de tels cas, il est préférable de s’attaquer d’abord au biais des modèles avant de considérer l’agrégation.</p></li>
<li><p>Les échantillons de petite taille : Avec des ensembles de données limités, les échantillons bootstrap peuvent ne pas être suffisamment diversifiés ou représentatifs, ce qui réduit l’efficacité du <em>bagging</em> et peut augmenter le biais des modèles.</p></li>
</ul>
<p><strong>Ce qui qu’il faut retenir</strong>: le <em>bagging</em> peut améliorer substantiellement la performance des modèles d’apprentissage automatique lorsqu’il est appliqué dans des conditions appropriées. Il est essentiel d’évaluer la variance et le biais des modèles individuels, ainsi que la taille et la représentativité du jeu de données, pour déterminer si le <em>bagging</em> est une stratégie adaptée. Lorsqu’il est utilisé judicieusement, le <em>bagging</em> peut conduire à des modèles plus robustes et précis, exploitant efficacement la puissance de l’agrégation pour améliorer la performance des modèles individuels.</p>
</section>
<section id="comment-utiliser-le-bagging-en-pratique" class="level3" data-number="1.4.2">
<h3 data-number="1.4.2" class="anchored" data-anchor-id="comment-utiliser-le-bagging-en-pratique"><span class="header-section-number">1.4.2</span> Comment utiliser le <em>bagging</em> en pratique</h3>
<section id="combien-de-modèles-agréger" class="level4" data-number="1.4.2.1">
<h4 data-number="1.4.2.1" class="anchored" data-anchor-id="combien-de-modèles-agréger"><span class="header-section-number">1.4.2.1</span> Combien de modèles agréger?</h4>
<p>“Optimal performance is often found by <em>bagging</em> 50–500 trees. Data sets that have a few strong predictors typically require less trees; whereas data sets with lots of noise or multiple strong predictors may need more. Using too many trees will not lead to overfitting. However, it’s important to realize that since multiple models are being run, the more iterations you perform the more computational and time requirements you will have. As these demands increase, performing k-fold CV can become computationally burdensome.”</p>
</section>
<section id="evaluation-du-modèle-cross-validation-et-échantillon-out-of-bag-oob" class="level4" data-number="1.4.2.2">
<h4 data-number="1.4.2.2" class="anchored" data-anchor-id="evaluation-du-modèle-cross-validation-et-échantillon-out-of-bag-oob"><span class="header-section-number">1.4.2.2</span> Evaluation du modèle: cross validation et échantillon Out-of-bag (OOB)</h4>
<p>“A benefit to creating ensembles via <em>bagging</em>, which is based on resampling with replacement, is that it can provide its own internal estimate of predictive performance with the out-of-bag (OOB) sample (see Section 2.4.2). The OOB sample can be used to test predictive performance and the results usually compare well compared to k-fold CV assuming your data set is sufficiently large (say n≥1,000). Consequently, as your data sets become larger and your <em>bagging</em> iterations increase, it is common to use the OOB error estimate as a proxy for predictive performance.”</p>
</section>
</section>
</section>
<section id="mise-en-pratique-exemple-avec-code" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="mise-en-pratique-exemple-avec-code"><span class="header-section-number">1.5</span> Mise en pratique (exemple avec code)</h2>
<p>Ou bien ne commencer les mises en pratique qu’avec les random forest ?</p>
</section>
<section id="interprétation" class="level2" data-number="1.6">




</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">1.6 Interprétation</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-breiman1996bagging" class="csl-entry" role="listitem">
Breiman, Leo. 1996. <span>“Bagging Predictors.”</span> <em>Machine Learning</em> 24: 123–40.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/github\.com\/inseefrlab\/DT_methodes_ensemblistes");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter2/1-CART.html" class="pagination-link" aria-label="Présentation formelle des algorithmes">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Présentation formelle des algorithmes</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter2/3-random_forest.html" class="pagination-link" aria-label="La forêt aléatoire">
        <span class="nav-page-text">La forêt aléatoire</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© CC-1.0</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/edit/main/chapters/chapter2/2-bagging.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/blob/main/chapters/chapter2/2-bagging.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>