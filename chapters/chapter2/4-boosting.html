<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>boosting – Introduction aux méthodes ensemblistes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter2/5-Sujets-avances.html" rel="next">
<link href="../../chapters/chapter2/3-random_forest.html" rel="prev">
<link href="../../images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ea167b1c95185128cea848f008f0cb8f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../custom.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter2/1-CART.html">Présentation formelle des algorithmes</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter2/4-boosting.html">Le <em>boosting</em></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Introduction aux méthodes ensemblistes</a> 
        <div class="sidebar-tools-main">
    <a href="../.././pdf/dt_methodes_ensemblistes.pdf" title="NMFS Open Science" class="quarto-navigation-tool px-1" aria-label="NMFS Open Science"><i class="bi bi-file-pdf-fill"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction aux méthodes ensemblistes</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter1/1-survol.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Survol des méthodes ensemblistes</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter2/1-CART.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Présentation formelle des algorithmes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/1-CART.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Les arbres de décision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/2-bagging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Le <em>bagging</em></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/3-random_forest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">La forêt aléatoire</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/4-boosting.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Le <em>boosting</em></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/5-Sujets-avances.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sujets avancés: traitement des données pendant l’entraînement</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter3/1-preparation_donnees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comment bien utiliser les algorithmes?</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/1-preparation_donnees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Préparation des données</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/2-guide_usage_RF.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guide d’usage des forêts aléatoires</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/3-guide_usage_GB.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guide d’usage du <em>gradient boosting</em></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#le-boosting" id="toc-le-boosting" class="nav-link active" data-scroll-target="#le-boosting"><span class="header-section-number">1</span> Le <em>boosting</em></a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">1.1</span> Introduction</a></li>
  <li><a href="#les-premières-approches-du-boosting" id="toc-les-premières-approches-du-boosting" class="nav-link" data-scroll-target="#les-premières-approches-du-boosting"><span class="header-section-number">1.2</span> Les premières approches du <em>boosting</em></a></li>
  <li><a href="#la-mécanique-du-gradient-boosting" id="toc-la-mécanique-du-gradient-boosting" class="nav-link" data-scroll-target="#la-mécanique-du-gradient-boosting"><span class="header-section-number">1.3</span> La mécanique du <em>gradient boosting</em></a></li>
  <li><a href="#sec-overfitting-gb" id="toc-sec-overfitting-gb" class="nav-link" data-scroll-target="#sec-overfitting-gb"><span class="header-section-number">1.4</span> Le grand ennemi du <em>gradient boosting</em>: le surajustement</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/edit/main/chapters/chapter2/4-boosting.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/blob/main/chapters/chapter2/4-boosting.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter2/1-CART.html">Présentation formelle des algorithmes</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter2/4-boosting.html">Le <em>boosting</em></a></li></ol></nav></header>




<section id="le-boosting" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="le-boosting"><span class="header-section-number">1</span> Le <em>boosting</em></h2>
<section id="introduction" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1.1</span> Introduction</h3>
<p>Le fondement théorique du <em>boosting</em> est un article de de 1990 (<span class="citation" data-cites="shapire1990strength">Shapire (<a href="#ref-shapire1990strength" role="doc-biblioref">1990</a>)</span>) qui a démontré théoriquement que, sous certaines conditions, il est possible de transformer un modèle prédictif peu performant en un modèle prédictif très performant. Plus précisément, cet article prouve que s’il est possible de construire un modèle simple dont les prédictions ne sont que légèrement meilleures que le hasard (appelé <em>weak learner</em>), alors il est possible de construire un modèle ayant un pouvoir prédictif arbitrairement élevé (appelé <em>strong learner</em>) en améliorant progressivement ce modèle simple. Le <em>boosting</em> est donc une méthode qui combine une approche ensembliste reposant sur un grand nombre de modèles simples avec un entraînement séquentiel: chaque modèle simple (souvent des arbres de décision peu profonds) tâche d’améliorer la prédiction globale en corrigeant les erreurs des prédictions précédentes à chaque étape. Bien qu’une approche de <em>boosting</em> puisse en théorie mobiliser différentes classes de <em>weak learners</em>, en pratique les <em>weak learners</em> utilisés par les algorithmes de <em>boosting</em> sont presque toujours des arbres de décision.</p>
<!-- S'il existe plusieurs variantes, tous les algorithmes de *boosting* suivent la même logique :

-   Un premier modèle simple et peu performant est entraîné sur les données.
-   Un deuxième modèle est entraîné de façon à corriger les erreurs du premier modèle (par exemple en pondérant davantage les observations mal prédites), puis combiné avec le premier modèle;
-   Ce processus est répété en ajoutant des modèles simples, chaque modèle corrigeant les erreurs commises par l'ensemble des modèles précédents;
-   Le modèle final est la combinaison de l'ensemble des modèles simples. -->
<p>En termes plus techniques, les différentes variantes du <em>boosting</em> partagent toutes trois caractéristiques communes:</p>
<ul>
<li><p>Ils visent à <strong>trouver une approximation</strong> <span class="math inline">\(\hat{F}\)</span> d’une fonction inconnue <span class="math inline">\(F^{\ast}: \mathbf{x} \mapsto y\)</span> à partir d’un ensemble d’entraînement <span class="math inline">\((y_i, \mathbf{x_i})_{i= 1,\dots,n}\)</span>;</p></li>
<li><p>Ils supposent que la fonction <span class="math inline">\(F^{\ast}\)</span> peut être approchée par une <strong>somme pondérée de modèles simples</strong> <span class="math inline">\(f\)</span> de paramètres <span class="math inline">\(\theta\)</span>: <span class="math display">\[ F\left(\mathbf{x}\right) = \sum_{m=1}^M \beta_m f\left(\mathbf{x}, \mathbf{\theta}_m\right) \]</span></p></li>
<li><p>Ils reposent sur une <strong>modélisation additive par étapes</strong> (<em>forward stagewise additive modeling</em>), qui décompose l’entraînement de ce modèle complexe en une <strong>séquence d’entraînements de petits modèles</strong>. Chaque étape de l’entraînement cherche le modèle simple <span class="math inline">\(f\)</span> qui améliore la puissance prédictive du modèle complet, sans modifier les modèles précédents, puis l’ajoute de façon incrémentale à ces derniers:</p></li>
</ul>
<p><span class="math display">\[ F_m(\mathbf{x}) = F_{m-1}(\mathbf{x}) + \hat{\beta}_m f(\mathbf{x}_i, \mathbf{\hat{\theta}_m}) \]</span></p>
<p>METTRE ICI UNE FIGURE EN UNE DIMENSION, avec des points et des modèles en escalier qui s’affinent.</p>
</section>
<section id="les-premières-approches-du-boosting" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="les-premières-approches-du-boosting"><span class="header-section-number">1.2</span> Les premières approches du <em>boosting</em></h3>
<section id="le-boosting-par-repondération-adaboost" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="le-boosting-par-repondération-adaboost"><span class="header-section-number">1.2.1</span> Le <em>boosting</em> par repondération: Adaboost</h4>
<p>Dans les années 1990, de nombreux travaux ont tâché de proposer des mise en application du <em>boosting</em> (<span class="citation" data-cites="breiman1998rejoinder">Breiman (<a href="#ref-breiman1998rejoinder" role="doc-biblioref">1998</a>)</span>, <span class="citation" data-cites="grove1998boosting">Grove and Schuurmans (<a href="#ref-grove1998boosting" role="doc-biblioref">1998</a>)</span>) et ont comparé les mérites des différentes approches. Deux approches ressortent particulièrement de cette littérature: Adaboost (Adaptive Boosting, <span class="citation" data-cites="freund1997decision">Freund and Schapire (<a href="#ref-freund1997decision" role="doc-biblioref">1997</a>)</span>) et la <em>Gradient Boosting Machine</em> (<span class="citation" data-cites="friedman2001greedy">Friedman (<a href="#ref-friedman2001greedy" role="doc-biblioref">2001</a>)</span>). Ces deux approches reposent sur des principes très différents.</p>
<p>Le principe d’Adaboost consiste à pondérer les erreurs commises à chaque itération en donnant plus d’importance aux observations mal prédites, de façon à obliger les modèles simples à se concentrer sur les observations les plus difficiles à prédire. Voici une esquisse du fonctionnement d’AdaBoost:</p>
<ul>
<li><p>Un premier modèle simple est entraîné sur un jeu d’entraînement dans lequel toutes les observations ont le même poids.</p></li>
<li><p>A l’issue de cette première itération, les observations mal prédites reçoivent une pondération plus élevée que les observations bien prédites, et un deuxième modèle est entraîné sur ce jeu d’entraînement pondéré.</p></li>
<li><p>Ce deuxième modèle est ajouté au premier, puis on repondère à nouveau les observations en fonction de la qualité de prédiction de ce nouveau modèle.</p></li>
<li><p>Cette procédure est répétée en ajoutant de nouveaux modèles et en ajustant les pondérations.</p></li>
</ul>
<p>L’algorithme Adaboost a été au coeur de la littérature sur le <em>boosting</em> à la fin des années 1990 et dans les années 2000, en raison de ses performances sur les problèmes de classification binaire. Il a toutefois été progressivement remplacé par les algorithmes de <em>gradient boosting</em> mis au point quelques années plus tard.</p>
</section>
<section id="linvention-du-boosting-boosting-la-gradient-boosting-machine" class="level4" data-number="1.2.2">
<h4 data-number="1.2.2" class="anchored" data-anchor-id="linvention-du-boosting-boosting-la-gradient-boosting-machine"><span class="header-section-number">1.2.2</span> L’invention du <em>boosting boosting</em> : la <em>Gradient Boosting Machine</em></h4>
<p>La <em>Gradient Boosting Machine</em> (GBM) propose une approche assez différente: elle introduit le <em>gradient boosting</em> en reformulant le <em>boosting</em> sous la forme d’un problème d’optimisation qui se résout par une approche itérative de descente de gradient. Cette approche repose entièrement sur la notion de <strong>fonction de perte</strong>, qui mesure l’écart entre la variable-cible et la prédiction du modèle. La mécanique de la <em>Gradient Boosting Machine</em> est présentée de façon formelle dans l’encadré ci-dessous; en voici une présentation intuitive:</p>
<!-- -   Un premier modèle simple est entraîné sur les données d'entraînement, de façon à minimiser une fonction de perte qui mesure l'écart entre la variable à prédire et la prédiction du modèle.
-   A l'issue de cette première itération, on calcule la dérivée partielle (*gradient*) de la fonction de perte par rapport à la prédiction en chaque point de l'ensemble d'entraînement. Ce gradient indique à la fois dans quelle direction et dans quelle ampleur la prédiction devrait être modifiée afin de réduire la perte.
-   A la deuxième itération, on ajoute un deuxième modèle qui va tâcher d'améliorer le modèle complet en prédisant le mieux possible l'opposé de ce gradient.
-   Ce deuxième modèle est ajouté au premier, puis on recalcule la dérivée partielle de la fonction de perte par rapport à la prédiction de ce nouveau modèle.
-   Cette procédure est répétée en ajoutant de nouveaux modèles et en recalculant le gradient à chaque étape.
-   La qualité du modèle final est évaluée sur un ensemble de test. -->
<ul>
<li><p>Le modèle global est <strong>initialisé</strong> à partir des données d’entraînement. A ce stade, le modèle prédit en général la moyenne de la variable-cible pour toutes les observations.</p></li>
<li><p>Première itération de <em>boosting</em>:</p>
<ul>
<li><p>On calcule la dérivée partielle (<em>gradient</em>) de la fonction de perte par rapport à la prédiction pour chaque observation de l’ensemble d’entraînement. Cette dérivée partielle est parfois appelée <strong>pseudo-résidu</strong>. L’opposé de ce gradient indique à la fois dans quelle direction et dans quelle ampleur la prédiction devrait être modifiée afin de réduire la perte (ou autrement dit afin de rapprocher la prédiction de la vraie valeur).</p></li>
<li><p>Un premier arbre est entraîné à prédire l’opposé du gradient de la fonction de perte.</p></li>
<li><p>Cet arbre est ajouté au modèle global (après multiplication par un facteur d’échelle).</p></li>
</ul></li>
<li><p>Deuxième itération de <em>boosting</em>: on calcule à nouveau la dérivée partielle de la fonction de perte par rapport aux nouvelles prédictions du modèle global, puis un deuxième arbre est entraîné à prédire l’opposé du gradient de la fonction de perte, et enfin cet arbre est ajouté au modèle global.</p></li>
<li><p>Cette procédure est répétée en ajoutant de nouveaux modèles et en recalculant le gradient à chaque étape.</p></li>
<li><p>La qualité du modèle final est évaluée sur un ensemble de test.</p></li>
</ul>
<p>L’approche de <em>gradient boosting</em> proposée par <span class="citation" data-cites="friedman2001greedy">Friedman (<a href="#ref-friedman2001greedy" role="doc-biblioref">2001</a>)</span> présente deux grands avantages. D’une part, <strong>toute la mécanique du <em>gradient boosting</em> est indépendante de la fonction de perte choisie et de la nature du problème modélisé</strong>. Cette approche peut donc être utilisée avec n’importe quelle fonction de perte différentiable, ce qui permet d’appliquer le <em>gradient boosting</em> à de multiples problèmes (régression, classification binaire ou multiclasse, <em>learning-to-rank</em>…). D’autre part, <strong>le <em>gradient boosting</em> offre souvent des performances comparables ou supérieures aux autres approches de <em>boosting</em></strong>. Le <em>gradient boosting</em> d’arbres de décision (<em>Gradient boosted Decision Trees</em> - GBDT) est donc devenue l’approche de référence en matière de <em>boosting</em>: toutes les implémentations modernes du <em>gradient boosting</em> comme <code>scikit-learn</code>, <code>XGBoost</code>, <code>LightGBM</code>, et <code>CatBoost</code> sont des extensions et améliorations de la <em>Gradient Boosting Machine</em>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Présentation formelle de la <em>Gradient Boosting Machine</em>
</div>
</div>
<div class="callout-body-container callout-body">
<p>On dispose d’un jeu de données <span class="math inline">\({(x_i, y_i)}_{i=1}^n\)</span> avec <span class="math inline">\(x_i \in \mathbb{R}^m\)</span> et une cible <span class="math inline">\(y_i\)</span>. On définit une fonction de perte <span class="math inline">\(l\)</span> qui mesure la distance entre la prédiction <span class="math inline">\(\hat{y}\)</span> et la vraie valeur <span class="math inline">\(y\)</span>. Elle présente généralement les propriétés suivantes: elle est convexe et dérivable deux fois, et atteint son minimum lorsque <span class="math inline">\(\hat{y} = y\)</span>. On veut entraîner un modèle comprenant <span class="math inline">\(m\)</span> arbres, chacun étant défini par les paramètres <span class="math inline">\(\mathbf{a_m}\)</span> (règles de décision et valeurs des feuilles terminales):</p>
<p><span class="math display">\[ \hat{y}_{i} =F\left(\mathbf{x}_i\right) = \sum_{k=1}^{K} f_k\left(\mathbf{x}_i\right) \]</span></p>
<p>Procédure de construction du modèle:</p>
<ol type="1">
<li><p>Initialiser le modèle avec <span class="math inline">\(F_0\left(\mathbf{x}\right) = f_0\left(\mathbf{x}\right) = \frac{1}{n}\sum_{i=1}^n y_i\)</span>.</p></li>
<li><p>Pour <span class="math inline">\(m = 1, \dots, M:\)</span></p>
<ol type="a">
<li><p>Calculer le gradient (les pseudo-résidus) à l’issue des <span class="math inline">\(m-1\)</span> étapes précédentes: <span class="math inline">\(g_{im} = \frac{\partial l(y_i, F_{m-1}\left(\mathbf{x}\right))}{\partial F_{m-1}\left(\mathbf{x}\right)}\)</span></p></li>
<li><p>Entraîner le <span class="math inline">\(m\)</span>-ième <em>weak learner</em>: on cherche l’arbre <span class="math inline">\(f_m\)</span> qui prédit le mieux l’opposé du gradient de la fonction de perte: <span class="math inline">\(\mathbf{\hat{f}_m} = \underset{f_m}{\arg \min} \sum_{i=1}^n \left(- g_{im} - f_m\left(\mathbf{x}_i\right)\right)^2\)</span></p></li>
<li><p>Mettre à jour le modèle global: <span class="math inline">\(F_m\left(\mathbf{x}_i\right) = F_{m-1}\left(\mathbf{x}_i\right) + \rho f_m\left(\mathbf{x}_i\right)\)</span> avec <span class="math inline">\(\rho\)</span> le taux d’apprentissage (<em>learning rate</em>) dont la raison d’être est présentée dans la section <a href="#sec-overfitting-gb" class="quarto-xref">Section&nbsp;1.4</a>.</p></li>
</ol></li>
</ol>
</div>
</div>
</section>
</section>
<section id="la-mécanique-du-gradient-boosting" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="la-mécanique-du-gradient-boosting"><span class="header-section-number">1.3</span> La mécanique du <em>gradient boosting</em></h3>
<p>La méthode de <em>gradient boosting</em> proposée <span class="citation" data-cites="friedman2001greedy">Friedman (<a href="#ref-friedman2001greedy" role="doc-biblioref">2001</a>)</span> a fait l’objet de multiples implémentations, parmi lesquelles <code>XGBoost</code> (<span class="citation" data-cites="chen2016xgboost">Chen and Guestrin (<a href="#ref-chen2016xgboost" role="doc-biblioref">2016</a>)</span>), <code>LightGBM</code> (<span class="citation" data-cites="ke2017lightgbm">Ke et al. (<a href="#ref-ke2017lightgbm" role="doc-biblioref">2017</a>)</span>), <code>CatBoost</code> (<span class="citation" data-cites="prokhorenkova2018catboost">Prokhorenkova et al. (<a href="#ref-prokhorenkova2018catboost" role="doc-biblioref">2018</a>)</span>) et <code>scikit-learn</code>. Ces implémentations sont proches les unes des autres, et ne diffèrent que sur des points relativement mineurs. En revanche, elles s’éloignent quelque peu de la formulation initiale de la <em>Gradient Boosting Machine</em>, afin d’optimiser la construction des arbres. Bien comprendre la mécanique interne de ces implémentations s’avère important en pratique, notamment pour appréhender le rôle des multiples hyperparamètres. Cette section présente donc la mécanique d’ensemble de ces implémentations, en s’appuyant sur l’implémentation proposée par XBGoost.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<section id="le-modèle-à-entraîner" class="level4" data-number="1.3.1">
<h4 data-number="1.3.1" class="anchored" data-anchor-id="le-modèle-à-entraîner"><span class="header-section-number">1.3.1</span> Le modèle à entraîner</h4>
<p>On dispose d’un jeu de données <span class="math inline">\({(x_i, y_i)}_{i=1}^n\)</span> avec <span class="math inline">\(x_i \in \mathbb{R}^m\)</span> et une cible <span class="math inline">\(y_i\)</span>. On veut entraîner un modèle global qui soit une somme de <span class="math inline">\(K\)</span> arbres de régression ou de classification: <span class="math inline">\(\hat{y}_i = F\left(\mathbf{x}_i\right) = \sum_{k=1}^K f_k(x_i)\)</span>. On rappelle que chaque arbre <span class="math inline">\(f\)</span> est défini par trois paramètres:</p>
<ul>
<li><p>sa <strong>structure</strong> qui est une fonction <span class="math inline">\(q: \mathbb{R}^m \rightarrow \{1, \dots, T\}\)</span> qui à un vecteur <span class="math inline">\(\mathbf{x}\)</span> de dimension <span class="math inline">\(m\)</span> associe une feuille terminale de l’arbre;cette structure est définie par l’ensemble des règles de décision de l’arbre;</p></li>
<li><p>son <strong>nombre de feuilles terminales</strong> <span class="math inline">\(T\)</span>;</p></li>
<li><p>les <strong>prédictions</strong> figurant sur ses feuilles terminales <span class="math inline">\(\mathbf{w}\in \mathbb{R}^T\)</span> (appelées poids ou <em>weights</em>).</p></li>
</ul>
<p>Le modèle complet est impossible à entraîner en une seule fois, car c’est un problème trop complexe. Le principe du <em>boosting</em> consiste donc à construire le modèle complet de façon itérative, par <strong>ajout successif d’arbres</strong>. À l’itération <span class="math inline">\(t\)</span>, on ajoute un nouvel arbre <span class="math inline">\(f_t\)</span> pour améliorer la prédiction actuelle <span class="math inline">\(\hat{y}_i^{(t-1)}\)</span>. Le modèle devient: <span class="math display">\[
\hat{y}_i^{(t)} = \hat{y}_i^{(t-1)} + f_t(x_i).
\]</span></p>
<p>L’objectif de l’itération <span class="math inline">\(t\)</span> est donc de trouver le nouvel arbre <span class="math inline">\(f_t(x_i)\)</span> qui minimise la fonction-objectif. Pour éviter le sur-ajustement, l’algorithme <code>XGBoost</code> utilise une fonction-objectif qui comporte à la fois une fonction de perte, et un terme de régularisation:</p>
<p><span id="eq-fct-obj-initial"><span class="math display">\[ L^{(t)} = \underbrace{\sum_{i=1}^n \ell\left(y_i,\;\hat{y}_i^{(t-1)} + f_t(x_i)\right)}_{\substack{\text{Perte sur les} \\ \text{observations}}} + \underbrace{\sum_k \Omega(f_{k})}_{\substack{\text{Fonction de} \\ \text{régularisation}}}\,\,\text{avec}\,\,\Omega(f) = \gamma T + \frac{1}{2} \lambda \sum_{k=1}^K \sum_{j=1}^{T_k} w_j^2
\tag{1}\]</span></span></p>
<p>Dans cette expression:</p>
<ul>
<li><p>La fonction de perte <span class="math inline">\(\ell\)</span> mesure la distance entre la prédiction <span class="math inline">\(\hat{y}\)</span> et la vraie valeur <span class="math inline">\(y\)</span> (exemples: erreur quadratique moyenne, erreur absolue moyenne, perte d’entropie croisée binaire, etc.).</p></li>
<li><p>Le terme de régularisation <span class="math inline">\(\Omega(f)\)</span> pénalise la complexité de l’arbre <span class="math inline">\(f\)</span> via deux termes: le terme <span class="math inline">\(\gamma\,T\)</span> pénalise les arbres avec un grand nombre de feuilles (<span class="math inline">\(T\)</span> élevé) et le terme <span class="math inline">\(\tfrac{1}{2} \lambda\sum_{j=1}^{T_t} w_j^2\)</span> pénalise les arbres avec des poids élevés (<span class="math inline">\(w_j\)</span> élevés en valeur absolue). Cette pénalisation privilégie les arbres plus « simples » (moins de feuilles, poids de feuilles plus petits) afin d’éviter le sur-ajustement (<em>overfitting</em>). <span class="math inline">\(\gamma\)</span> et <span class="math inline">\(\lambda\)</span> sont des hyperparamètres de régularisation qui contrôlent la complexité de l’arbre.</p></li>
</ul>
</section>
<section id="principe-de-lentraînement-du-modèle" class="level4" data-number="1.3.2">
<h4 data-number="1.3.2" class="anchored" data-anchor-id="principe-de-lentraînement-du-modèle"><span class="header-section-number">1.3.2</span> Principe de l’entraînement du modèle</h4>
<p>A chaque étape de l’entraînement, l’algorithme de <em>gradient boosting</em> ajoute un nouvel arbre au modèle en faisant deux choses: <strong>déterminer la structure</strong> de l’arbre en tenant compte de la régularisation (c’est-à-dire choisir les règles de décision qui définissent l’arbre) et <strong>calculer la meilleure valeur <span class="math inline">\(w_j\)</span>​</strong> pour chaque feuille terminale (c’est-à-dire la valeur qui <strong>minimise</strong> la fonction de perte).</p>
<p>La construction de l’arbre se fait selon une approche <strong>gloutonne</strong>, <em>nœud après nœud</em>, de façon très similaire à la construction d’un arbre CART (voir section <strong>?@sec-CART</strong>): on divise les données d’entraînement en sous-régions de plus en plus petites, tant que cela génère une réduction “suffisante” de la fonction de perte. Une différence notable avec les arbres CART et les forêts aléatoires est que les arbres utilisés dans le <em>gradient boosting</em> sont souvent relativement simples et peu profonds. Ainsi, le partitionnement récursif des données s’arrête généralement assez tôt, soit lorsqu’est atteinte une des limites de complexité définies <em>a priori</em> (<strong>profondeur maximale</strong> de l’arbre, <strong>nombre maximal de feuilles</strong>, <strong>nombre minimal d’observations par feuille</strong>), soit lorsque l’algorithme ne parvient plus à trouver de partitionnement intéressant (c’est-à-dire qui permette de réduire suffisamment la perte).</p>
<!-- 
: on divise les données d'entraînement en sous-régions de plus en plus petites, tant que cela génère une réduction "suffisante" de la fonction de perte. Cette approche peut être résumée ainsi:

1. On part du noeud-racine qui contient toutes les données d'entraînement.

2. Pour ce noeud, on essaie de trouver un partitionnement optimal:

    - On teste toutes les règles de décision possibles, en faisant une boucle sur toutes les variables, et sur les différents seuils possibles.

    - Pour chaque règle de décision candidate, on calcule le **gain** associé (c'est-à-dire la réduction de la perte globale si l'on retient cette règle de décision), et on retient la règle de décision avec le gain maximal.

    - On utilise la règle de décision optimale pour créer deux noeuds-enfants dans lesquels les observations sont réparties.

3. On répète le processus récursivement en partant des noeuds nouvellement créés, jusqu'à :

    - soit atteindre les limites de complexité définies _a priori_ (**profondeur maximale** de l'arbre, **nombre maximal de feuilles**, **nombre minimal d'observations par feuille**);

    - soit ne plus trouver de partitionnement intéressant (c'est-à-dire qui permette de réduire suffisamment la perte). -->
</section>
<section id="détail-de-lentraînement-du-modèle" class="level4" data-number="1.3.3">
<h4 data-number="1.3.3" class="anchored" data-anchor-id="détail-de-lentraînement-du-modèle"><span class="header-section-number">1.3.3</span> Détail de l’entraînement du modèle</h4>
<p>Les paragraphes qui suivent détaillent le processus de construction du <span class="math inline">\(t\)</span>-ième arbre, et les équations utilisées dans ce processus.</p>
<section id="étape-1-faire-apparaître-le-gradient-de-la-fonction-de-perte" class="level5" data-number="1.3.3.1">
<h5 data-number="1.3.3.1" class="anchored" data-anchor-id="étape-1-faire-apparaître-le-gradient-de-la-fonction-de-perte"><span class="header-section-number">1.3.3.1</span> Étape 1: Faire apparaître le gradient de la fonction de perte</h5>
<p>On souhaite construire le <span class="math inline">\(t\)</span>-ième arbre qui minimise la perte, conditionnellement aux données et aux <span class="math inline">\(t-1\)</span> arbres déjà construits. Formellement on cherche la fonction <span class="math inline">\(f_t\)</span> telle que</p>
<p><span class="math inline">\(\hat{f}_t = \arg\min_{f} L^{(t)} = \arg\min_{f} \sum_{i=1}^n \ell\left(y_i,\;\hat{y}_i^{(t-1)} + f_t(x_i)\right) + \sum_k \Omega(f_{k})\)</span></p>
<p>Pour simplifier la construction de ce <span class="math inline">\(t\)</span>-ième arbre, <code>XGBoost</code> utilise une <strong>approximation de second ordre</strong> de la fonction de perte <span class="math inline">\(L^{(t)}\)</span>. Plus précisément, on fait un développement limité d’ordre 2 de <span class="math inline">\(l(y_i, \hat{y}_{i}^{(t-1)} + f_{t}(\mathbf{x}_i))\)</span> au voisinage de <span class="math inline">\(\hat{y}_{i}^{(t-1)}\)</span>, en considérant que la prédiction du <span class="math inline">\(t\)</span>-ième arbre <span class="math inline">\(f_{t}(\mathbf{x}_i)\)</span> est un incrément de petite taille:</p>
<p><span class="math display">\[ \mathcal{L}^{(t)} \approx \sum_{i=1}^{n} [\underbrace{l(y_i, \hat{y}_{i}^{(t-1)})}_{\text{(A)}} + g_i f_t(\mathbf{x}_i)+ \frac{1}{2} h_i f^2_t(\mathbf{x}_i)] + \underbrace{\sum_{j=1}^{t-1}\Omega(f_j)}_{\text{(B)}} + \Omega(f_t) \]</span></p>
<p>avec</p>
<p><span class="math display">\[ g_i = \frac{\partial l(y_i, \hat{y}_i^{(t-1)})}{\partial\hat{y}_i^{(t-1)}} \;\;\text{et}\;\; h_i = \frac{\partial^2 l(y_i, \hat{y}_i^{(t-1)})}{{\partial \hat{y}_i^{(t-1)}}^2} \]</span></p>
<p>Les termes <span class="math inline">\(g_i\)</span> et <span class="math inline">\(h_i\)</span> désignent respectivement la dérivée première (le gradient) et la dérivée seconde (la hessienne) de la fonction de perte par rapport à la variable prédite pour l’observation <span class="math inline">\(i\)</span>. Dans cette équation, les termes (A) et (B) sont constants car ils ne dépendent que des <span class="math inline">\(t-1\)</span> arbres précédents qui ont déjà été entraînés et qui ne sont pas modifiés par l’entraînement du <span class="math inline">\(t\)</span>-ième arbre. <!-- Autrement dit, la seule façon d'améliorer le modèle sera de trouver un $t$-ième arbre $f_t$ qui minimise la fonction-objectif \mathcal{L}^{(t)} ainsi réécrite.  --> On peut donc retirer ces termes pour obtenir la fonction-objectif simplifiée <span class="math inline">\(\tilde{L}^{(t)}\)</span> qui sera utilisée pour l’entraînement du <span class="math inline">\(t\)</span>-ième arbre:</p>
<p><span id="eq-fct-obj-final"><span class="math display">\[ \tilde{\mathcal{L}}^{(t)} = \sum_{i=1}^{n} [g_i f_t(\mathbf{x}_i)+ \frac{1}{2} h_i [f_t(\mathbf{x}_i)]^2] + \Omega(f_t)
\tag{2}\]</span></span></p>
<p>Deux remarques:</p>
<ul>
<li><p>Cette expression montre que le problème initial où il fallait entraîner un grand nombre d’arbres simultanément (équation <a href="#eq-fct-obj-initial" class="quarto-xref">1</a>) à un problème beaucoup plus simple dans lequel il n’y a plus qu’un seul arbre à entraîner (équation <a href="#eq-fct-obj-final" class="quarto-xref">2</a>).</p></li>
<li><p>A COMPLETER: il ne reste que g et h, cadre général applicable à tout problème.</p></li>
</ul>
</section>
</section>
<section id="étape-2-calculer-les-poids-optimaux-conditionnellement-à-la-structure-de-larbre" class="level4" data-number="1.3.4">
<h4 data-number="1.3.4" class="anchored" data-anchor-id="étape-2-calculer-les-poids-optimaux-conditionnellement-à-la-structure-de-larbre"><span class="header-section-number">1.3.4</span> Étape 2: calculer les poids optimaux conditionnellement à la structure de l’arbre</h4>
<p>A partir de l’équation <a href="#eq-fct-obj-final" class="quarto-xref">2</a>, il est possible de faire apparaître les poids <span class="math inline">\(w_j\)</span> du <span class="math inline">\(t\)</span>-ième arbre. Chaque arbre <span class="math inline">\(f_t\)</span> peut être vu comme une fonction constante par morceaux du type <span class="math inline">\(f_t(x) = w_{\,q(x)}\)</span> où <span class="math inline">\(q(x)\)</span> est une fonction qui assigne un indice de feuille (un entier entre 1 et <span class="math inline">\(T\)</span>) à chaque observation <span class="math inline">\(x\)</span>, et <span class="math inline">\(w_j\)</span> est le poids (valeur de sortie) de la <span class="math inline">\(j\)</span>-ième feuille. En regroupant les observations <span class="math inline">\(i\)</span> tombant dans la feuille <span class="math inline">\(j\)</span> dans l’ensemble <span class="math inline">\(I_j = \{i\mid q(x_i)=j\}\)</span>, la fonction de perte approchée peut être réécrite sous la forme:</p>
<p><span class="math display">\[
\begin{align*}
\tilde{L}^{(t)} =&amp;   \sum_{j=1}^{T} \sum_{i\in I_{j}} \bigg[g_i f_t(\mathbf{x}_i)\phantom{\frac{1}{2}} &amp;+ \frac{1}{2} h_i [f_t(\mathbf{x}_i)]^2\bigg]&amp;+ \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_i^2 \\
     &amp;= \sum_{j=1}^{T} \sum_{i\in I_{j}} \bigg[g_i w_j &amp;+ \frac{1}{2} h_i w_j^2\bigg] &amp;+ \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_i^2 \\
     &amp;= \sum^T_{j=1} \bigg[w_j\sum_{i\in I_{j}} g_i &amp;+ \frac{1}{2} w_j^2 \left( \sum_{i \in I_{j}} h_i + \lambda \right) \bigg] &amp;+ \gamma T
\end{align*}
\]</span></p>
<p>Dans la dernière expression, la fonction de perte simplifiée se reformule comme une combinaison quadratique des poids <span class="math inline">\(w_j\)</span>, dans laquelle les dérivées première et seconde de la fonction de perte interviennent sous forme de pondérations (<span class="math inline">\(\sum_{i \in I_j} g_i\)</span> et <span class="math inline">\(\sum_{i \in I_j} h_i\)</span>). Cette expression peut elle-même s’écrire comme la somme sur l’ensemble des feuilles de la fonction de perte relative à chaque feuille <span class="math inline">\(j\)</span> : <span class="math display">\[
\tilde{L}^{(t)} = \sum_{j=1}^T k(w_j) + \gamma\,T
\]</span></p>
<p>avec <span class="math inline">\(k(w_j)\)</span> la perte relative à la feuille <span class="math inline">\(j\)</span> : <span class="math display">\[
k(w_j) = \sum_{i \in I_j} \bigl(g_i\,w_j + \tfrac12\,h_i\,w_j^2\bigr) + \tfrac12\,\lambda w_j^2
\]</span></p>
<p>Pour un arbre de structure donnée, la valeur optimale <span class="math inline">\(w_j^{\ast}\)</span> de la feuille <span class="math inline">\(j\)</span>, c’est-à-dire la valeur qui minimise la contribution de la feuille à la fonction de perte globale se calcule facilement (en résolvant pour chaque feuille <span class="math inline">\(j\)</span> la condition du premier ordre <span class="math inline">\(\frac{\partial k}{\partial w_j} = 0\)</span>):</p>
<p><span id="eq-w-j-optimal"><span class="math display">\[
w_j^{\ast} = -\frac{\sum_{i \in I_j} g_i}{\sum_{i \in I_j} h_i + \lambda}
\tag{3}\]</span></span></p>
<p>On déduit alors, pour une structure d’arbre <span class="math inline">\(q\)</span> donnée, la valeur optimale de la fonction-objectif pour le <span class="math inline">\(t\)</span>-ième arbre:</p>
<p><span id="eq-fct-obj-optimal"><span class="math display">\[
\tilde{L}^{(t)}(q) = -\,\tfrac12 \sum_{j=1}^T \frac{\bigl(\sum_{i \in I_j} g_i\bigr)^2}{\sum_{i \in I_j} h_i + \lambda} + \gamma\,T
\tag{4}\]</span></span></p>
<p>L’équation <a href="#eq-fct-obj-optimal" class="quarto-xref">4</a> est utile en pratique car elle permet de comparer la qualité de deux arbres candidats, et de déterminer immédiatement lequel est le meilleur. On pourrait même penser que cette équation est à elle seule suffisante pour choisir le <span class="math inline">\(t\)</span>-ième arbre: il suffirait d’énumérer les arbres possibles, de calculer la qualité de chacun d’entre eux, et de retenir le meilleur. En réalité, cette approche est inemployable en pratique car le nombre d’arbres possibles est extrêmement élevé. Par conséquent, cette équation n’est pas utilisée telle quelle, mais sert à comparer les règles de décision possibles à chaque étape d’une optimisation gloutonne, de façon à trouver la structure <span class="math inline">\(q^\ast\)</span> du <span class="math inline">\(t\)</span>-ième arbre.</p>
<section id="étape-3-déterminer-la-structure-de-larbre" class="level5" data-number="1.3.4.1">
<h5 data-number="1.3.4.1" class="anchored" data-anchor-id="étape-3-déterminer-la-structure-de-larbre"><span class="header-section-number">1.3.4.1</span> Étape 3: déterminer la structure de l’arbre</h5>
<p>La méthode de construction des arbres dans les algorithmes de <em>gradient boosting</em> est très similaire à celle décrite dans la partie sur les arbres de décision: le <span class="math inline">\(t\)</span>-ième arbre n’est pas défini en une fois, mais construit de façon gloutonne (<em>greedy</em>). On part du noeud-racine qui contient toutes les données d’entraînement, et à chaque étape on partitionne les noeuds de l’arbre en choisissant la règle de décision qui maximise la réduction de la perte. Le processus est réitéré jusqu’à ce que <strong>l’arbre atteigne un critère d’arrêt</strong>, ou jusqu’à ce que <strong>plus aucune scission ne permette de réduire la fonction de perte</strong>.</p>
<p>La grande différence avec les arbres CART et les forêts aléatoires est que ces algorithmes utilisent l’équation <a href="#eq-fct-obj-optimal" class="quarto-xref">4</a> pour choisir la règle de décision (<em>split</em>) à chaque étape de la construction de l’arbre, et non une mesure d’impureté. Pour chaque noeud, l’algorithme de détermination des règles de décision (<em>split finding algorithm</em>) consiste en une double boucle sur les variables et les valeurs prises par ces variables, qui énumère un grand nombre de règles de décision possibles et mesure le gain associé à chacun d’entre elles avec l’équation <a href="#eq-fct-eval-split" class="quarto-xref">5</a>. La règle de décision retenue sera simplement celui dont le gain est le plus élevé.</p>
<p>Plus précisément, la réduction de perte associée au partitionnement de la feuille <span class="math inline">\(I\)</span> en deux feuilles gauche (<span class="math inline">\(I_L\)</span>) et droite (<span class="math inline">\(I_R\)</span>) à l’aide d’une certaine règle de décision s’écrit (à partir de l’équation <a href="#eq-fct-obj-optimal" class="quarto-xref">4</a>): <span id="eq-fct-eval-split"><span class="math display">\[
\Delta \tilde{L}^{(t)} = \tfrac12 \bigl[
    \underbrace{\frac{\bigl(\sum_{i \in I_L} g_i\bigr)^2}{\sum_{i \in I_L} h_i + \lambda}}_{\text{Perte de la feuille gauche}} +
    \underbrace{\frac{\bigl(\sum_{i \in I_R} g_i\bigr)^2}{\sum_{i \in I_R} h_i + \lambda}}_{\text{Perte de la feuille droite}} -
    \underbrace{\frac{\bigl(\sum_{i \in I} g_i\bigr)^2}{\sum_{i \in I} h_i + \lambda}}_{\text{Perte de la feuille d'origine}}
\bigr]
- \gamma
\tag{5}\]</span></span></p>
<p>La réduction de perte permise par le partitionnement est simplement la différence entre la somme des pertes après partitionnement (feuille gauche + feuille droite) et l’ancienne perte avant partitionnement. Le terme <span class="math inline">\(\gamma\)</span> est le terme de régularisation qui mesure le coût associé à la création d’une feuille supplémentaire. Si <span class="math inline">\(\Delta \tilde{L}^{(t)}\)</span> est <strong>positive</strong> et suffisamment grande, alors la scission fait <strong>baisser</strong> la perte globale et on la retient. Sinon, on renonce à scinder cette feuille.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>L’algorithme de détermination des règles de décision est le composant le plus intense en calcul des algorithmes de <em>gradient boosting</em>. Les différentes implémentations du <em>gradient boosting</em> proposent donc de multiples améliorations et optimisations visant à le rendre le plus efficace possible. Certaines de ces optimisations sont présentées dans la partie LIEN A LA PARTIE HISTOGRAMME/CATVAR.</p>
</div>
</div>
</section>
<section id="etape-4-ajouter-des-arbres-jusquà-atteindre-un-critère-darrêt" class="level5" data-number="1.3.4.2">
<h5 data-number="1.3.4.2" class="anchored" data-anchor-id="etape-4-ajouter-des-arbres-jusquà-atteindre-un-critère-darrêt"><span class="header-section-number">1.3.4.2</span> Etape 4: Ajouter des arbres jusqu’à atteindre un critère d’arrêt</h5>
<p>Une fois que la structure du <span class="math inline">\(t\)</span>-ième arbre a été définie et que les valeurs de chaque feuille ont été calculées, cet arbre est ajouté au modèle global, et la prédiction est mise à jour par la formule suivante:</p>
<p><span id="eq-update-model"><span class="math display">\[ F_{t}(x)=F_{t-1}(x)+ \eta f_{t}(x)  \tag{6}\]</span></span></p>
<p>Puis les valeurs des gradients et hessiennes sont mises à jour pour chaque observation par les formules</p>
<p><span class="math display">\[ g_i = \frac{\partial l(y_i, \hat{y}_i^{(t)})}{\partial\hat{y}_i^{(t)}} \;\;\text{et}\;\; h_i = \frac{\partial^2 l(y_i, \hat{y}_i^{(t)})}{{\partial \hat{y}_i^{(t)}}^2} \]</span></p>
<p>Il est alors possible de commencer l’entraînement de l’arbre suivant, selon la même logique que précédemment. Le processus de construction des arbres se poursuit jusqu’à atteindre soit le nombre maximum d’arbres autorisé dans le modèle (<span class="math inline">\(K\)</span>), soit un autre <strong>critère d’arrêt</strong> (par exemple, une réduction de perte minimale par arbre).</p>
</section>
</section>
</section>
<section id="sec-overfitting-gb" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="sec-overfitting-gb"><span class="header-section-number">1.4</span> Le grand ennemi du <em>gradient boosting</em>: le surajustement</h3>
<p>Une différence majeure entre les forêts aléatoires et les algorithmes de <em>boosting</em> est que ces derniers ne contiennent en eux-mêmes aucune limite au surajustement, bien au contraire: le <em>gradient boosting</em> est un algorithme conçu pour approximer le plus précisément possible la relation entre <span class="math inline">\(X\)</span> et <span class="math inline">\(y\)</span> telle qu’elle apparaît dans les données d’entraînement, qu’il s’agisse d’un signal pertinent ou d’un bruit statistique. Par conséquent, <strong>tous les algorithmes de <em>gradient boosting</em> sont très vulnérables au surajustement</strong>. Plus précisément, il y a deux raisons à cela. D’une part, lors de l’entraînement d’un modèle de <em>gradient boosting</em>, chaque nouvel arbre essaie de réduire l’erreur résiduelle en s’ajustant toujours plus finement aux données. Ainsi, au fur et mesure que le nombre d’arbres augmente, l’algorithme capture non seulement des relations pertinentes entre <span class="math inline">\(X\)</span> et <span class="math inline">\(y\)</span>, mais aussi le bruit et les particularités aléatoires de l’échantillon d’entraînement. D’autre part, les arbres de décision utilisés sont très flexibles et conçus pour refléter les relations entre <span class="math inline">\(X\)</span> et <span class="math inline">\(y\)</span> présentes dans les données d’entraînement, y compris celles qui ne se généralisent pas bien aux nouvelles données. Par exemple, un arbre très profond peut correspondre finement aux données d’entraînement, mais risque de manquer de robustesse sur les données de test.</p>
<p><strong>La lutte contre le surajustement est donc un enjeu majeur de l’entraînement des modèles de <em>gradient boosting</em>.</strong> De multiples méthodes ont été proposées pour lutter contre le surajustement:</p>
<ul>
<li><p>la <strong>technique de réduction</strong> (<em>shrinkage technique</em>) consiste à réduire l’influence de chaque arbre sur le modèle global en multipliant la prédiction de cet arbre par un facteur d’échelle compris entre 0 et 1 au moment de mettre à jour le modèle par l’équation <a href="#eq-update-model" class="quarto-xref">6</a>. Ce facteur d’échelle est appelé <strong>taux d’apprentissage</strong> (<em>learning rate</em>); il s’agit du paramètre <span class="math inline">\(\eta\)</span> dans l’équation <a href="#eq-update-model" class="quarto-xref">6</a>. L’avantage principal de cette technique est que le modèle s’ajuste progressivement aux données, et est moins altéré par les erreurs dues à des variations aléatoires ou au bruit dans les données. Un taux d’apprentissage bas et un nombre d’itérations suffisant permettent souvent d’obtenir un modèle final plus performant sur des données de test. L’inconvénient est que réduire le taux d’apprentissage nécessite d’augmenter le nombre d’itérations pour obtenir des performances comparables, ce qui peut rallonger le temps d’entraînement.</p></li>
<li><p>l’<strong>hyperparamètre de régularisation <span class="math inline">\(\lambda\)</span></strong> intervient dans l’équation <a href="#eq-w-j-optimal" class="quarto-xref">3</a> et réduit la valeur absolue des poids des feuilles terminales. Cet hyperparamètre contribue à ce que chaque arbre prédise des valeurs peu élevées. L’intuition est la suivante: lorsqu’une feuille terminale contient un poids <span class="math inline">\(w_i\)</span> élevé en valeur absolue, ce poids est probablement dû au moins en partie à des observations inhabituelles ou aberrantes (et dont le gradient <span class="math inline">\(g_i\)</span> prend une valeur extrême); il est donc préférable de réduire légèrement ce poids pour ne pas donner trop d’importance à ces points aberrants.</p></li>
<li><p>l’<strong>hyperparamètre de régularisation <span class="math inline">\(\gamma\)</span></strong> intervient dans l’équation <a href="#eq-fct-eval-split" class="quarto-xref">5</a>. Ce paramètre mesure la réduction minimale de la perte requise pour qu’un nœud soit divisé; une valeur plus élevée aboutit à des arbres moins profonds et contribue à limiter le surajustement en empêchant l’algorithme de créer des <em>splits</em> dont l’apport est très faible et potentiellement dû à des variations non significatives des données d’entraînement.</p></li>
<li><p>la dernière approche consiste à <strong>entraîner les arbres sur un échantillon d’observations et/ou de variables</strong>. L’échantillonnage des observations permet de réduire l’influence des éventuels points extrêmes contenus dans les données (car ils n’apparaissent pas dans les données d’entraînement de certains arbres); l’échantillonnage des variables permet de varier les variables utilisées dans les <em>splits</em>.</p></li>
</ul>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-breiman1998rejoinder" class="csl-entry" role="listitem">
Breiman, Leo. 1998. <span>“Rejoinder: Arcing Classifiers.”</span> <em>The Annals of Statistics</em> 26 (3): 841–49.
</div>
<div id="ref-chen2016xgboost" class="csl-entry" role="listitem">
Chen, Tianqi, and Carlos Guestrin. 2016. <span>“Xgboost: A Scalable Tree Boosting System.”</span> In <em>Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 785–94.
</div>
<div id="ref-freund1997decision" class="csl-entry" role="listitem">
Freund, Yoav, and Robert E Schapire. 1997. <span>“A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting.”</span> <em>Journal of Computer and System Sciences</em> 55 (1): 119–39.
</div>
<div id="ref-friedman2001greedy" class="csl-entry" role="listitem">
Friedman, Jerome H. 2001. <span>“Greedy Function Approximation: A Gradient Boosting Machine.”</span> <em>Annals of Statistics</em>, 1189–1232.
</div>
<div id="ref-grove1998boosting" class="csl-entry" role="listitem">
Grove, Adam J, and Dale Schuurmans. 1998. <span>“Boosting in the Limit: Maximizing the Margin of Learned Ensembles.”</span> In <em>AAAI/IAAI</em>, 692–99.
</div>
<div id="ref-ke2017lightgbm" class="csl-entry" role="listitem">
Ke, Guolin, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. <span>“Lightgbm: A Highly Efficient Gradient Boosting Decision Tree.”</span> <em>Advances in Neural Information Processing Systems</em> 30.
</div>
<div id="ref-prokhorenkova2018catboost" class="csl-entry" role="listitem">
Prokhorenkova, Liudmila, Gleb Gusev, Aleksandr Vorobev, Anna Veronika Dorogush, and Andrey Gulin. 2018. <span>“CatBoost: Unbiased Boosting with Categorical Features.”</span> <em>Advances in Neural Information Processing Systems</em> 31.
</div>
<div id="ref-shapire1990strength" class="csl-entry" role="listitem">
Shapire, R. 1990. <span>“The Strength of Weak Learning.”</span> <em>Machine Learning</em> 5 (2).
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Cette partie reprend la structure et les notations de la partie 2 de <span class="citation" data-cites="chen2016xgboost">Chen and Guestrin (<a href="#ref-chen2016xgboost" role="doc-biblioref">2016</a>)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/github\.com\/inseefrlab\/DT_methodes_ensemblistes");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter2/3-random_forest.html" class="pagination-link" aria-label="La forêt aléatoire">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">La forêt aléatoire</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter2/5-Sujets-avances.html" class="pagination-link" aria-label="Sujets avancés: traitement des données pendant l'entraînement">
        <span class="nav-page-text">Sujets avancés: traitement des données pendant l’entraînement</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© CC-1.0</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/edit/main/chapters/chapter2/4-boosting.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/blob/main/chapters/chapter2/4-boosting.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>