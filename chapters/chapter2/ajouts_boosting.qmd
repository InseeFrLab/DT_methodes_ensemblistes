### Sujets avancés

#### Remarques diverses

Choses importantes à mettre en avant:

-   Le _boosting_ est fondamentalement différent des forêts aléatoires. See ESL, chapitre 10.
-   La mécanique du _gradient boosting_ est entièrement indépendante de la nature du problème considéré (régression, classification, classement...) et de la fonction de perte choisie[^lossfunction]. L'approche de _gradient boosting_ est donc particulièrement flexible et peut être adaptée à des problèmes variés.

[^lossfunction]: la fonction de perte doit uniquement vérifier quelques conditions mathématiques peu contraignantes en pratique.

-   A la différence des forêts aléatoires, l'approche de _gradient boosting_ ne contient en elle-même aucune limite au surapprentissage, bien au contraire: le _gradient boosting_ est un algorithme conçu pour approximer le plus précisément possible la relation entre $X$ et $y$ telle qu'elle apparaît dans les données d'entraînement, qu'il s'agisse d'un signal pertinent ou d'un bruit statistique, ce qui le rend particulièrement vulnérable au surapprentissage. Par conséquent, la lutte contre l'_overfitting_ est un élément essentiel de l'usage des algorithmes de _gradient boosting_.

-   Les termes de régularisation sont directement intégrées à la mécanique du _gradient boosting_.

Interprétation intuitive: $\gamma$ est le gain minimal nécessaire pour diviser un noeud.

-   Comment on interprète le gradient et la hessienne: cas avec une fonction de perte quadratique.

### Les optimisations de l'entraînement

#### Le traitement des variables continues: l'utilisation des histogrammes

__L'algorithme de détermination des critères de partition (_split-finding algorithm_) est un enjeu de performance essentiel dans les méthodes ensemblistes.__ En effet, l'algorithme le plus simple qui consiste à énumérer tous les critères de partition possibles (en balayant toutes les valeurs de toutes les variables) s'avère très coûteux à utiliser dès lors que les données contiennent soit un grand nombre de variables, soit des variables continues prenant un grand nombre de valeurs. C'est pourquoi cet algorithme a fait l'objet de multiples améliorations et optimisations visant à réduire leur coût computationnel sans dégrader la qualité des critères de partition.

L'utilisation d'histogrammes (_histogram-based algorithms_) est une approche efficace qui permet de réduire de manière significative le coût computationnel lié à la recherche des _splits_ optimaux en discrétisant les variables continues. Elle est proposée par toutes les implémentations courantes du _gradient boosting_ (XGBoost, LightGBM, CatBoost et scikit-learn). Elle comprend deux caractéristiques principales:

- __Discrétisation__: avant le début de l'entraînement, chaque variable continue est discrétisée en un nombre limité d'intervalles (_bins_), construits le plus souvent à partir de ses quantiles. Ce processus est appelé *binning*. Par exemple, une variable continue uniformément distribuée de 0 à 100 peut être divisée en dix intervalles ($[0, 10), [10, 20), \dots, [90, 100)$). Le nombre maximal de _bins_ est un hyperparamètre qui peut parfois jouer un rôle important.
<!-- - __Construction de l'histogramme__: après la discrétisation, un histogramme est construit pour chaque variable continue; il résume combien d'observations appartiennent à chaque _bin_, ainsi que la somme des gradients et la somme des hessiennes de ces observations (il s'agit des quantités $\sum_{i \in \text{bin}} g_i$ et $\sum_{i \in \text{bin}} h_i$ mentionnées dans l'équation @eq-w-j-optimal. -->
- __Énumération restreinte__: l'algorithme de détermination des critères de partition ne considère que les bornes des intervalles précédemment définies (10, 20, 30, etc. dans l'exemple précédent) et non l'ensemble des valeurs prises par les variables continues. Cette modification se traduit par une nette accélération de l'entraînement, dans la mesure où le nombre de _bins_ est en général beaucoup plus faible que le nombre de valeurs uniques des variables continues.
<!-- - __Mise à jour de l'histogramme__: G et H sont mis à jour après chaque arbre. -->

#### Le traitement des variables catégorielles: une diversité d'approches

Les variables catégorielles, c'est compliqué. Quatre approches possibles. 

Les trois premières sont des approches d'encodage, qui visent à transformer les variables catégorielles en variables numériques et qui ne sont pas spécifiques aux méthodes ensemblistes à base d'arbres:

- Le **_one-hot encoding_** consiste à transformer une variable catégorielle en une série de variables binaires qui représentent chacune une modalité de la variable; pour chaque observation, seule la colonne correspondant à la modalité de la variable catégorielle aura la valeur 1, et toutes les autres auront la valeur 0. Cette approche permet de représenter des catégories de manière numérique de façon très simple et sans leur attribuer un ordre. Toutefois, le _one-hot encoding_ augmente fortement la dimensionnalité des données (ce qui ralentit l'entraînement et augmente les besoins en mémoire), et est inutilisable lorsque les variables catégorielles présentent un nombre de modalités[^note_OHE].

- L'**_ordinal encoding_** consiste à attribuer un entier unique à chaque modalité d'une variable catégorielle. Par exemple, la catégorie "Sans diplôme" sera encodée par la valeur 0, la catégorie "Baccalauréat ou moins" sera encodée par 1, etc. Simple à mettre en œuvre, cette approche permet de remplacer la variable catégorielle par une unique variable numérique et est donc utile pour traiter les variables présentant un grand nombre de modalités, pour lesquelles le _one-hot encoding_ est impraticable. Elle est particulièrement adaptée aux variables catégorielles qui sont naturellement ordonnées (exemples: niveau de diplôme, catégorie d'âge, étage d'un appartement...). En revanche, cette approche est peu adaptée aux variables non ordonnées (exemples: secteur d'activité, département, pays...) car elle introduit un ordre fictif qui peut perturber les modèles qui interprètent les entiers comme des valeurs ordonnées.

- Le **_target encoding_** consiste à remplacer chaque modalité d'une variable catégorielle par la moyenne de la variable cible pour cette modalité. Comme l'_ordinal encoding_, cette approche permet d'obtenir une unique variable numérique et est donc utile pour traiter les variables présentant un grand nombre de modalités. Par ailleurs, le _target encoding_ fonctionne bien avec la méthode des histogrammes décrite précédemment, dans la mesure où les valeurs encodées sont par construction ordonnées en fonction de leur association avec la variable cible. Toutefois, le _target encoding_ étant sujet au surapprentissage, il est important de l'utiliser en lissant la moyenne ou en recourant à une validation croisée. Cette approche est notamment proposée par CatBoost[^note_catboost] et par scikit-learn[^note_scikit].

La dernière approche est spécifique aux algorithmes de _gradient boosting_

support natif des variables catégorielles (_native support for categorical features_)


Cette approche a été introduite par [LightGBM](https://lightgbm.readthedocs.io/en/latest/Features.html#optimal-split-for-categorical-features), puis reprise par [XGBoost](https://xgboost.readthedocs.io/en/latest/tutorials/categorical.html) et [scikit-learn](https://scikit-learn.org/stable/modules/ensemble.html#categorical-features-support).


@fisher1958grouping

Fisher 1958.


[^note_OHE] Il est bien sûr possible de n'encoder que les modalités les plus fréquentes, et de regrouper toutes les autres dans une seule variable binaire.
[^note_catboost] Le _target encoding_ utilisé par CatBoost est présenté en détail dans @prokhorenkova2018catboost et sur ce [billet de blog](https://blog.dataiku.com/how-do-gradient-boosting-algorithms-handle-categorical-variables).
[^note_scikit] Voir cet [exemple](https://scikit-learn.org/dev/auto_examples/preprocessing/plot_target_encoder.html#sphx-glr-auto-examples-preprocessing-plot-target-encoder-py) dans la documentation de scikit-learn.





# Le Shrinkage en Apprentissage Automatique

Le **shrinkage** (ou **réduction** en français) est une technique utilisée dans l'apprentissage automatique, en particulier dans des algorithmes comme le gradient boosting, pour réduire la complexité du modèle et améliorer sa généralisation. En termes simples, le shrinkage consiste à appliquer un facteur de réduction aux mises à jour des paramètres à chaque itération.

## Explication du Shrinkage dans le Contexte du Gradient Boosting

### 1. But
Dans les méthodes de boosting, à chaque itération, un nouveau modèle (souvent un arbre de décision) est ajouté pour corriger les erreurs du modèle précédent. Le shrinkage permet de réduire l'impact de chaque nouvel arbre ajouté, ce qui peut aider à éviter le sur-apprentissage (overfitting) en ralentissant l'ajustement du modèle aux données d'entraînement.

### 2. Comment ça fonctionne
- Après chaque itération, au lieu d'ajouter directement le nouvel arbre au modèle existant, on applique un facteur de réduction \( \eta \) (souvent appelé taux d'apprentissage ou **learning rate**) qui détermine l'ampleur de l'ajustement du modèle.
- Par exemple, si l'arbre nouvellement appris améliore la prédiction de \( \Delta f(x) \), au lieu de l'ajouter directement à la prédiction, on ajoute \( \eta \times \Delta f(x) \), où \( \eta \) est un petit nombre (généralement entre 0 et 1).

### 3. Avantages
- **Réduction du sur-apprentissage** : En limitant l'impact de chaque arbre, le shrinkage aide à éviter que le modèle s'ajuste trop précisément aux bruits ou aux fluctuations des données d'entraînement.
- **Amélioration de la généralisation** : Bien qu'il ralentisse l'entraînement, le shrinkage améliore souvent les performances du modèle sur des données de test (généralisation).

### 4. Inconvénients
- **Temps d'entraînement plus long** : En raison de la réduction de l'impact de chaque arbre, il peut être nécessaire de former plus d'arbres pour atteindre une performance similaire à celle d'un modèle sans shrinkage.

## Conclusion
En résumé, le shrinkage dans le contexte du gradient boosting consiste à appliquer un facteur de réduction à chaque nouvel arbre pour modérer ses effets sur le modèle final, afin d'améliorer la stabilité et la capacité de généralisation du modèle.