<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>random_forest – Introduction aux méthodes ensemblistes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter2/4-boosting.html" rel="next">
<link href="../../chapters/chapter2/2-bagging.html" rel="prev">
<link href="../../images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ea167b1c95185128cea848f008f0cb8f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../custom.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter2/1-CART.html">Présentation formelle des algorithmes</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter2/3-random_forest.html">La forêt aléatoire</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Introduction aux méthodes ensemblistes</a> 
        <div class="sidebar-tools-main">
    <a href="../.././pdf/dt_methodes_ensemblistes.pdf" title="NMFS Open Science" class="quarto-navigation-tool px-1" aria-label="NMFS Open Science"><i class="bi bi-file-pdf-fill"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction aux méthodes ensemblistes</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Survol des méthodes ensemblistes</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter2/1-CART.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Présentation formelle des algorithmes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/1-CART.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Les arbres de décision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/2-bagging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Le <em>bagging</em></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/3-random_forest.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">La forêt aléatoire</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/4-boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Le <em>boosting</em></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/ajouts_boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sujets avancés</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/chapter3/1-preparation_donnees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comment bien utiliser les algorithmes?</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/1-preparation_donnees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Préparation des données</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/2-guide_usage_RF.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guide d’usage des forêts aléatoires</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/3-guide_usage_GB.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guide d’usage du <em>gradient boosting</em></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-rf-detail" id="toc-sec-rf-detail" class="nav-link active" data-scroll-target="#sec-rf-detail"><span class="header-section-number">1</span> La forêt aléatoire</a>
  <ul class="collapse">
  <li><a href="#principe-de-la-forêt-aléatoire" id="toc-principe-de-la-forêt-aléatoire" class="nav-link" data-scroll-target="#principe-de-la-forêt-aléatoire"><span class="header-section-number">1.1</span> Principe de la forêt aléatoire</a></li>
  <li><a href="#comment-construit-on-une-forêt-aléatoire" id="toc-comment-construit-on-une-forêt-aléatoire" class="nav-link" data-scroll-target="#comment-construit-on-une-forêt-aléatoire"><span class="header-section-number">1.2</span> Comment construit-on une forêt aléatoire?</a></li>
  <li><a href="#pourquoi-les-forêts-aléatoires-sont-elles-performantes" id="toc-pourquoi-les-forêts-aléatoires-sont-elles-performantes" class="nav-link" data-scroll-target="#pourquoi-les-forêts-aléatoires-sont-elles-performantes"><span class="header-section-number">1.3</span> Pourquoi les forêts aléatoires sont-elles performantes?</a>
  <ul class="collapse">
  <li><a href="#réduction-de-la-variance-par-agrégation" id="toc-réduction-de-la-variance-par-agrégation" class="nav-link" data-scroll-target="#réduction-de-la-variance-par-agrégation"><span class="header-section-number">1.3.1</span> Réduction de la variance par agrégation</a></li>
  <li><a href="#convergence-et-limite-théorique-au-surapprentissage" id="toc-convergence-et-limite-théorique-au-surapprentissage" class="nav-link" data-scroll-target="#convergence-et-limite-théorique-au-surapprentissage"><span class="header-section-number">1.3.2</span> Convergence et limite théorique au surapprentissage</a></li>
  <li><a href="#sec-facteur-perf-rf" id="toc-sec-facteur-perf-rf" class="nav-link" data-scroll-target="#sec-facteur-perf-rf"><span class="header-section-number">1.3.3</span> Facteurs influençant l’erreur de généralisation</a></li>
  </ul></li>
  <li><a href="#sec-rf-oob" id="toc-sec-rf-oob" class="nav-link" data-scroll-target="#sec-rf-oob"><span class="header-section-number">1.4</span> Evaluation des performances par l’erreur <em>Out-of-Bag</em> (OOB)</a></li>
  <li><a href="#interprétation-et-importance-des-variables" id="toc-interprétation-et-importance-des-variables" class="nav-link" data-scroll-target="#interprétation-et-importance-des-variables"><span class="header-section-number">1.5</span> Interprétation et importance des variables</a>
  <ul class="collapse">
  <li><a href="#mesures-dimportance-classiques-et-leurs-biais" id="toc-mesures-dimportance-classiques-et-leurs-biais" class="nav-link" data-scroll-target="#mesures-dimportance-classiques-et-leurs-biais"><span class="header-section-number">1.5.1</span> Mesures d’importance classiques (et leurs biais)</a></li>
  <li><a href="#méthodes-dimportance-avancées" id="toc-méthodes-dimportance-avancées" class="nav-link" data-scroll-target="#méthodes-dimportance-avancées"><span class="header-section-number">1.5.2</span> Méthodes d’importance avancées</a></li>
  </ul></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/edit/main/chapters/chapter2/3-random_forest.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/blob/main/chapters/chapter2/3-random_forest.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter2/1-CART.html">Présentation formelle des algorithmes</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter2/3-random_forest.html">La forêt aléatoire</a></li></ol></nav></header>




<section id="sec-rf-detail" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> La forêt aléatoire</h1>
<p>La forêt aléatoire (<em>random forests</em>) est une méthode ensembliste puissante, largement utilisée pour les tâches de classification et de régression. Elle combine la simplicité des arbres de décision et l’échantillonnage des observations et des variables avec la puissance de l’agrégation pour améliorer les performances prédictives et réduire le risque de surapprentissage (<em>overfitting</em>).</p>
<!-- 
Objectifs: 

- comprendre le principe et les propriétés fondamentales des forêts aléatoires afin de comprendre comment elles améliorent les performances des modèles; 

- Apprendre les étapes de construction d'une forêt aléatoire : échantillonnage bootstrap, sélection de variables, partitions, prédiction, évaluation, interprétation

- Optimiser les performances du modèle: savoir préparer les données adéquatement, ajuster les hyperparamètres et comprendre les implications théoriques de ces choix.
 -->
<section id="principe-de-la-forêt-aléatoire" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="principe-de-la-forêt-aléatoire"><span class="header-section-number">1.1</span> Principe de la forêt aléatoire</h2>
<p>La forêt aléatoire est une extension du <em>bagging</em>, présenté dans la section <strong>?@sec-bagging-detail</strong>. Elle introduit un niveau supplémentaire de randomisation dans la construction des arbres, puisqu’à chaque nouvelle division (<em>noeud</em>), le critère de séparation est choisi en considérant uniquement un sous-ensemble de variables <strong>sélectionné aléatoirement</strong>. Cette randomisation supplémentaire <strong>réduit la corrélation</strong> entre les arbres, ce qui permet de diminuer la variance des prédiction du modèle agrégé.</p>
<p>Les forêts aléatoires reposent sur quatre éléments essentiels:</p>
<ul>
<li><p><strong>Les arbres CART</strong>: Les modèles élémentaires sont des arbres CART non élagués, c’est-à-dire autorisés à pousser jusqu’à l’atteinte d’un critère d’arrêt défini en amont.</p></li>
<li><p><strong>L’échantillonnage <em>bootstrap</em></strong>: Chaque arbre est construit à partir d’un échantillon aléatoire du jeu de données d’entraînement tiré avec remise (ou parfois sans remise).</p></li>
<li><p><strong>La sélection aléatoire de variables</strong> : Lors de la construction d’un arbre, à chaque nœud de celui-ci, un sous-ensemble aléatoire de variables est sélectionné. La meilleure division est ensuite choisie parmi ces caractéristiques aléatoires.</p></li>
<li><p><strong>L’agrégation des prédictions</strong> : Comme pour le <em>bagging</em>, les prédictions de tous les arbres sont combinées. On procède généralement à la moyenne (ou à la médiane) des prédictions dans le cas de la régression, et au vote majoritaire (ou à la moyenne des probabilités prédites pour chaque classe) dans le cas de la classification.</p></li>
</ul>
</section>
<section id="comment-construit-on-une-forêt-aléatoire" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="comment-construit-on-une-forêt-aléatoire"><span class="header-section-number">1.2</span> Comment construit-on une forêt aléatoire?</h2>
<p>L’entraînement d’une forêt aléatoire est très similaire à celui du <em>bagging</em> et se résume comme suit:</p>
<ul>
<li>Le nombre d’arbres à construire est défini <em>a priori</em>.</li>
<li>Pour chaque arbre, on effectue les étapes suivantes:
<ul>
<li>Générer un échantillon <em>bootstrap</em> de taille fixe à partir des données d’entraînement.</li>
<li>Construire récursivement un arbre de décision à partir de cet échantillon:
<ul>
<li>À chaque nœud de l’arbre, un sous-ensemble de <em>features</em> est sélectionné aléatoirement.</li>
<li>Déterminer quel couple (variable, valeur) définit la règle de décision qui divise la population du nœud en deux sous-groupes les plus homogènes possibles.</li>
<li>Créer les deux nœuds-enfants à partir de cette règle de décision.</li>
<li>Arrêter la croissance de l’arbre selon des critères d’arrêt fixés <em>a priori</em>.</li>
</ul></li>
</ul></li>
</ul>
<p>Pour construire la prédiction de la forêt aléatoire une fois celle-ci entraînée, on agrège les arbres selon une méthode qui dépend du problème modélisé:</p>
<ul>
<li>Régression: la prédiction finale est la moyenne des prédictions de tous les arbres.</li>
<li>Classification: chaque arbre vote pour une classe, et la classe majoritaire est retenue.</li>
</ul>
<p>Les principaux hyper-paramètres des forêts aléatoires (détaillés dans la section <strong>?@sec-guide-rf</strong>) sont les suivants: le nombre d’arbres, la méthode et le taux d’échantillonnage, le nombre (ou la proportion) de variables considérées à chaque nœud, le critère de division des nœuds (ou mesure d’hétérogénéité), et les critères d’arrêt (notamment la profondeur de l’arbre, le nombre minimal d’observations dans une feuille terminale, et le nombre minimal d’observations qu’un nœud doit comprendre pour être divisé en deux).</p>
<!-- ::: {.content-visible unless-format="html"}
```{=typst}
#import "@preview/lovelace:0.3.0": *
#align(center, pseudocode-list(
  title: text(weight: "bold")[Pseudocode de l'entraînement d'une forêt aléatoire],
  booktabs: true,
  line-numbering: none,
  indentation: 0em, 
  line-gap: 0.3em
  )[
  + *for* 1 to `n_trees`
    + Tirer un échantillon aléatoire de taille `n`.
    + Construire un arbre CART à partir de cet échantillon, en répétant récursivement les étapes suivantes jusqu'à ce que chaque feuille terminale ne puisse plus être divisée:
      + Sélectionner aléatoirement `mtry` variables;
      + Déterminer quel couple (variable, valeur) définit la règle de décision qui définit les deux sous-groupes les plus homogènes possibles;
      + Diviser le noeud considéré en deux noeuds-enfants.
  + *end*
]
)


// #import "@preview/algo:0.3.4": algo, i, d, comment, code

// #set table(
//   fill: white,
// )

// #algo(
//   title: [                    // note that title and parameters
//     #set text(size: 15pt)     // can be content
//     #emph(smallcaps("Fib"))
//   ],
//   line-numbers: false,
//   strong-keywords: false,
//   parameters: ([#math.italic("n")],),
//   comment-prefix: [#sym.triangle.stroked.r ],
//   comment-styles: (fill: rgb(100%, 0%, 0%)),
//   indent-size: 15pt,
//   indent-guides: 1pt + gray,
//   row-gutter: 5pt,
//   column-gutter: 5pt,
//   inset: 5pt,
//   stroke: 2pt + black,
//   fill: white

// )[
//   if $n < 0$:#i\
//     return null#d\
//   if $n = 0$ or $n = 1$:#i\
//     return $n$#d\
//   \
//   let $x <- 0$\
//   let $y <- 1$\
//   for $i <- 2$ to $n-1$:#i #comment[so dynamic!]\
//     let $z <- x+y$\
//     $x <- y$\
//     $y <- z$#d\
//     \
//   return $x+y$
// ]

// #set table(
//   fill: (_, y) => if calc.odd(y) { rgb("EAF2F5") },
// )

```
::: -->
</section>
<section id="pourquoi-les-forêts-aléatoires-sont-elles-performantes" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="pourquoi-les-forêts-aléatoires-sont-elles-performantes"><span class="header-section-number">1.3</span> Pourquoi les forêts aléatoires sont-elles performantes?</h2>
<p>Les propriétés théoriques des forêts aléatoires permettent de comprendre pourquoi (et dans quelles situations) elles sont particulièrement robustes et performantes.</p>
<section id="réduction-de-la-variance-par-agrégation" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="réduction-de-la-variance-par-agrégation"><span class="header-section-number">1.3.1</span> Réduction de la variance par agrégation</h3>
<p>L’agrégation de plusieurs arbres permet de réduire la variance globale du modèle, ce qui améliore la stabilité des prédictions. Lorsque les estimateurs sont (faiblement) biaisés mais caractérisés par une variance élevée, l’agrégation permet d’obtenir un estimateur avec un biais similaire mais une variance réduite. La démonstration est identique à celle présentée dans la section <strong>?@sec-bagging-detail</strong>.</p>
</section>
<section id="convergence-et-limite-théorique-au-surapprentissage" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="convergence-et-limite-théorique-au-surapprentissage"><span class="header-section-number">1.3.2</span> Convergence et limite théorique au surapprentissage</h3>
<p>Bien qu’elle s’avèrent très performantes en pratique, <strong>il n’est pas prouvé à ce stade que les forêts aléatoires convergent vers une solution optimale</strong> lorsque la taille de l’échantillon tend vers l’infini (<span class="citation" data-cites="louppe2014understanding">Louppe (<a href="#ref-louppe2014understanding" role="doc-biblioref">2014</a>)</span>). Plusieurs travaux théoriques ont toutefois fourni des preuves de convergence pour des versions simplifiées de l’algorithme (par exemple, <span class="citation" data-cites="biau2012analysis">Biau (<a href="#ref-biau2012analysis" role="doc-biblioref">2012</a>)</span>).</p>
<p>Par ailleurs, une propriété importante des forêts aléatoires démontrée par <span class="citation" data-cites="breiman2001random">Breiman (<a href="#ref-breiman2001random" role="doc-biblioref">2001</a>)</span> est que leur erreur de généralisation, c’est-à-dire l’écart entre les prédictions du modèle et les résultats attendus sur des données jamais vues (donc hors de l’échantillon d’entraînement), diminue à mesure que le nombre d’arbres augmente et converge vers une valeur constante. Autrement dit, <strong>la forêt aléatoire ne souffre pas d’un surapprentissage croissant avec le nombre d’arbres</strong>. La conséquence pratique de ce résultat est qu’inclure un (trop) grand nombre d’arbres dans le modèle n’en dégrade pas la qualité, ce qui contribue à la rendre particulièrement robuste. En revanche, une forêt aléatoire peut souffrir de surapprentissage si ses autres hyperparamètres sont mal choisis (des arbres trop profonds par exemple).</p>
</section>
<section id="sec-facteur-perf-rf" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="sec-facteur-perf-rf"><span class="header-section-number">1.3.3</span> Facteurs influençant l’erreur de généralisation</h3>
<p>L’erreur de généralisation des forêts aléatoires est influencée par deux facteurs principaux :</p>
<ul>
<li><p><strong>La puissance prédictrice des arbres individuels</strong> : Les arbres doivent être suffisamment prédictifs pour contribuer positivement à l’ensemble, et idéalement sans biais.</p></li>
<li><p><strong>La corrélation entre les arbres</strong> : Moins les arbres sont corrélés, plus la variance de l’ensemble est réduite, car leurs erreurs tendront à se compenser. Inversement, des arbres fortement corrélés auront tendance à faire des erreurs similaires, donc agréger un grand nombre d’arbres n’apportera pas grand chose.</p></li>
</ul>
<p>On peut mettre en évidence ces deux facteurs dans le cas d’une forêt aléatoire utilisée pour une tâche de régression (où l’objectif est de minimiser l’erreur quadratique moyenne). Dans ce cas, la variance de la prédiction du modèle peut être décomposée de la façon suivante:</p>
<p><span class="math display">\[
\text{Var}(\hat{f}(x)) = \rho(x) \sigma(x)^2 + \frac{1 - \rho(x)}{M} \sigma(x)^2
\]</span></p>
<p>où <span class="math inline">\(\rho(x)\)</span> est le coefficient de corrélation moyen entre les arbres individuels, <span class="math inline">\(\sigma(x)^2\)</span> est la variance d’un arbre individuel, <span class="math inline">\(M\)</span> est le nombre d’arbres dans la forêt. Cette décomposition fait apparaître l’influence de la corrélation entre les arbres sur les performance de la forêt aléatoire:</p>
<ul>
<li><strong>Si <span class="math inline">\(\rho(x)\)</span> est proche de 1</strong> (forte corrélation entre les arbres) : la première composante <span class="math inline">\(\rho \sigma^2\)</span> domine et la réduction de variance est moindre lorsque le nombre d’arbres augmente.</li>
<li><strong>Si <span class="math inline">\(\rho(x)\)</span> est proche de 0</strong> (faible corrélation entre les arbres) : la seconde composante <span class="math inline">\(\frac{1 - \rho}{M} \sigma^2\)</span> et la variance est davantage réduite avec l’augmentation du nombre d’arbres <span class="math inline">\(M\)</span>.</li>
</ul>
<p>L’objectif de l’entraînement des forêts aléatoires est donc de minimiser la corrélation entre les arbres tout en maximisant leur capacité à prédire correctement, ce qui permet de réduire la variance globale sans augmenter excessivement le biais. La sélection aléatoires des caractéristiques (<em>features</em>) à chaque nœud joue un rôle majeur dans cet arbitrage entre puissance prédictive des arbres et corrélation entre arbres.</p>
<!-- ## Les hyper-paramètres clés des forêts aléatoires

- **Nombre d'arbres**: les performances croissent avec le nombre d'arbres, jusqu'à un certain seuil à partir duquel elles se stabilisent. Souvent, quelques centaines d'arbres suffisent à stabiliser les performances des modèles. Au-delà, les gains de performance sont marginaux par rapport au temps de calcul nécessaire.

- **Méthode d'échantillonnage**: les échantillons _bootstrap_ peuvent être construits par tirage aléatoire **avec** ou **sans** remise.

- **Taux d'échantillonnage**: cet hyperparamètre contrôle la taille des échantillons _bootstrap_ utilisés pour entraîner les arbres.

- **Nombre de variables considérées à chaque noeud**: cet hyperparamètre détermine le nombre (ou la proportion) de _features_ sélectionnées aléatoirement à chaque nœud lors de la construction des arbres. Un nombre plus faible conduit à des arbres plus diversifiés et donc moins corrélés entre eux, mais peut entraîner une diminution de la qualité prédictive des arbres individuels, car ils sont parfois contraints de se diviser sur des variables moins pertinentes. Inversement, un nombre plus élevé améliore la performance des arbres individuels en leur permettant d'utiliser des variables plus informatives, mais accroît leur corrélation (les mêmes variables ayant tendance à être sélectionnées dans tous les arbres), limitant ainsi les bénéfices de l'agrégation en termes de réduction de variance. Ce phénomène est amplifié si seules quelques variables sont fortement prédictives, car elles dominent les divisions dans la majorité des arbres.


- **Nombre minimal d'observations dans une feuille** : Un nombre d'observation minimal peut réduire le surapprentissage et surtout le temps de calcul.

- **Critère de division des noeuds** (_splitting rule_) : 

- **Profondeur maximale des arbres** : en général, il est conseillé de laisser les arbres se développer pleinement (sans élagage) pour profiter de la réduction de variance par agrégation. Limiter la profondeur des arbres peut toutefois réduire le risque de surapprentissage et diminuer le temps de calcul.
 -->
</section>
</section>
<section id="sec-rf-oob" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sec-rf-oob"><span class="header-section-number">1.4</span> Evaluation des performances par l’erreur <em>Out-of-Bag</em> (OOB)</h2>
<p>La forêt aléatoire présente une particularité intéressante et très utile en pratique: <strong>il est possible d’évaluer les performances d’une forêt aléatoire directement à partir des données d’entraînement</strong>, grâce à l’estimation de l’erreur <em>Out-of-Bag</em> (OOB). Cette technique repose sur le fait que chaque arbre est construit à partir d’un échantillon <em>bootstrap</em>, c’est-à-dire un échantillon tiré avec remise. Cela implique qu’une part conséquente des observations ne sont pas utilisées pour entraîner un arbre donné. Ces observations laissées de côté forment un <strong>échantillon dit <em>out-of-bag</em></strong>, que l’on peut utiliser pour évaluer la performance de chaque arbre. On peut donc construire pour chaque observation du jeu d’entraînement une prédiction qui agrège uniquement les prédictions des arbres pour lesquels cette observation est <em>out-of-bag</em>; cette prédiction n’est pas affectée par le surapprentissage (puisque cette observation n’a jamais été utilisée pour entraîner ces arbres). De cette façon, il est possible d’évaluer correctement la performance de la forêt aléatoire en comparant ces prédictions avec la variable-cible à l’aide d’une métrique bien choisie.</p>
<p>La procédure d’estimation de l’erreur OOB se déroule comme ceci:</p>
<ol type="1">
<li><strong>Entraînement de la forêt aléatoire</strong>: la forêt aléatoire est entraînée sur les données d’entraînement selon la procédure détaillée ci-dessus.</li>
<li><strong>Prédiction <em>out-of-bag</em></strong> : Pour chaque observation <span class="math inline">\((x_i, y_i)\)</span> des données d’entraînement, on calcule la prédiction de tous les arbres pour lesquels elle fait partie de l’échantillon <em>out-of-bag</em>.</li>
<li><strong>Agrégation des prédictions</strong> : La prédiction finale est obtenue en agrégeant les prédictions selon la procédure standard détaillée ci-dessus (moyenne pour la régression, vote majoritaire pour la classification).</li>
<li><strong>Calcul de l’erreur OOB</strong> : L’erreur OOB est ensuite calculée en comparant les prédictions avec la variable-cible <span class="math inline">\(y\)</span> sur toutes les observations, à l’aide d’une métrique (précision, rappel, AUC, erreur quadratique moyenne, score de Brier…).</li>
</ol>
<p>L’utilisation de l’erreur OOB présente de multiples avantages:</p>
<ul>
<li><strong>Approximation de l’erreur de généralisation</strong>: L’erreur OOB est en général considérée comme une bonne approximation de l’erreur de généralisation, comparable à celle obtenue par une validation croisée.</li>
<li><strong>Pas besoin de jeu de validation séparé</strong> : L’un des principaux avantages de l’erreur OOB est qu’elle ne nécessite pas de réserver une partie des données pour la validation. Cela est particulièrement utile lorsque la taille du jeu de données est limitée, car toutes les données peuvent être utilisées pour l’entraînement tout en ayant une estimation fiable de la performance. Ceci dit, il est malgré tout recommandé de conserver un ensemble de test si la taille des données le permet, car il arrive que l’erreur OOB sous</li>
<li><strong>Gain de temps</strong> : Contrairement à la validation croisée qui requiert de réentraîner plusieurs fois le modèle pour un jeu donné d’hyperparamètres, l’erreur OOB ne nécessite qu’un seul entraînement du modèle. Cela induit un gain de temps appréciable lors de l’optimisation des hyperparamètres.</li>
</ul>
<!-- 
ANCIENNE VERSION DU PARAGRAPHE

### Estimation de l'erreur Out-of-Bag (OOB) {#sec-rf-oob}

L'estimation **Out-of-Bag (OOB)** est une méthode particulièrement efficace pour évaluer les performances des forêts aléatoires sans nécessité une **validation croisée** ou de réserver une partie des données pour l'étape du test. Cette technique repose sur le fait que chaque arbre dans une forêt aléatoire est construit à partir d'un échantillon bootstrap du jeu de données d'origine, c'est-à-dire un échantillon tiré avec remise. Or, en moyenne, environ **36 %** des observations ne sont pas inclus dans chaque échantillon bootstrap, ce qui signifie qu'elles ne sont pas utilisées pour entraîner l'arbre correspondant. Ces observations laissées de côté forment un **échantillon out-of-bag**. Chaque arbre peut donc être évalué sur son **échantillon out-of-bag** plutôt que sur un échantillon test.

**Procédure d'Estimation OOB**:

1. **Construction des arbres** : Chaque arbre de la forêt est construit à partir d'un échantillon bootstrap tiré avec remise à partir du jeu de données d'origine. Cela signifie que certaines observations seront sélectionnées plusieurs fois, tandis que d'autres ne seront pas sélectionnées du tout.
2. **Prédiction OOB** : Pour chaque observation $(x_i, y_i)$ qui n'a pas été inclus dans l'échantillon bootstrap qui a permi de construire un arbre donné, l'arbre est utilisé pour prédire la valeur de $y_i$. Ainsi, chaque observation est prédite par tous les arbres pour lesquels elle fait partie de l'échantillon out-of-bag.
3. **Agrégation des prédictions** : La prédiction finale pour chaque échantillon out-of-bag est obtenue en moyennant les prédictions de tous les arbres pour lesquels cet échantillon était OOB (pour la régression) ou par un vote majoritaire (pour la classification).
4. **Calcul de l'erreur OOB** : L'erreur OOB est ensuite calculée en comparant les prédictions agrégées avec les valeurs réelles des observations $y_i$. Cette erreur est une bonne approximation de l'erreur de généralisation du modèle.

**Avantages de l'Estimation OOB**:

- **Pas besoin de jeu de validation séparé** : L'un des principaux avantages de l'estimation OOB est qu'elle ne nécessite pas de réserver une partie des données pour la validation. Cela est particulièrement utile lorsque la taille du jeu de données est limitée, car toutes les données peuvent être utilisées pour l'entraînement tout en ayant une estimation fiable de la performance.
- **Estimation directe et efficace** : Contrairement à la validation croisée qui peut être coûteuse en temps de calcul, l'estimation OOB est disponible "gratuitement" pendant la construction des arbres. Cela permet d'évaluer la performance du modèle sans avoir besoin de réentraîner plusieurs fois le modèle et d'optimiser plus rapidement les hyperparamètres.
- **Approximation de l'erreur de généralisation** : L'erreur OOB est considérée comme une bonne approximation de l'erreur de généralisation, comparable à celle obtenue par une validation croisée 10-fold.  -->
</section>
<section id="interprétation-et-importance-des-variables" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="interprétation-et-importance-des-variables"><span class="header-section-number">1.5</span> Interprétation et importance des variables</h2>
<p>Les forêts aléatoires sont des modèles d’apprentissage performants, mais leur complexité interne les rend difficiles à interpréter, ce qui leur vaut souvent le qualificatif de “boîtes noires”. Comprendre l’influence des variables explicatives sur les prédictions est crucial pour interpréter les résutlats et être en mesure d’extraire des connaissances.</p>
<p>L’objectif des <strong>méthodes d’interprétabilité</strong> (ou d’importance des variables) est d’identifier les variables les plus influentes sur la variable cible, de comprendre les mécanismes prédictifs sous-jacents, et potentiellement d’extraire des règles de décision simples et transparentes. Plusieurs méthodes d’importance des variables existent, mais il est important de comprendre leurs forces et faiblesses.</p>
<section id="mesures-dimportance-classiques-et-leurs-biais" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="mesures-dimportance-classiques-et-leurs-biais"><span class="header-section-number">1.5.1</span> Mesures d’importance classiques (et leurs biais)</h3>
<ul>
<li><strong>Réduction moyenne de l’impureté</strong> (<em>Mean Decrease in Impurity</em> - <em>MDI</em>) : Cette méthode quantifie l’importance d’une variable par la somme des réductions d’impureté qu’elle induit dans tous les arbres de la forêt. Plus spécifiquement, pour chaque variable, on s’intéresse à la moyenne des réductions d’impureté qu’elle a engendrées dans tous les nœuds de tous les arbres où elle est impliquée. Les variables présentant la réduction moyenne d’impureté la plus élevée sont considérées comme les prédicteurs les plus importants.</li>
</ul>
<p>La MDI présente des biais importants. Elle est notamment sensible aux variables catégorielles avec de nombreuses modalités, qui peuvent apparaître artificiellement importantes (même si leur influence réelle est faible), ainsi qu’aux variables avec une échelle de valeurs plus étendues, qui obtiennent des scores plus élevés, indépendamment de leur importance réelle. Elle est également fortement biaisée en présence de variables explicatives corrélées, ce qui conduit à surestimer l’importance de variables redondantes. Les interactions entre variables ne sont pas non plus prises en compte de manière adéquate.</p>
<ul>
<li><strong>Importance par permutation</strong> (<em>Mean Decrease Accuracy</em> - <em>MDA</em>) : Cette méthode évalue l’importance d’une variable en mesurant la diminution de précision du modèle après permutation aléatoire de ses valeurs. Plus spécifiquement, pour chaque variable, les performances du modèle sont comparées avant et après la permutation de ses valeurs. La différence moyenne de performance correspond à la MDA. L’idée est que si l’on permute aléatoirement les valeurs d’une variable (cassant ainsi sa relation avec la cible), une variable importante entraînera une hausse significative de l’erreur de généralisation.</li>
</ul>
<p>Comme la MDI, la MDA présente des biais lorsque les variables sont corrélées. En particulier, la MDA peut surévaluer l’importance de variables qui sont corrélées à d’autres variables importantes, même si elles n’ont pas d’influence directe sur la cible (<span class="citation" data-cites="benard2022mda">Bénard, Da Veiga, and Scornet (<a href="#ref-benard2022mda" role="doc-biblioref">2022</a>)</span>).</p>
<p>Plusieurs stratégies peuvent aider à réduire les biais d’interprétation :</p>
<ul>
<li>Prétraitement des variables: Standardisation des variables, regroupement des modalités rares des variables catégorielles, réduction de la cardinalité des variables catégorielles.</li>
<li>Analyse des corrélations: Identification et gestion des variables fortement corrélées, qui peuvent fausser les mesures d’importance.</li>
<li>Choix de méthodes robustes: Privilégier les méthodes moins sensibles aux biais, comme les CIF ou la Sobol-MDA, et, le cas échéant, SHAFF pour les valeurs de Shapley. Ces méthodes sont présentées dans la sectio suivante.</li>
</ul>
</section>
<section id="méthodes-dimportance-avancées" class="level3" data-number="1.5.2">
<h3 data-number="1.5.2" class="anchored" data-anchor-id="méthodes-dimportance-avancées"><span class="header-section-number">1.5.2</span> Méthodes d’importance avancées</h3>
<p>Pour pallier les limites des méthodes traditionnelles, des approches plus sophistiquées ont été développées.</p>
<ul>
<li><p><strong>Valeurs de Shapley</strong>: Les valeurs de Shapley permettent de quantifier la contribution de chaque variable explicative à la variance expliquée de la variable cible, en tenant compte des interactions entre les variables. Elles attribuent à chaque variable une contribution marginale moyenne à la performance du modèle, en considérant toutes les combinaisons possibles de sous-ensembles de variables. Cependant, l’estimation des valeurs de Shapley est computationnellement coûteuse (complexité exponentielle avec le nombre de variables). Des méthodes approximatives existent, mais peuvent introduire des biais. L’algorithme SHAFF (<span class="citation" data-cites="benard2022shaff">Bénard et al. (<a href="#ref-benard2022shaff" role="doc-biblioref">2022</a>)</span>) propose une solution rapide et précise à ce problème, en tirant parti des propriétés des forêts aléatoires.</p></li>
<li><p><strong>Conditional Inference Forests</strong> (CIF): Les CIF (<span class="citation" data-cites="strobl2007bias">Strobl et al. (<a href="#ref-strobl2007bias" role="doc-biblioref">2007</a>)</span>), implémentées dans le package party de R (cforest), corrigent certains biais de la MDI en utilisant des tests statistiques conditionnels pour sélectionner les variables et les seuils de coupure dans les arbres. Elles sont particulièrement robustes face aux variables hétérogènes et aux corrélations entre variables. Couplées à un échantillonnage sans remise, les CIF fournissent des mesures d’importance plus fiables.</p></li>
<li><p><strong>Sobol-MDA</strong>: La Sobol-MDA combine l’idée de la MDA avec une approche basée sur les indices de Sobol, permettant de gérer efficacement les variables dépendantes. Au lieu de permuter les valeurs, elle projette la partition des arbres sur le sous-espace excluant la variable dont on souhaite mesurer l’importance, simulant ainsi son absence. Elle est plus efficace en calcul que les méthodes MDA classiques tout en fournissant une mesure d’importance cohérente, convergeant vers l’indice de Sobol total (la mesure appropriée pour identifier les covariables les plus influentes, même avec des dépendances) (<span class="citation" data-cites="benard2022mda">Bénard, Da Veiga, and Scornet (<a href="#ref-benard2022mda" role="doc-biblioref">2022</a>)</span>).</p></li>
</ul>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-benard2022shaff" class="csl-entry" role="listitem">
Bénard, Clément, Gérard Biau, Sébastien Da Veiga, and Erwan Scornet. 2022. <span>“SHAFF: Fast and Consistent SHApley eFfect Estimates via Random Forests.”</span> In <em>International Conference on Artificial Intelligence and Statistics</em>, 5563–82. PMLR.
</div>
<div id="ref-benard2022mda" class="csl-entry" role="listitem">
Bénard, Clément, Sébastien Da Veiga, and Erwan Scornet. 2022. <span>“Mean Decrease Accuracy for Random Forests: Inconsistency, and a Practical Solution via the Sobol-MDA.”</span> <em>Biometrika</em> 109 (4): 881–900. <a href="https://doi.org/10.1093/biomet/asac017">https://doi.org/10.1093/biomet/asac017</a>.
</div>
<div id="ref-biau2012analysis" class="csl-entry" role="listitem">
Biau, Gérard. 2012. <span>“Analysis of a Random Forests Model.”</span> <em>The Journal of Machine Learning Research</em> 13 (1): 1063–95.
</div>
<div id="ref-breiman2001random" class="csl-entry" role="listitem">
Breiman, Leo. 2001. <span>“Random Forests.”</span> <em>Machine Learning</em> 45: 5–32.
</div>
<div id="ref-louppe2014understanding" class="csl-entry" role="listitem">
Louppe, Gilles. 2014. <span>“Understanding Random Forests: From Theory to Practice.”</span> <em>arXiv Preprint arXiv:1407.7502</em>.
</div>
<div id="ref-strobl2007bias" class="csl-entry" role="listitem">
Strobl, Carolin, Anne-Laure Boulesteix, Achim Zeileis, and Torsten Hothorn. 2007. <span>“Bias in Random Forest Variable Importance Measures: Illustrations, Sources and a Solution.”</span> <em>BMC Bioinformatics</em> 8: 1–21.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/github\.com\/inseefrlab\/DT_methodes_ensemblistes");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter2/2-bagging.html" class="pagination-link" aria-label="Le _bagging_">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Le <em>bagging</em></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter2/4-boosting.html" class="pagination-link" aria-label="Le *boosting*">
        <span class="nav-page-text">Le <em>boosting</em></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© CC-1.0</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/edit/main/chapters/chapter2/3-random_forest.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/blob/main/chapters/chapter2/3-random_forest.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/inseefrlab/DT_methodes_ensemblistes/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>