### Comparaison entre forêts aléatoires et _gradient boosting_

Les forêts aléatoires et le *gradient boosting* paraissent très similaires au premier abord: il s'agit de deux approches ensemblistes, qui construisent des modèles très prédictifs performants en combinant un grand nombre d'arbres de décision. Mais en réalité, ces deux approches présentent plusieurs différences fondamentales:

-   Les deux approches reposent sur des __fondements théoriques différents__: la loi des grands nombres pour les forêts aléatoires, la théorie de l'apprentissage statistique pour le *boosting*.

-   __Les arbres n'ont pas le même statut dans les deux approches__. Dans une forêt aléatoire, les arbres sont entraînés indépendamment les uns des autres et constituent chacun un modèle à part entière, qui peut être utilisé, représenté et interprété isolément. Dans un modèle de *boosting*, les arbres sont entraînés séquentiellement, ce qui implique que chaque arbre n'a pas de sens indépendamment de l'ensemble des arbres qui l'ont précédé dans l'entraînement. Par ailleurs, les arbres d'une forêt aléatoire sont relativement complexes et profonds (car ce sont des modèles à part entière), alors que dans le _boosting_ les arbres sont plus souvent simples et peu profonds.

-   Les __points d'attention lors de l'entraînement__ des algorithmes sont différents: l'enjeu principal de l'entraînement d'une forêt aléatoire est trouver le bon arbitrage entre puissance prédictive des arbres et corrélation entre arbres, tandis que l'entraînement d'un algorithme de _gradient boosting_ porte davantage sur la lutte contre le surapprentissage.

-   __Complexité d'usage__: les forêts aléatoires s'avèrent plus faciles à prendre en main que le _gradient boosting_, car elles comprennent moins d'hyperparamètres dont l'optimisation est moins complexe.

-   __Conditions d'utilisation__: il est possible d'évaluer la qualité d'une forêt aléatoire en utilisant les données sur lesquelles elle a été entraînée (en utilisant les échantillons _Out-Of-Bag_), alors que c'est impossible avec le _gradient boosting_, pour lequel il faut impérativement conserver un ensemble de validation pour évaluer correctement la performance. Ce point (développé dans la section @sec-rf-oob) peut sembler purement technique en apparence, mais il s'avère important en pratique dans de nombreuses situations, par exemple lorsque les données disponibles sont de taille restreinte ou lorsque les ressources informatiques disponibles ne sont pas suffisantes pour mener un exercice de validation croisée.


