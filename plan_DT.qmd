<!-- ---
title: "Introduction aux méthodes ensemblistes"
subtitle: "Plan détaillé"
author: |
  [Olivier Meslin](https://github.com/oliviermeslin)
  [Mélina Hillion](https://github.com/melinahillion)
format:
  typst:
    toc: true
    section-numbering: 1.1.1
bibliography: references.bib
--- -->

Restriction du champ: méthodes ensemblistes à base d'arbres.

Lecture de base: chapitres 9-12: https://bradleyboehmke.github.io/HOML/

# Survol des méthodes ensemblistes

__Principe__: cette partie propose une présentation intuitive des méthodes ensemblistes, à destination notamment des _managers_ sans bagage en _machine learning_. Elle ne contient aucune formalisation mathématique.

## Principe des méthodes ensemblistes


### Pourquoi utiliser des méthodes ensemblistes?

Avantages: 

- Méthodes adaptées à un grand nombre de cas d'usage de la statistique publique:

    - Elles sont notamment applicables à tous les problèmes pour lesquels on utilise une régression linéaire ou une régression logistisque);
    - Elles s'appliquent à des données tabulaires (enregistrements en lignes, variables en colonnes), situation très fréquente dans la statistique publique.
    
- Performances quasi systématiquement supérieures aux méthodes économétriques traditionnelles;
- Scalabilité: ces méthodes peuvent être appliquées à des données volumineuses;
- Coût d'entrée modéré (comparé à des approches plus avancées comme le _deep learning_).

Inconvénients:

- Temps d'entraînement potentiellement long, notamment pour l'optimisation des hyperparamètres.
- Ces méthodes peuvent nécessiter une puissance de calcul importante et/ou une mémoire vive de grande taille.
- Interprétabilité moindre que les méthodes économétriques traditionnelles (et encore, ça se discute)
- Risque de surapprentissage, en particulier pour le _boosting_
- La prise en main de ces méthodes requiert un temps d'apprentissage (une bonne maîtrise de Python ou R est un prérequis).


### L'union fait la force

Plutôt que de chercher à construire d'emblée un unique modèle très complexe, les approches ensemblistes vise à obtenir un modèle très performant en combinant un grand nombre de modèles simples.

Il existe trois grandes approches ensemblistes: 

- le _bagging_;
- le _stacking_;
- le _boosting_.

Le présent document se concentre sur deux approches: le _bagging_ et le _boosting_.


### Critères de performance et sélection d'un modèle 

La performance d'un modèle augmente généralement avec sa complexité, jusqu'à atteindre un maximum, puis diminue. L'objectif est d'obtenir un modèle qui minimise à la fois le sous-apprentissage (biais) et le sur-apprentissage (variance). C'est ce qu'on appelle le compromis biais/variance. Cette section présente très brièvement les critères utilisés pour évaluer et comparer les performances des modèles.

## Comment fonctionnent les méthodes ensemblistes?

Trois temps:

- les arbres de décision et de régression (CART);
- les forêts aléatoires;
- le boosting.

### Le point de départ: les arbres de décision et de régression

Présenter _decision tree_ et _regression tree_. Reprendre des éléments du chapitre 9 de https://bradleyboehmke.github.io/HOML/

Principes d'un arbre: 

- partition de l'espace des _features_;
- fonction constante par morceaux, avec une valeur unique par feuille;
- un arbre mobilise notamment les interactions entre variables.

Illustration, et représentation graphique (sous forme d'arbre et de graphique).

## Le _bagging_ et les _random forests_

### Le _bagging_

Présenter le _bagging_ en reprenant des éléments du chapitre 10 de https://bradleyboehmke.github.io/HOML.

- Présentation avec la figure en SVG;
- Illustration avec un cas d'usage de classification en deux dimensions.

### Les _random forests_

Expliquer que les _random forests_ sont une amélioration du _bagging_, en reprenant des éléments du chapitre 11 de https://bradleyboehmke.github.io/HOML/

<!-- https://neptune.ai/blog/ensemble-learning-guide -->
<!-- https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/ -->

- Présentation avec la figure en SVG;
- Difficile d'illustrer avec un exemple (car on ne peut pas vraiment représenter le _feature sampling_);
- Bien insister sur les avantages des RF: 1/ faible nombre d'hyperparamètres; 2/ faible sensibilité aux hyperparamètres; 3/ limite intrinsèque à l'overfitting.

## Le _boosting_

Reprendre des éléments du chapitre 12 de https://bradleyboehmke.github.io/HOML/ et des éléments de la formation boosting.

Le *boosting* combine l'[**approche ensembliste**]{.orange} avec une [**modélisation additive par étapes**]{.orange} (*forward stagewise additive modeling*).

- Présentation du principe: entraîner séquentiellement des modèles simples et peu performants (_weak learners_) pour obtenir un modèle complexe très performant (_strong learner_);
- Avantage du boosting: performances particulièrement élevées.
- Inconvénients: 1/ nombre élevé d'hyperparamètres; 2/ sensibilité des performances aux hyperparamètres; 3/ risque élevé d'overfitting.

- Préciser qu'il est possible d'utiliser du subsampling par lignes et colonnes pour un algoithme de boosting. Ce point est abordé plus en détail dans la partie sur les hyperparamètres.

### Les différences entre _random forests_ et _boosting_

Les forêts aléatoires et le *gradient boosting* paraissent très similaires au premier abord: il s'agit de deux approches ensemblistes, qui construisent des modèles très prédictifs performants en combinant un grand nombre d'arbres de décision. Mais en réalité, ces deux approches présentent plusieurs différences fondamentales:

-   Les deux approches reposent sur des fondements théoriques différents: la loi des grands nombres pour les forêts aléatoires, la théorie de l'apprentissage statistique pour le *boosting*.

-   Les arbres n'ont pas le même statut dans les deux approches. Dans une forêt aléatoire, les arbres sont entraînés indépendamment les uns des autres et constituent chacun un modèle à part entière, qui peut être utilisé, représenté et interprété isolément. Dans un modèle de *boosting*, les arbres sont entraînés séquentiellement, ce qui implique que chaque arbre n'est ni utilisable, ni interprétable indépendamment de l'ensemble des arbres qui l'ont précédé dans l'entraînement.

-   *overfitting*: borne théorique à l'*overfitting* dans les RF, contre pas de borne dans le *boosting*. Deux conséquences: 1/ lutter contre l'overfitting est essentiel dans l'usage du *boosting*; 2/ le *boosting* est plus sensible au bruit et aux erreurs sur $y$ que la RF.

-   Les points d'attention dans l'entraînement ne sont pas les mêmes: arbitrage puissance-corrélation dans la RF, arbitrage puissance prédictive-overfitting dans le *boosting*.

-   Conditions d'utilisation: la RF peut être utilisée sur le _train_ grâce aux prédictions _out-of-bag_, pas le *boosting*. Exemple: repondération d'une enquête.

-   Complexité d'usage: peu d'hyperparamètres dans les RF, contre un grand nombre dans le *boosting*.

### Quel algorithme utiliser?

Comment choisir entre forêt aléatoire et boosting:

- Temps dont on dispose: RF si peu de temps;
- Puissance de calcul dont on dispose: RF si peu de puissance;
- Compréhension des algorithmes: RF si on est débutant;
- Nombre de _features_: RF si nombreuses;
- Nature du problème: y a-t-il des spécificités locales (au sens mathématique) que même un arbre assez profond aura du mal à prendre en compte? Si oui, le _boosting_ est indiqué.
- Y a-t-il beaucoup de bruit, de valeurs aberrantes ou d'erreurs dans les données: si oui, la RF est préférable.

# Présentation formalisée des méthodes ensemblistes

## Rappels sur l'apprentissage supervisé

Veut-on faire quelque rappels sur l'apprentissage supervisé?



## Les arbres de décision et de classification

### La brique élémentaire: l'arbre de décision



### L'algorithme CART, un partitionnement binaire récursif

Description des CART.

## Le bagging et les forêts aléatoires

### Le _bagging_

### Les forêts aléatoires

## Le _gradient boosting_

Cette section détaille la mécanique du _gradient boosting_ en reprenant les notations de l'article décrivant XGBoost (2016). Cette partie décrit rapidement: le cadre théorique _weak learner_ et _strong learner_ (@shapire1990strength), le principe de la modélisation additive par étapes (@friedman2001greedy), l'approximation faite par XGBoost, la méthode de calcul des poids optimaux, la méthode de recherche des _splits_ optimaux, les fonctions de perte couramment utilisées.

Cette partie mentionnera rapidement les poinds suivants:

- il existe des implémentations du _boosting_ qui ne sont pas du _gradient boosting_ (exemple: l'_adaptative boosting_ de l'algorithme AdaBoost).
- Il existe de multiples implémentations du _gradient boosting_ (GBM, lightGBM, XGBoost, Catboost...), globalement similaires mais qui diffèrent sur des points de détail. La présentation qui suit doit donc être complétée par la lecture de la documentation des différents algorithmes.  
- Cette approche permet de construire des modèles de _boosting_, mais aussi des forêts aléatoires entraînées par descente de gradient. 

<!-- Question: Donner un algorithme en pseudo code décrivant la façon dont XGBoost énumère les splits possibles. -->

# Comment (bien) utiliser les approches ensemblistes

## Préparer les données

### La _target_

- Penser aux transformations préalables (log, ratio...).
- Quid des variables catégorielles ordonnées?

### Les _features_

- Que faire des variables continues? 
    - les transformations monotones sont inutiles;
    - les transformations non monotones peuvent être utiles;
    - attention aux paramètres de la _quantization_ par histogramme;
- La gestion des variables catégorielles:
    - Il est possible de passer les variables catégorielles ordonnées en integer.
    - Pour les variables catégorielles non ordonnées: 
        - Réduire le nombre de modalités?
        - utiliser le one hot encoding ou le support expérimental des variables catégorielles (split selon la méthode de @fisher1958grouping)

## Comment entraîner un algorithme

### Entraîner une _random forest_

#### Rôle et interprétation des principaux hyperparamètres

Faire systématiquement le renvoi vers la partie formalisée, pour que les lecteurs sachent où intervient chaque hyperparamètre.

#### Guide d'entraînement d'une forêt aléatoire

Reprendre les recommandations de @probst2019hyperparameters.

### Entraîner un algorithme de _boosting_

#### Rôle et interprétation des principaux hyperparamètres

Faire systématiquement le renvoi vers la partie formalisée, pour que les lecteurs sachent où intervient chaque hyperparamètre.

#### Guide d'entraînement d'un algorithme de _boosting_

Reprendre les recommandations de @bentejac2021comparative. Que dit HOML là-dessus?

## Usage avancé

### Choisir une fonction de perte non standard

Exemple: Huber?

### L'utilisation des pondérations

Cette partie présente l'usage des pondérations des observations (`sample_weight`) et de la pondération de la classe positive (`scale_pos_weight`).

Bien expliquer où ces pondérations interviennent dans la partie formalisée.


## Interprétabilité des méthodes

- Mesure d'importance: intérêt et limites.
- Quels frameworks veut-on présenter?
    - Interprétabilité globale;
    - Interprétabilité locale.



# Cas d'usage

- Données (pouvant être rendues) publiques
- Notebooks déployables sur le datalab
- Code en Python

## Régression

### Cas général

### Régression en présence d'outliers

=> Changement de fonction de perte

## Classification

### Cas général

### Classification déséquilibrée

=> Utiliser la pondération de la classe minoritaire

<!-- IMPORTANT -->
<!-- Formations sur le ML -->
<!-- https://github.com/davidrpugh/machine-learning-for-tabular-data -->
<!-- IMPORTANT -->

<!-- Petites questions: -->
<!-- - Quelle implémentation des RF veut-on présenter? Je suis favorable à avoir un seul framework RF/Boosting, mais c'est peut-être pas standard. Quelques références: -->

<!--     - r -->
<!--     - https://xgboost.readthedocs.io/en/stable/tutorials/rf.html -->



<!-- Petites notes complémentaires -->
<!-- - Interprétabilité: https://selfexplainml.github.io/PiML-Toolbox/_build/html/index.html -->
<!-- - Comparaison arbres et autres (Papier R Avouac): https://proceedings.neurips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Paper-Datasets_and_Benchmarks.pdf -->

<!-- https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_6_ImbalancedLearning/CostSensitive.html -->
