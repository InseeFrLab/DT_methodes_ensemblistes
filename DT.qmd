---
title: "Hello Typst!"
author: |
  [Olivier Meslin](https://github.com/oliviermeslin)
  [Mélina Hillion](https://github.com/melinahillion)
format:
  typst:
    toc: true
    section-numbering: 1.1.1
---
  
Restriction du champ: méthodes ensemblistes à base d'arbres.

Lecture de base: chapitres 9-12: https://bradleyboehmke.github.io/HOML/

# Survol des méthodes ensemblistes

__Principe__: cette partie propose une présentation intuitive des méthodes ensemblistes, à destination notamment des _managers_ sans bagage en _machine learning_. Elle ne contient aucune formalisation mathématique.

## Principe des méthodes ensemblistes

### Pourquoi utiliser des méthodes ensemblistes?

Avantages: 

- Méthodes adaptées à un grand nombre de cas d'usage de la statistique publique:
  
    - Elles sont notamment applicables à tous les problèmes pour lesquels on utilise une régression linéaire ou une régression logistisque);
    - Elles s'appliquent à des données tabulaires (enregistrements en lignes, variables en colonnes), situation très fréquente dans la statistique publique.
    
    
- Performances quasi systématiquement supérieures aux méthodes économétriques traditionnelles;
- Scalabilité: ces méthodes peuvent être appliquées à des données volumineuses;
- Coût d'entrée modéré (comparé à des approches plus avancées comme le _deep learning_)

Inconvénients:
  
- Bagage informatique minimal (une bonne maîtrise de Python ou R est un prérequis) -> comme toutes les méthodes statistiques je dirais. Et avec l'arrivée de chat GPT & co ou avec une bonne documentation le coût d'entrée est moindre.
- Temps d'entraînement potentiellement long, notamment pour l'optimisation des hyperparamètres.
- Ces méthodes peuvent nécessiter une puissance de calcul importante et/ou une mémoire vive de grande taille.
- Interprétabilité moindre que les méthodes économétriques traditionnelles (et encore, ça se discute)
- Risque de surapprentissage.


### L'union fait la force

Plutôt que de chercher à construire d'emblée un unique modèle très complexe, les approches ensemblistes vise à obtenir un modèle très performant en combinant un grand nombre de modèles simples.

Il existe quatre grandes approches ensemblistes: 

- le _bagging_;
- la _random forest_
- le _stacking_;
- le _boosting_.

Le présent document se concentre sur deux approches: la _radom forest_ et le _boosting_.


Les méthodes ensemblistes consistent à entraîner plusieurs modèles de base, puis à combiner les résultats obtenus afin de produire une prédiction consolidée. Les modèles de base, dits "apprenants faibles" ("weak learners"), sont généralement peu complexes. Le choix de ces modèles et la manière dont leurs prédictions sont combinées sont des facteurs clés pour la performance de ces approches.

Les méthodes ensemblistes peuvent être divisées en deux grandes familles selon qu'elles s'appuient sur des modèles entrainés en parallèle ou de manière imbriquée ou séquentielle. Lorsque les modèles sont entrainés en parallèle, chaque modèle de base est entraîné pour la même tâche de prédiction en utilisant un sous-ensemble de l'échantillon d'entraînement, un sous-ensemble de variables, ou une combinaison des deux. Les techniques les plus populaires sont le bagging et la forêt aléatoire. 
Lorsque les modèles de base sont entrainés de manière séquentielle, appelée boosting, chaque modèle vise à minimiser l'erreur de prédiction du modèle précédent. Les implémentations les plus courantes du boosting sont actuellement XGBoost, CatBoost et LightGBM.


## Comment fonctionnent les méthodes ensemblistes?

Quatre temps:
  
- les arbres de décision et de régression (CART);
- les forêts aléatoires;
- le boosting.

### Le point de départ: les arbres de décision et de régression

Présenter _decision tree_ et _regression tree_. Reprendre des éléments du chapitre 9 de https://bradleyboehmke.github.io/HOML/
  
Principes d'un arbre: 

- fonction constante par morceaux;
- partition de l'espace;
- interactions entre variables.

Illustration, et représentation graphique (sous forme d'arbre et de graphique).



### Critères de performance et sélection d'un modèle 

La performance d'un modèle augmente généralement avec sa complexité, jusqu'à atteindre un maximum, puis diminue. L'objectif est d'obtenir un modèle qui minimise à la fois le sous-apprentissage (biais) et le sur-apprentissage (variance). C'est ce qu'on appelle le compromis biais/variance. Cette section présente très brièvement les critères utilisés pour évaluer et comparer les performances des modèles.




## Le _bagging_ et les _random forests_

### Le _bagging_

Présenter le _bagging_ en reprenant des éléments du chapitre 10 de https://bradleyboehmke.github.io/HOML.
Mettre une description de l'algorithme en pseudo-code?


- Présentation avec la figure en SVG;
- Illustration avec un cas d'usage de classification en deux dimensions.


### Les _random forests_

Expliquer que les _random forests_ sont une amélioration du _bagging_, en reprenant des éléments du chapitre 11 de https://bradleyboehmke.github.io/HOML/

<!-- https://neptune.ai/blog/ensemble-learning-guide -->
<!-- https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/ -->

- Présentation avec la figure en SVG;
- Difficile d'illustrer avec un exemple (car on ne peut pas vraiment représenter le _feature sampling_);
- Bien insister sur les avantages des RF: 1/ faible nombre d'hyperparamètres; 2/ faible sensibilité aux hyperparamètres; 3/ limite intrinsèque à l'overfitting.

## Le _boosting_

Reprendre des éléments du chapitre 12 de https://bradleyboehmke.github.io/HOML/ et des éléments de la formation boosting.

Le *boosting* combine l'[**approche ensembliste**]{.orange} avec une [**modélisation additive par étapes**]{.orange} (*forward stagewise additive modeling*).

- Présentation;
- Avantage du boosting: performances particulièrement élevées.
- Inconvénients: 1/ nombre élevé d'hyperparamètres; 2/ sensibilité des performances aux hyperparamètres; 3/ risque élevé d'overfitting.

- Préciser qu'il est possible d'utiliser du subsampling par lignes et colonnes pour un algoithme de boosting. Ce point est abordé plus en détail dans la partie sur les hyperparamètres.




# Les méthodes d'entraînement


Présentation détaillée des algorithmes utilisés et des fondements statistiques. Cette partie porte précisément sur l'optimisation par le gradient.

Bien préciser:

- il existe des implémentations du _boosting_ qui ne sont pas du _gradient boosting_ (exemple: l'_adaptative boosting_ de l'algorithme AdaBoost).
- Il existe de multiples implémentations du _gradient boosting_ (GBM, lightGBM, XGBoost, Catboost...), globalement similaires mais qui diffèrent sur des points de détail. La présentation qui suit doit donc être complétée par la lecture de la documentation des différents algorithmes.  
- cette approche permet de construire des forêts aléatoires et des modèles de _boosting_. 

L'exposé qui suit reprend les notations de l'article qui a introduit XGBoost (2016). Il est important de numéroter les équations pour faire le lien entre la partie qui liste les hyperparamètres et les équations dans lesquels ils interviennent.

## Rappels sur l'apprentissage supervisé

Reprendre les éléments figurant dans la formation boosting.


## La mécanique des approches ensemblistes

### La  _random forest_

Mettre une description de l'algorithme en pseudo-code

Reprendre les éléments figurant dans la formation boosting.

La Random Forest est un algorithme d'apprentissage ensembliste basé sur le bagging (Bootstrap Aggregating) qui combine les prédictions de multiples arbres de décision pour améliorer les performances de prédiction et réduire le surapprentissage. Voici les étapes principales :

    Sous-échantillonnage bootstrap :
      Chaque arbre de décision est construit à partir d'un échantillon aléatoire (tirage avec remise, échantillon de même taille que l'échantillon initial) généré par bootstrap à partir de l'ensemble d'entraînement initial. 

    Construction de l'arbre de décision :
        À chaque nœud de l'arbre, un sous-ensemble aléatoire de caractéristiques (variables) est considéré pour le split.
        L'arbre est construit en divisant récursivement les données en sous-ensembles homogènes jusqu'à ce qu'un critère d'arrêt soit atteint, tel que la profondeur maximale de l'arbre ou le nombre minimum d'observations par feuille.

    Entraînement de la forêt :
        Une fois les arbres de décision construits, les prédictions de chaque arbre sont agrégées. Pour une classification, le mode (classe la plus fréquente) est utilisé comme prédiction finale ; pour une régression, la moyenne des prédictions est considérée

    Prédiction :
        Pour faire une prédiction sur de nouvelles données, chaque arbre de la forêt donne sa prédiction et la prédiction finale est déterminée selon la méthode d'agrégation mentionnée ci-dessus.
        

### Le boosting

Mettre une description de l'algorithme en pseudo-code

Reprendre les éléments figurant dans la formation boosting.


Le boosting est une famille d'algorithmes d'apprentissage ensembliste où les modèles sont formés séquentiellement, chaque modèle tentant de corriger les erreurs des modèles précédents. L'algorithme de boosting le plus populaire est AdaBoost (Adaptive Boosting), et ses variantes les plus récentes incluent Gradient Boosting, XGBoost et LightGBM. 

Etapes de construction du modèle :

    Initialisation des poids :
        Les observations de l'échantillon d'entraînement reçoivent un poids égal.

    Construction du modèle de base :
        Le modèle de base accorde une importance (poids) plus élevée aux observations mal classées par les modèles précédents.

    Calcul de l'erreur pondérée :
        L'erreur pondérée du modèle de base est calculée en utilisant les poids associés à chaque observation. Cela permet de quantifier l'ampleur du problème lié aux observations mal classées.

    Mise à jour des poids :
        Les poids des observations sont mis à jour à chaque itération en augmentant le poids des observations mal classés et en diminuant le poids des observations correctement classés.

    Répétition du processus :
        Les étapes précédentes sont répétées pour former un ensemble de modèles, où chaque modèle est entraîné pour corriger les erreurs des modèles précédents.

    Agrégation des prédictions :
        Pour faire une prédiction sur de nouvelles données, les prédictions de chaque modèle sont agrégées, souvent en utilisant une moyenne pondérée.



## La construction d'un arbre 


## L'optimisation du modèle de random forest par descente de gradient

Donner les formules d'XGBoost. Donner un algorithme en pseudo code décrivant la façon dont XGBoost énumère les splits possibles.

Expliquer:

- l'approche _greedy_, et le _pruning_;
- l'approche par histogramme ou par énumération exacte;
- le rôle des hyperparamètres qui interviennent dans la construction des arbres.

Faire une figure détaillée d'un arbre avec des annotations (A, B, C) pour permettre des renvois depuis la liste des hyperparamètres?


## Présentation détaillée du _gradient boosting_


## Le choix d'une fonction de perte

Exemple: Huber?

## L'utilisation des pondérations

Bien expliquer où elles interviennent.




# Comment (bien) utiliser les approches ensemblistes

## Différence entre RF et _boosting_

Comment choisir entre forêt aléatoire et boosting:

- Temps dont on dispose: RF si peu de temps;
- Puissance de calcul dont on dispose: RF si peu de puissance;
- Compréhension des algorithmes: RF si on est débutant;
- Nombre de _features_; RF si nombreuses;
- Nature du problème: y a-t-il des spécificités locales (au sens mathématique) qu'un arbre assez profond aura du mal à prendre en compte? Si oui, le _boosting_ peut aider
- Présence d'_outliers_: si oui, RF, ou alors _boosting_ avec _subsampling_.


## La préparation des données

### La _target_

- Penser aux transformations préalables (log, ratio...).
- Quid des variables catégorielles ordonnées?

### Les _features_

- Que faire des variables continues? 
    - les transformations monotones sont inutiles;
    - les transformations non monotones peuvent être utiles;
    - attention aux paramètres de la _quantization_ par histogramme;
- La gestion des variables catégorielles:
    - one hot encoding?
    - support expérimental des variables catégorielles?

## Rôle et interprétation des principaux hyperparamètres

gamma, beta, alpha, lambda, eta, M, T, nb de quantiles;
method = "hist"

Faire systématiquement le renvoi vers la partie matheuse, pour que les lecteurs sachent où intervient chaque paramètre.

## Diagnostics post-entraînement

- Mesure d'importance: intérêt et limites.
- Y a-t-il d'autres diagnostics standards?

# Interprétabilité

Quels frameworks veut-on présenter?


# Cas d'usage: exemples d'application

- Données (pouvant être rendues) publiques
- Notebooks déployables sur le datalab
- Code en Python

## Régression

### Cas général

### Régression en présence d'outliers

=> Changement de fonction de perte

## Classification

### Cas général

### Classification déséquilibrée

=> Pondération de la classe minoritaire

<!-- IMPORTANT -->
<!-- Formations sur le ML -->
<!-- https://github.com/davidrpugh/machine-learning-for-tabular-data -->
<!-- IMPORTANT -->

<!-- Petites questions: -->
<!-- - Quelle implémentation des RF veut-on présenter? Je suis favorable à avoir un seul framework RF/Boosting, mais c'est peut-être pas standard. Quelques références: -->

<!--     - https://konfuzio.com/en/random-forest/ -->
<!--     - https://xgboost.readthedocs.io/en/stable/tutorials/rf.html -->



<!-- Petites notes complémentaires -->
<!-- - Interprétabilité: https://selfexplainml.github.io/PiML-Toolbox/_build/html/index.html -->
<!-- - Comparaison arbres et autres (Papier R Avouac): https://proceedings.neurips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Paper-Datasets_and_Benchmarks.pdf -->

<!-- https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_6_ImbalancedLearning/CostSensitive.html -->
